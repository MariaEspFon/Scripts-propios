{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaEspFon/Scripts-propios/blob/main/TensorFlow/CNN_model_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNAOn5Ia7pG"
      },
      "source": [
        "# OPTIMIZACIÓN DE HIPERPARÁMETROS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhxVlFL7j4N6"
      },
      "source": [
        "## 1. Inicialización de Keras y TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcFrOCQOYU1R",
        "outputId": "00b03189-079a-4fe1-8a26-c895a1209cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version:  2.18.0\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "#print(\"Keras version: \", tf.keras.__version__)\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtndO_D__Z2T"
      },
      "source": [
        "## 2. Carga de datos EDA desde Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niPo3Nfh-bVz",
        "outputId": "3f14ac9b-ca64-47c6-d535-26be4c212f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset: (3949, 21)\n",
            "Recuento de instancias por clase:\n",
            "State\n",
            "1    2435\n",
            "0    1514\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/MariaEspFon/Scripts-propios/main/MATLAB/EDA_D7.2_EMA.csv'\n",
        "column_names = ['Mean','Median', 'Standard Dev', 'Max Value', 'Min Value', 'Standard Dev 1st diff', 'Median 1st diff', 'Standard Dev 2nd diff',\n",
        "                'Total Area', 'Kurtosis', 'SCR', 'Power', '99% Bandwidth', 'Top Bandwidth Frequency',\n",
        "                'Phasic mean', 'Phasic Stdev', 'Phasic AuC', 'Tonic mean', 'Tonic Stdev', 'Tonic AuC',\n",
        "                'State']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names, sep=',', skipinitialspace=True)\n",
        "\n",
        "size = raw_dataset.shape\n",
        "print(f'Formato del dataset: {size}')\n",
        "\n",
        "class_counts = raw_dataset['State'].value_counts()\n",
        "print(\"Recuento de instancias por clase:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WEvgfenf-pEf",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "e677a28f-e000-4bb7-aefe-a863ab215bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Mean    Median  Standard Dev  Max Value  Min Value  \\\n",
              "4466  1.466113  1.566922      1.261131   3.142194  -0.076818   \n",
              "4467  0.540481  0.034924      0.963236   3.007747  -0.231767   \n",
              "4468  2.449819  2.981136      1.047429   3.098601   0.061658   \n",
              "4469  2.944428  2.946765      0.031031   3.030734   2.796635   \n",
              "4470  2.840264  2.868869      0.263836   2.909742   0.000000   \n",
              "\n",
              "      Standard Dev 1st diff  Median 1st diff  Standard Dev 2nd diff  \\\n",
              "4466               0.183625         0.002763               0.093909   \n",
              "4467               0.171018         0.000410               0.068237   \n",
              "4468               0.102151         0.000678               0.043690   \n",
              "4469               0.014701        -0.000828               0.009593   \n",
              "4470               0.257542        -0.000595               0.258572   \n",
              "\n",
              "      Total Area    Kurtosis  ...        Power  99% Bandwidth  \\\n",
              "4466  174.826977    1.231085  ...   447.202123       0.517393   \n",
              "4467   63.761552    3.701841  ...   145.465354       0.969150   \n",
              "4468  292.429905    3.509624  ...   850.749576       0.402680   \n",
              "4469  350.382482   10.605559  ...  1040.473268       0.016502   \n",
              "4470  339.376835  113.812119  ...   976.335639       0.806445   \n",
              "\n",
              "      Top Bandwidth Frequency  Phasic mean  Phasic Stdev  Phasic AuC  \\\n",
              "4466                 0.517538     2.650141      3.726599   78.992107   \n",
              "4467                 0.969496     1.919576      2.938044   54.869583   \n",
              "4468                 0.402778     1.049711      1.670153   31.491325   \n",
              "4469                 0.016585     0.072713      0.296073    2.045646   \n",
              "4470                 0.806529     0.539952      1.058184   16.198553   \n",
              "\n",
              "      Tonic mean  Tonic Stdev   Tonic AuC  State  \n",
              "4466   -3.209107     1.263214  -95.019918      1  \n",
              "4467   -3.763126     1.339107 -111.580315      1  \n",
              "4468   -0.741003     1.967254  -21.775323      1  \n",
              "4469    1.257076     0.145131   37.424606      1  \n",
              "4470    0.802859     0.775748   23.916348      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943dd167-7b22-4994-b1a4-4fdfd511c5c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Standard Dev</th>\n",
              "      <th>Max Value</th>\n",
              "      <th>Min Value</th>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <th>Median 1st diff</th>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <th>Total Area</th>\n",
              "      <th>Kurtosis</th>\n",
              "      <th>...</th>\n",
              "      <th>Power</th>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <th>Phasic mean</th>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <th>Phasic AuC</th>\n",
              "      <th>Tonic mean</th>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <th>Tonic AuC</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>1.466113</td>\n",
              "      <td>1.566922</td>\n",
              "      <td>1.261131</td>\n",
              "      <td>3.142194</td>\n",
              "      <td>-0.076818</td>\n",
              "      <td>0.183625</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.093909</td>\n",
              "      <td>174.826977</td>\n",
              "      <td>1.231085</td>\n",
              "      <td>...</td>\n",
              "      <td>447.202123</td>\n",
              "      <td>0.517393</td>\n",
              "      <td>0.517538</td>\n",
              "      <td>2.650141</td>\n",
              "      <td>3.726599</td>\n",
              "      <td>78.992107</td>\n",
              "      <td>-3.209107</td>\n",
              "      <td>1.263214</td>\n",
              "      <td>-95.019918</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>0.540481</td>\n",
              "      <td>0.034924</td>\n",
              "      <td>0.963236</td>\n",
              "      <td>3.007747</td>\n",
              "      <td>-0.231767</td>\n",
              "      <td>0.171018</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.068237</td>\n",
              "      <td>63.761552</td>\n",
              "      <td>3.701841</td>\n",
              "      <td>...</td>\n",
              "      <td>145.465354</td>\n",
              "      <td>0.969150</td>\n",
              "      <td>0.969496</td>\n",
              "      <td>1.919576</td>\n",
              "      <td>2.938044</td>\n",
              "      <td>54.869583</td>\n",
              "      <td>-3.763126</td>\n",
              "      <td>1.339107</td>\n",
              "      <td>-111.580315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4468</th>\n",
              "      <td>2.449819</td>\n",
              "      <td>2.981136</td>\n",
              "      <td>1.047429</td>\n",
              "      <td>3.098601</td>\n",
              "      <td>0.061658</td>\n",
              "      <td>0.102151</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.043690</td>\n",
              "      <td>292.429905</td>\n",
              "      <td>3.509624</td>\n",
              "      <td>...</td>\n",
              "      <td>850.749576</td>\n",
              "      <td>0.402680</td>\n",
              "      <td>0.402778</td>\n",
              "      <td>1.049711</td>\n",
              "      <td>1.670153</td>\n",
              "      <td>31.491325</td>\n",
              "      <td>-0.741003</td>\n",
              "      <td>1.967254</td>\n",
              "      <td>-21.775323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4469</th>\n",
              "      <td>2.944428</td>\n",
              "      <td>2.946765</td>\n",
              "      <td>0.031031</td>\n",
              "      <td>3.030734</td>\n",
              "      <td>2.796635</td>\n",
              "      <td>0.014701</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>0.009593</td>\n",
              "      <td>350.382482</td>\n",
              "      <td>10.605559</td>\n",
              "      <td>...</td>\n",
              "      <td>1040.473268</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>0.016585</td>\n",
              "      <td>0.072713</td>\n",
              "      <td>0.296073</td>\n",
              "      <td>2.045646</td>\n",
              "      <td>1.257076</td>\n",
              "      <td>0.145131</td>\n",
              "      <td>37.424606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4470</th>\n",
              "      <td>2.840264</td>\n",
              "      <td>2.868869</td>\n",
              "      <td>0.263836</td>\n",
              "      <td>2.909742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257542</td>\n",
              "      <td>-0.000595</td>\n",
              "      <td>0.258572</td>\n",
              "      <td>339.376835</td>\n",
              "      <td>113.812119</td>\n",
              "      <td>...</td>\n",
              "      <td>976.335639</td>\n",
              "      <td>0.806445</td>\n",
              "      <td>0.806529</td>\n",
              "      <td>0.539952</td>\n",
              "      <td>1.058184</td>\n",
              "      <td>16.198553</td>\n",
              "      <td>0.802859</td>\n",
              "      <td>0.775748</td>\n",
              "      <td>23.916348</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943dd167-7b22-4994-b1a4-4fdfd511c5c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "raw_dataset.tail() # muestra las últimas 5 filas por defecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Cqjf_xnwpw"
      },
      "outputs": [],
      "source": [
        "raw_dataset.head() # muestra las primeras 5 filas por defecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9-FGkx3glzZ"
      },
      "source": [
        "## 3. Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBXjhOwa_eFh"
      },
      "source": [
        "### 3.1. Extracción de los conjuntos de entrenamiento, prueba y validación\n",
        "\n",
        "*   Datos de **entrenamiento**: para el aprendizaje de parámetros.\n",
        "*   Datos de **prueba**: para hacer test de predicciones.\n",
        "*   Datos de **validación**: para afinar hiperparámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wtq9cEZV_V-m"
      },
      "outputs": [],
      "source": [
        "# Extracción de subconjuntos: bloque de código para mantener la proporción de clases\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = raw_dataset.drop('State', axis=1)\n",
        "labels = raw_dataset['State']\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "FekCNTKP_WBI",
        "outputId": "8c83c799-2ae8-454d-ba0c-c6abf6c0c735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count         mean          std           min  \\\n",
              "Mean                     3159.0     1.461257     2.688161  2.881417e-04   \n",
              "Median                   3159.0     1.466649     2.710469  0.000000e+00   \n",
              "Standard Dev             3159.0     0.144952     0.381106  4.706701e-04   \n",
              "Max Value                3159.0     1.704078     2.942718  4.779257e-03   \n",
              "Min Value                3159.0     1.193842     2.469216  0.000000e+00   \n",
              "Standard Dev 1st diff    3159.0     0.022006     0.039530  3.494808e-04   \n",
              "Median 1st diff          3159.0    -0.000315     0.003921 -1.093078e-01   \n",
              "Standard Dev 2nd diff    3159.0     0.018383     0.029861  4.191872e-04   \n",
              "Total Area               3159.0   173.890366   319.923866  3.457700e-02   \n",
              "Kurtosis                 3159.0     5.549862     7.382169  1.057126e+00   \n",
              "SCR                      3159.0     1.063944     2.344673  0.000000e+00   \n",
              "Power                    3159.0  1142.881747  3839.609331  1.060477e-04   \n",
              "99% Bandwidth            3159.0     0.182056     0.350587  1.650002e-02   \n",
              "Top Bandwidth Frequency  3159.0     0.182157     0.350636  1.658335e-02   \n",
              "Phasic mean              3159.0     0.606996     1.303538  4.475971e-08   \n",
              "Phasic Stdev             3159.0     0.966032     1.883792  1.652074e-08   \n",
              "Phasic AuC               3159.0    18.063914    38.840793  1.331816e-06   \n",
              "Tonic mean               3159.0    -0.782682     1.836786 -2.952807e+01   \n",
              "Tonic Stdev              3159.0     0.433241     0.832538  1.055206e-04   \n",
              "Tonic AuC                3159.0   -23.288679    54.738380 -8.829021e+02   \n",
              "\n",
              "                               25%        50%         75%           max  \n",
              "Mean                      0.249013   0.433919    1.120415     16.873588  \n",
              "Median                    0.241514   0.431638    1.125672     17.060042  \n",
              "Standard Dev              0.005087   0.024107    0.121097      6.510492  \n",
              "Max Value                 0.293813   0.496918    1.504204     17.572616  \n",
              "Min Value                 0.140055   0.314706    0.660940     16.098618  \n",
              "Standard Dev 1st diff     0.001248   0.005013    0.023161      0.471897  \n",
              "Median 1st diff          -0.000351  -0.000024    0.000155      0.048991  \n",
              "Standard Dev 2nd diff     0.001694   0.004379    0.020992      0.258629  \n",
              "Total Area               29.601951  51.637832  133.571556   2013.300593  \n",
              "Kurtosis                  2.075404   2.857487    5.505709    113.896441  \n",
              "SCR                       0.000000   0.000000    1.000000     24.000000  \n",
              "Power                     7.913682  23.449923  171.273761  34363.988284  \n",
              "99% Bandwidth             0.016504   0.016529    0.167778      1.982856  \n",
              "Top Bandwidth Frequency   0.016587   0.016612    0.167895      1.983451  \n",
              "Phasic mean               0.018716   0.101285    0.523234     21.397006  \n",
              "Phasic Stdev              0.053579   0.223113    0.967546     35.095213  \n",
              "Phasic AuC                0.551897   2.997145   15.523808    638.941089  \n",
              "Tonic mean               -1.153674  -0.500970    0.136751      3.422684  \n",
              "Tonic Stdev               0.027316   0.098597    0.515756     16.795811  \n",
              "Tonic AuC               -34.324767 -14.913256    4.080784    101.863348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-666ea658-885c-4bfa-99e9-7bccea74cb78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.461257</td>\n",
              "      <td>2.688161</td>\n",
              "      <td>2.881417e-04</td>\n",
              "      <td>0.249013</td>\n",
              "      <td>0.433919</td>\n",
              "      <td>1.120415</td>\n",
              "      <td>16.873588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.466649</td>\n",
              "      <td>2.710469</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.241514</td>\n",
              "      <td>0.431638</td>\n",
              "      <td>1.125672</td>\n",
              "      <td>17.060042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.144952</td>\n",
              "      <td>0.381106</td>\n",
              "      <td>4.706701e-04</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.024107</td>\n",
              "      <td>0.121097</td>\n",
              "      <td>6.510492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.704078</td>\n",
              "      <td>2.942718</td>\n",
              "      <td>4.779257e-03</td>\n",
              "      <td>0.293813</td>\n",
              "      <td>0.496918</td>\n",
              "      <td>1.504204</td>\n",
              "      <td>17.572616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.193842</td>\n",
              "      <td>2.469216</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.314706</td>\n",
              "      <td>0.660940</td>\n",
              "      <td>16.098618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.022006</td>\n",
              "      <td>0.039530</td>\n",
              "      <td>3.494808e-04</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0.023161</td>\n",
              "      <td>0.471897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>-1.093078e-01</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.048991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>0.029861</td>\n",
              "      <td>4.191872e-04</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.258629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>173.890366</td>\n",
              "      <td>319.923866</td>\n",
              "      <td>3.457700e-02</td>\n",
              "      <td>29.601951</td>\n",
              "      <td>51.637832</td>\n",
              "      <td>133.571556</td>\n",
              "      <td>2013.300593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.549862</td>\n",
              "      <td>7.382169</td>\n",
              "      <td>1.057126e+00</td>\n",
              "      <td>2.075404</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>5.505709</td>\n",
              "      <td>113.896441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.063944</td>\n",
              "      <td>2.344673</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1142.881747</td>\n",
              "      <td>3839.609331</td>\n",
              "      <td>1.060477e-04</td>\n",
              "      <td>7.913682</td>\n",
              "      <td>23.449923</td>\n",
              "      <td>171.273761</td>\n",
              "      <td>34363.988284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182056</td>\n",
              "      <td>0.350587</td>\n",
              "      <td>1.650002e-02</td>\n",
              "      <td>0.016504</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.167778</td>\n",
              "      <td>1.982856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182157</td>\n",
              "      <td>0.350636</td>\n",
              "      <td>1.658335e-02</td>\n",
              "      <td>0.016587</td>\n",
              "      <td>0.016612</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>1.983451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.606996</td>\n",
              "      <td>1.303538</td>\n",
              "      <td>4.475971e-08</td>\n",
              "      <td>0.018716</td>\n",
              "      <td>0.101285</td>\n",
              "      <td>0.523234</td>\n",
              "      <td>21.397006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.966032</td>\n",
              "      <td>1.883792</td>\n",
              "      <td>1.652074e-08</td>\n",
              "      <td>0.053579</td>\n",
              "      <td>0.223113</td>\n",
              "      <td>0.967546</td>\n",
              "      <td>35.095213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>18.063914</td>\n",
              "      <td>38.840793</td>\n",
              "      <td>1.331816e-06</td>\n",
              "      <td>0.551897</td>\n",
              "      <td>2.997145</td>\n",
              "      <td>15.523808</td>\n",
              "      <td>638.941089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.782682</td>\n",
              "      <td>1.836786</td>\n",
              "      <td>-2.952807e+01</td>\n",
              "      <td>-1.153674</td>\n",
              "      <td>-0.500970</td>\n",
              "      <td>0.136751</td>\n",
              "      <td>3.422684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.832538</td>\n",
              "      <td>1.055206e-04</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.098597</td>\n",
              "      <td>0.515756</td>\n",
              "      <td>16.795811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-23.288679</td>\n",
              "      <td>54.738380</td>\n",
              "      <td>-8.829021e+02</td>\n",
              "      <td>-34.324767</td>\n",
              "      <td>-14.913256</td>\n",
              "      <td>4.080784</td>\n",
              "      <td>101.863348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-666ea658-885c-4bfa-99e9-7bccea74cb78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-666ea658-885c-4bfa-99e9-7bccea74cb78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-666ea658-885c-4bfa-99e9-7bccea74cb78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cba90fc4-5ff5-4e30-8085-4e07c0d8b015\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cba90fc4-5ff5-4e30-8085-4e07c0d8b015')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cba90fc4-5ff5-4e30-8085-4e07c0d8b015 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_df95927e-a9f0-41d9-9d71-bc36d745292d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_df95927e-a9f0-41d9-9d71-bc36d745292d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_stats",
              "summary": "{\n  \"name\": \"train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.43774243066844,\n        \"min\": -23.288679302492756,\n        \"max\": 1142.8817465910665,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.4612569864023432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856.3494010607636,\n        \"min\": 0.003920865966528552,\n        \"max\": 3839.6093312957755,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.688160769255659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.1982611498348,\n        \"min\": -882.902109713819,\n        \"max\": 1.05712563449178,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0002881416666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.567138491113965,\n        \"min\": -34.3247668007665,\n        \"max\": 29.601950522781898,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.24901303990454848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.034024453837553,\n        \"min\": -14.9132560124876,\n        \"max\": 51.6378323985219,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.43391925352509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.88127532395101,\n        \"min\": 0.000155043576272,\n        \"max\": 171.27376076324,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.120414963183705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7661.905667264518,\n        \"min\": 0.0489910736836237,\n        \"max\": 34363.988283576,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          16.873587916458\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_size = train_dataset.shape\n",
        "test_size = test_dataset.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syU3bAgjhaZb"
      },
      "source": [
        "### 3.2. Normalización y estandarización de todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "V6-D516VCSUe",
        "outputId": "d4cc24c1-8c8b-4dc5-e9ae-192d7cf66dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count          mean  std        min       25%  \\\n",
              "Mean                     3159.0  8.997059e-18  1.0  -0.543483 -0.450957   \n",
              "Median                   3159.0 -1.462022e-17  1.0  -0.541105 -0.452001   \n",
              "Standard Dev             3159.0  6.410405e-17  1.0  -0.379110 -0.366997   \n",
              "Max Value                3159.0 -3.261434e-17  1.0  -0.577459 -0.479239   \n",
              "Min Value                3159.0  1.349559e-17  1.0  -0.483490 -0.426770   \n",
              "Standard Dev 1st diff    3159.0  8.997059e-17  1.0  -0.547850 -0.525124   \n",
              "Median 1st diff          3159.0  8.997059e-18  1.0 -27.798013 -0.008976   \n",
              "Standard Dev 2nd diff    3159.0  1.012169e-16  1.0  -0.601592 -0.558901   \n",
              "Total Area               3159.0 -1.135879e-16  1.0  -0.543429 -0.451009   \n",
              "Kurtosis                 3159.0 -5.848088e-17  1.0  -0.608593 -0.470655   \n",
              "SCR                      3159.0 -3.036507e-17  1.0  -0.453771 -0.453771   \n",
              "Power                    3159.0 -2.249265e-17  1.0  -0.297656 -0.295595   \n",
              "99% Bandwidth            3159.0 -2.474191e-17  1.0  -0.472226 -0.472214   \n",
              "Top Bandwidth Frequency  3159.0 -6.185478e-18  1.0  -0.472211 -0.472199   \n",
              "Phasic mean              3159.0 -2.305496e-17  1.0  -0.465652 -0.451294   \n",
              "Phasic Stdev             3159.0  5.623162e-19  1.0  -0.512813 -0.484370   \n",
              "Phasic AuC               3159.0 -1.433906e-17  1.0  -0.465076 -0.450867   \n",
              "Tonic mean               3159.0 -5.117077e-17  1.0 -15.649830 -0.201979   \n",
              "Tonic Stdev              3159.0  2.924044e-17  1.0  -0.520259 -0.487576   \n",
              "Tonic AuC                3159.0 -6.579099e-17  1.0 -15.704035 -0.201615   \n",
              "\n",
              "                              50%       75%        max  \n",
              "Mean                    -0.382171 -0.126794   5.733411  \n",
              "Median                  -0.381857 -0.125800   5.753023  \n",
              "Standard Dev            -0.317089 -0.062595  16.702809  \n",
              "Max Value               -0.410220 -0.067921   5.392477  \n",
              "Min Value               -0.356038 -0.215818   6.036239  \n",
              "Standard Dev 1st diff   -0.429885  0.029211  11.380875  \n",
              "Median 1st diff          0.074262  0.120010  12.575429  \n",
              "Standard Dev 2nd diff   -0.468976  0.087356   8.045450  \n",
              "Total Area              -0.382130 -0.126026   5.749525  \n",
              "Kurtosis                -0.364713 -0.005981  14.676795  \n",
              "SCR                     -0.453771 -0.027272   9.782197  \n",
              "Power                   -0.291548 -0.253049   8.652210  \n",
              "99% Bandwidth           -0.472143 -0.040728   5.136521  \n",
              "Top Bandwidth Frequency -0.472128 -0.040677   5.137217  \n",
              "Phasic mean             -0.387952 -0.064257  15.948907  \n",
              "Phasic Stdev            -0.394374  0.000804  18.117274  \n",
              "Phasic AuC              -0.387911 -0.065398  15.985183  \n",
              "Tonic mean               0.153372  0.500566   2.289524  \n",
              "Tonic Stdev             -0.401957  0.099112  19.653834  \n",
              "Tonic AuC                0.153008  0.500005   2.286367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f092864a-5cb5-4995-93fe-980728850f64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543483</td>\n",
              "      <td>-0.450957</td>\n",
              "      <td>-0.382171</td>\n",
              "      <td>-0.126794</td>\n",
              "      <td>5.733411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.462022e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.541105</td>\n",
              "      <td>-0.452001</td>\n",
              "      <td>-0.381857</td>\n",
              "      <td>-0.125800</td>\n",
              "      <td>5.753023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>6.410405e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.379110</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-0.317089</td>\n",
              "      <td>-0.062595</td>\n",
              "      <td>16.702809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.261434e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.577459</td>\n",
              "      <td>-0.479239</td>\n",
              "      <td>-0.410220</td>\n",
              "      <td>-0.067921</td>\n",
              "      <td>5.392477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.349559e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.483490</td>\n",
              "      <td>-0.426770</td>\n",
              "      <td>-0.356038</td>\n",
              "      <td>-0.215818</td>\n",
              "      <td>6.036239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.547850</td>\n",
              "      <td>-0.525124</td>\n",
              "      <td>-0.429885</td>\n",
              "      <td>0.029211</td>\n",
              "      <td>11.380875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-27.798013</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.074262</td>\n",
              "      <td>0.120010</td>\n",
              "      <td>12.575429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.012169e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.601592</td>\n",
              "      <td>-0.558901</td>\n",
              "      <td>-0.468976</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>8.045450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.135879e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543429</td>\n",
              "      <td>-0.451009</td>\n",
              "      <td>-0.382130</td>\n",
              "      <td>-0.126026</td>\n",
              "      <td>5.749525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.848088e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.608593</td>\n",
              "      <td>-0.470655</td>\n",
              "      <td>-0.364713</td>\n",
              "      <td>-0.005981</td>\n",
              "      <td>14.676795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.036507e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.027272</td>\n",
              "      <td>9.782197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.249265e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.297656</td>\n",
              "      <td>-0.295595</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.253049</td>\n",
              "      <td>8.652210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.474191e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472226</td>\n",
              "      <td>-0.472214</td>\n",
              "      <td>-0.472143</td>\n",
              "      <td>-0.040728</td>\n",
              "      <td>5.136521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.185478e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472211</td>\n",
              "      <td>-0.472199</td>\n",
              "      <td>-0.472128</td>\n",
              "      <td>-0.040677</td>\n",
              "      <td>5.137217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.305496e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465652</td>\n",
              "      <td>-0.451294</td>\n",
              "      <td>-0.387952</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>15.948907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.623162e-19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.512813</td>\n",
              "      <td>-0.484370</td>\n",
              "      <td>-0.394374</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>18.117274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.433906e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465076</td>\n",
              "      <td>-0.450867</td>\n",
              "      <td>-0.387911</td>\n",
              "      <td>-0.065398</td>\n",
              "      <td>15.985183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.117077e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.649830</td>\n",
              "      <td>-0.201979</td>\n",
              "      <td>0.153372</td>\n",
              "      <td>0.500566</td>\n",
              "      <td>2.289524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>2.924044e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.520259</td>\n",
              "      <td>-0.487576</td>\n",
              "      <td>-0.401957</td>\n",
              "      <td>0.099112</td>\n",
              "      <td>19.653834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.579099e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.704035</td>\n",
              "      <td>-0.201615</td>\n",
              "      <td>0.153008</td>\n",
              "      <td>0.500005</td>\n",
              "      <td>2.286367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f092864a-5cb5-4995-93fe-980728850f64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f092864a-5cb5-4995-93fe-980728850f64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f092864a-5cb5-4995-93fe-980728850f64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6706ed9e-bb5f-401d-aedf-2364985ca980\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6706ed9e-bb5f-401d-aedf-2364985ca980')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6706ed9e-bb5f-401d-aedf-2364985ca980 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bbf80187-f49a-4a9f-939a-87ae690633a7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('normed_train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bbf80187-f49a-4a9f-939a-87ae690633a7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('normed_train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "normed_train_stats",
              "summary": "{\n  \"name\": \"normed_train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.130827903032307e-17,\n        \"min\": -1.13587870072444e-16,\n        \"max\": 1.012169139259402e-16,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          8.997059015639129e-18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1848847376991577e-14,\n        \"min\": 0.9999999999999469,\n        \"max\": 1.000000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9999999999999469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.397919147016072,\n        \"min\": -27.798013059723413,\n        \"max\": -0.2976557097171227,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.5434826895194267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13303447554408515,\n        \"min\": -0.5589012867384386,\n        \"max\": -0.008976423627184933,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.4509566393357717\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1982775721363611,\n        \"min\": -0.47214325593943735,\n        \"max\": 0.15337222439091985,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.3821712393941821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19358796580988194,\n        \"min\": -0.2530486572965829,\n        \"max\": 0.500566267762931,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.12679376438970055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4656321224551565,\n        \"min\": 2.2863670387300563,\n        \"max\": 19.653834404298966,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          5.733411150971922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "train_size = normed_train_data.shape\n",
        "test_size = normed_test_data.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "normed_train_stats = normed_train_data.describe()\n",
        "normed_train_stats = normed_train_stats.transpose()\n",
        "normed_train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmNpCfOqCwqv"
      },
      "source": [
        "## 4.1. Optimización masiva de parámetros\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_conv_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(hp.Int('hidden_blocks', min_value=1, max_value=4)):\n",
        "        filters = hp.Int(f'n_filters{i}', min_value=4, max_value=32, step=4)\n",
        "        kernel_size = hp.Choice(f'size{i}', values=[2, 3, 4, 5])\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))  # Valor fijo para la etapa 1\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_conv_model(HyperParameters())\n",
        "\n",
        "tuner_1 = kt.BayesianOptimization(\n",
        "    build_conv_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage1',\n",
        "    project_name='cnn1d_conv_structure'\n",
        ")\n",
        "\n",
        "#28min 30s sin GPU"
      ],
      "metadata": {
        "id": "U_quo4A8uaj8",
        "outputId": "df9965c0-4e89-4852-8767-634bc8de1dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_1.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=200,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp1 = tuner_1.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp1.values"
      ],
      "metadata": {
        "id": "xgJLDUbVGQrN",
        "outputId": "9eaebfe1-0361-4b5f-c5c1-741f19534d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.760284811258316\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7610759437084198\n",
            "Total elapsed time: 00h 02m 14s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "4                 |1                 |hidden_blocks\n",
            "32                |16                |n_filters0\n",
            "5                 |3                 |size0\n",
            "20                |None              |n_filters1\n",
            "2                 |None              |size1\n",
            "\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 267ms/step - binary_accuracy: 0.5885 - f1_score: 0.7603 - loss: 0.6984 - precision: 0.6322 - recall: 0.7855 - val_binary_accuracy: 0.5807 - val_f1_score: 0.7799 - val_loss: 0.6874 - val_precision: 0.6257 - val_recall: 0.8564\n",
            "Epoch 2/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - binary_accuracy: 0.6316 - f1_score: 0.7573 - loss: 0.6325 - precision: 0.6417 - recall: 0.8960 - val_binary_accuracy: 0.5997 - val_f1_score: 0.7799 - val_loss: 0.6814 - val_precision: 0.6396 - val_recall: 0.8564\n",
            "Epoch 3/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6683 - f1_score: 0.7607 - loss: 0.6148 - precision: 0.6688 - recall: 0.9096 - val_binary_accuracy: 0.6076 - val_f1_score: 0.7799 - val_loss: 0.6771 - val_precision: 0.6444 - val_recall: 0.8614\n",
            "Epoch 4/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6955 - f1_score: 0.7524 - loss: 0.6009 - precision: 0.6886 - recall: 0.9048 - val_binary_accuracy: 0.6092 - val_f1_score: 0.7799 - val_loss: 0.6748 - val_precision: 0.6495 - val_recall: 0.8441\n",
            "Epoch 5/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6730 - f1_score: 0.7577 - loss: 0.5969 - precision: 0.6744 - recall: 0.8980 - val_binary_accuracy: 0.6123 - val_f1_score: 0.7799 - val_loss: 0.6730 - val_precision: 0.6532 - val_recall: 0.8391\n",
            "Epoch 6/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6712 - f1_score: 0.7532 - loss: 0.5944 - precision: 0.6648 - recall: 0.9212 - val_binary_accuracy: 0.6028 - val_f1_score: 0.7799 - val_loss: 0.6723 - val_precision: 0.6515 - val_recall: 0.8144\n",
            "Epoch 7/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6813 - f1_score: 0.7468 - loss: 0.5855 - precision: 0.6995 - recall: 0.8154 - val_binary_accuracy: 0.6108 - val_f1_score: 0.7799 - val_loss: 0.6698 - val_precision: 0.6599 - val_recall: 0.8069\n",
            "Epoch 8/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7102 - f1_score: 0.7567 - loss: 0.5747 - precision: 0.7212 - recall: 0.8550 - val_binary_accuracy: 0.6139 - val_f1_score: 0.7799 - val_loss: 0.6667 - val_precision: 0.6587 - val_recall: 0.8218\n",
            "Epoch 9/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7127 - f1_score: 0.7577 - loss: 0.5616 - precision: 0.7141 - recall: 0.8823 - val_binary_accuracy: 0.6218 - val_f1_score: 0.7799 - val_loss: 0.6652 - val_precision: 0.6730 - val_recall: 0.7946\n",
            "Epoch 10/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7154 - f1_score: 0.7603 - loss: 0.5485 - precision: 0.7330 - recall: 0.8439 - val_binary_accuracy: 0.6187 - val_f1_score: 0.7799 - val_loss: 0.6618 - val_precision: 0.6694 - val_recall: 0.7970\n",
            "Epoch 11/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7182 - f1_score: 0.7569 - loss: 0.5438 - precision: 0.7370 - recall: 0.8366 - val_binary_accuracy: 0.6187 - val_f1_score: 0.7799 - val_loss: 0.6586 - val_precision: 0.6730 - val_recall: 0.7847\n",
            "Epoch 12/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7147 - f1_score: 0.7559 - loss: 0.5507 - precision: 0.7243 - recall: 0.8589 - val_binary_accuracy: 0.6297 - val_f1_score: 0.7799 - val_loss: 0.6523 - val_precision: 0.6742 - val_recall: 0.8144\n",
            "Epoch 13/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7262 - f1_score: 0.7568 - loss: 0.5488 - precision: 0.7301 - recall: 0.8739 - val_binary_accuracy: 0.6313 - val_f1_score: 0.7799 - val_loss: 0.6517 - val_precision: 0.6831 - val_recall: 0.7896\n",
            "Epoch 14/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7137 - f1_score: 0.7562 - loss: 0.5460 - precision: 0.7267 - recall: 0.8480 - val_binary_accuracy: 0.6250 - val_f1_score: 0.7799 - val_loss: 0.6524 - val_precision: 0.6819 - val_recall: 0.7748\n",
            "Epoch 15/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7367 - f1_score: 0.7566 - loss: 0.5229 - precision: 0.7390 - recall: 0.8773 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6461 - val_precision: 0.6947 - val_recall: 0.8168\n",
            "Epoch 16/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7393 - f1_score: 0.7515 - loss: 0.5199 - precision: 0.7490 - recall: 0.8533 - val_binary_accuracy: 0.6487 - val_f1_score: 0.7799 - val_loss: 0.6412 - val_precision: 0.6953 - val_recall: 0.8020\n",
            "Epoch 17/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7583 - f1_score: 0.7640 - loss: 0.5208 - precision: 0.7583 - recall: 0.8949 - val_binary_accuracy: 0.6582 - val_f1_score: 0.7799 - val_loss: 0.6260 - val_precision: 0.6950 - val_recall: 0.8292\n",
            "Epoch 18/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7444 - f1_score: 0.7664 - loss: 0.5124 - precision: 0.7682 - recall: 0.8436 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6246 - val_precision: 0.7051 - val_recall: 0.7871\n",
            "Epoch 19/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7437 - f1_score: 0.7638 - loss: 0.5133 - precision: 0.7563 - recall: 0.8640 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6194 - val_precision: 0.6956 - val_recall: 0.8144\n",
            "Epoch 20/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7458 - f1_score: 0.7694 - loss: 0.5139 - precision: 0.7656 - recall: 0.8552 - val_binary_accuracy: 0.6677 - val_f1_score: 0.7799 - val_loss: 0.6105 - val_precision: 0.7100 - val_recall: 0.8119\n",
            "Epoch 21/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7623 - f1_score: 0.7602 - loss: 0.4887 - precision: 0.7801 - recall: 0.8523 - val_binary_accuracy: 0.6693 - val_f1_score: 0.7799 - val_loss: 0.6012 - val_precision: 0.7327 - val_recall: 0.7599\n",
            "Epoch 22/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7523 - f1_score: 0.7738 - loss: 0.4950 - precision: 0.7808 - recall: 0.8443 - val_binary_accuracy: 0.6772 - val_f1_score: 0.7799 - val_loss: 0.6010 - val_precision: 0.7101 - val_recall: 0.8366\n",
            "Epoch 23/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7757 - f1_score: 0.7708 - loss: 0.4912 - precision: 0.7875 - recall: 0.8785 - val_binary_accuracy: 0.7009 - val_f1_score: 0.7799 - val_loss: 0.5762 - val_precision: 0.7483 - val_recall: 0.8020\n",
            "Epoch 24/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7716 - f1_score: 0.7626 - loss: 0.4691 - precision: 0.7760 - recall: 0.8849 - val_binary_accuracy: 0.7041 - val_f1_score: 0.7799 - val_loss: 0.5647 - val_precision: 0.7416 - val_recall: 0.8243\n",
            "Epoch 25/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7659 - f1_score: 0.7628 - loss: 0.4830 - precision: 0.7859 - recall: 0.8523 - val_binary_accuracy: 0.7247 - val_f1_score: 0.7799 - val_loss: 0.5578 - val_precision: 0.7457 - val_recall: 0.8639\n",
            "Epoch 26/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7707 - f1_score: 0.7608 - loss: 0.4669 - precision: 0.7920 - recall: 0.8505 - val_binary_accuracy: 0.6725 - val_f1_score: 0.7799 - val_loss: 0.5858 - val_precision: 0.7074 - val_recall: 0.8317\n",
            "Epoch 27/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7807 - f1_score: 0.7610 - loss: 0.4652 - precision: 0.7975 - recall: 0.8626 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5485 - val_precision: 0.7540 - val_recall: 0.8267\n",
            "Epoch 28/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7823 - f1_score: 0.7527 - loss: 0.4737 - precision: 0.7780 - recall: 0.8961 - val_binary_accuracy: 0.7104 - val_f1_score: 0.7799 - val_loss: 0.5650 - val_precision: 0.7600 - val_recall: 0.7995\n",
            "Epoch 29/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7577 - f1_score: 0.7527 - loss: 0.4841 - precision: 0.7834 - recall: 0.8263 - val_binary_accuracy: 0.7199 - val_f1_score: 0.7799 - val_loss: 0.5585 - val_precision: 0.7918 - val_recall: 0.7624\n",
            "Epoch 30/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7686 - f1_score: 0.7670 - loss: 0.4801 - precision: 0.7859 - recall: 0.8630 - val_binary_accuracy: 0.7009 - val_f1_score: 0.7799 - val_loss: 0.5589 - val_precision: 0.7822 - val_recall: 0.7376\n",
            "Epoch 31/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7783 - f1_score: 0.7547 - loss: 0.4536 - precision: 0.7944 - recall: 0.8561 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5448 - val_precision: 0.7563 - val_recall: 0.8218\n",
            "Epoch 32/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7783 - f1_score: 0.7607 - loss: 0.4490 - precision: 0.7857 - recall: 0.8781 - val_binary_accuracy: 0.7215 - val_f1_score: 0.7799 - val_loss: 0.5496 - val_precision: 0.7780 - val_recall: 0.7896\n",
            "Epoch 33/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7850 - f1_score: 0.7548 - loss: 0.4568 - precision: 0.8022 - recall: 0.8568 - val_binary_accuracy: 0.7247 - val_f1_score: 0.7799 - val_loss: 0.5423 - val_precision: 0.7964 - val_recall: 0.7649\n",
            "Epoch 34/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7748 - f1_score: 0.7478 - loss: 0.4663 - precision: 0.8118 - recall: 0.8130 - val_binary_accuracy: 0.7073 - val_f1_score: 0.7799 - val_loss: 0.5510 - val_precision: 0.7844 - val_recall: 0.7475\n",
            "Epoch 35/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.7964 - f1_score: 0.7626 - loss: 0.4465 - precision: 0.8251 - recall: 0.8500 - val_binary_accuracy: 0.7263 - val_f1_score: 0.7799 - val_loss: 0.5435 - val_precision: 0.7954 - val_recall: 0.7698\n",
            "Epoch 36/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7924 - f1_score: 0.7669 - loss: 0.4471 - precision: 0.8158 - recall: 0.8605 - val_binary_accuracy: 0.7152 - val_f1_score: 0.7799 - val_loss: 0.5460 - val_precision: 0.7732 - val_recall: 0.7847\n",
            "Epoch 37/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7928 - f1_score: 0.7644 - loss: 0.4332 - precision: 0.8098 - recall: 0.8697 - val_binary_accuracy: 0.7326 - val_f1_score: 0.7799 - val_loss: 0.5414 - val_precision: 0.7752 - val_recall: 0.8193\n",
            "Epoch 38/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.7944 - f1_score: 0.7558 - loss: 0.4339 - precision: 0.8164 - recall: 0.8535 - val_binary_accuracy: 0.7500 - val_f1_score: 0.7799 - val_loss: 0.5383 - val_precision: 0.7733 - val_recall: 0.8614\n",
            "Epoch 39/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8069 - f1_score: 0.7547 - loss: 0.4140 - precision: 0.8198 - recall: 0.8732 - val_binary_accuracy: 0.7294 - val_f1_score: 0.7799 - val_loss: 0.5457 - val_precision: 0.7920 - val_recall: 0.7822\n",
            "Epoch 40/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7920 - f1_score: 0.7565 - loss: 0.4280 - precision: 0.8230 - recall: 0.8389 - val_binary_accuracy: 0.7342 - val_f1_score: 0.7799 - val_loss: 0.5381 - val_precision: 0.7757 - val_recall: 0.8218\n",
            "Epoch 41/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8051 - f1_score: 0.7547 - loss: 0.4166 - precision: 0.8163 - recall: 0.8759 - val_binary_accuracy: 0.7089 - val_f1_score: 0.7799 - val_loss: 0.5454 - val_precision: 0.7989 - val_recall: 0.7277\n",
            "Epoch 42/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8112 - f1_score: 0.7703 - loss: 0.4176 - precision: 0.8292 - recall: 0.8800 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5407 - val_precision: 0.7650 - val_recall: 0.8540\n",
            "Epoch 43/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8087 - f1_score: 0.7490 - loss: 0.4158 - precision: 0.8188 - recall: 0.8758 - val_binary_accuracy: 0.7405 - val_f1_score: 0.7799 - val_loss: 0.5417 - val_precision: 0.7575 - val_recall: 0.8738\n",
            "Epoch 44/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7978 - f1_score: 0.7500 - loss: 0.4220 - precision: 0.8006 - recall: 0.8838 - val_binary_accuracy: 0.7453 - val_f1_score: 0.7799 - val_loss: 0.5332 - val_precision: 0.7670 - val_recall: 0.8639\n",
            "Epoch 45/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8198 - f1_score: 0.7574 - loss: 0.3960 - precision: 0.8395 - recall: 0.8710 - val_binary_accuracy: 0.7310 - val_f1_score: 0.7799 - val_loss: 0.5651 - val_precision: 0.7623 - val_recall: 0.8416\n",
            "Epoch 46/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7999 - f1_score: 0.7527 - loss: 0.4060 - precision: 0.8179 - recall: 0.8600 - val_binary_accuracy: 0.7405 - val_f1_score: 0.7799 - val_loss: 0.5390 - val_precision: 0.7857 - val_recall: 0.8168\n",
            "Epoch 47/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8089 - f1_score: 0.7556 - loss: 0.4028 - precision: 0.8226 - recall: 0.8733 - val_binary_accuracy: 0.7073 - val_f1_score: 0.7799 - val_loss: 0.5689 - val_precision: 0.7844 - val_recall: 0.7475\n",
            "Epoch 48/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7974 - f1_score: 0.7556 - loss: 0.4179 - precision: 0.8347 - recall: 0.8310 - val_binary_accuracy: 0.7468 - val_f1_score: 0.7799 - val_loss: 0.5491 - val_precision: 0.7748 - val_recall: 0.8515\n",
            "Epoch 49/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8032 - f1_score: 0.7464 - loss: 0.4165 - precision: 0.8181 - recall: 0.8612 - val_binary_accuracy: 0.7278 - val_f1_score: 0.7799 - val_loss: 0.5537 - val_precision: 0.7886 - val_recall: 0.7847\n",
            "Epoch 50/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8158 - f1_score: 0.7638 - loss: 0.3847 - precision: 0.8301 - recall: 0.8825 - val_binary_accuracy: 0.7263 - val_f1_score: 0.7799 - val_loss: 0.5547 - val_precision: 0.8016 - val_recall: 0.7599\n",
            "Epoch 51/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8194 - f1_score: 0.7592 - loss: 0.3883 - precision: 0.8299 - recall: 0.8868 - val_binary_accuracy: 0.7342 - val_f1_score: 0.7799 - val_loss: 0.5448 - val_precision: 0.7744 - val_recall: 0.8243\n",
            "Epoch 52/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8194 - f1_score: 0.7480 - loss: 0.3904 - precision: 0.8291 - recall: 0.8794 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5858 - val_precision: 0.7922 - val_recall: 0.8020\n",
            "Epoch 53/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8271 - f1_score: 0.7634 - loss: 0.3725 - precision: 0.8348 - recall: 0.8972 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5579 - val_precision: 0.7852 - val_recall: 0.8144\n",
            "Epoch 54/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8251 - f1_score: 0.7633 - loss: 0.3718 - precision: 0.8248 - recall: 0.9096 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5951 - val_precision: 0.7792 - val_recall: 0.7772\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1127897549>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tuner_1.search(normed_train_data, train_labels,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    115\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The model does not have any trainable weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;31m# Run update step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3005\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m       return self._replica_ctx_update(\n\u001b[0m\u001b[1;32m   3008\u001b[0m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[1;32m   3009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2884\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3476\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3477\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3483\u001b[0m         _CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3484\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ):\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             ops.divide(\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             ),\n\u001b[1;32m    150\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\u001b[0m in \u001b[0;36msparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;31m# x2 is an IndexedSlices, densify.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msparse_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   3938\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    491\u001b[0m         \"AddV2\", x=x, y=y, name=name)\n\u001b[1;32m    492\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     return super()._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m       ret = Operation.from_node_def(\n\u001b[0m\u001b[1;32m   2702\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mfrom_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       if not all(\n\u001b[0m\u001b[1;32m   1175\u001b[0m           x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):\n\u001b[1;32m   1176\u001b[0m         raise TypeError(\"In op '%s', input types (%s) are not compatible \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       if not all(\n\u001b[0m\u001b[1;32m   1175\u001b[0m           x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):\n\u001b[1;32m   1176\u001b[0m         raise TypeError(\"In op '%s', input types (%s) are not compatible \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(best_hp1.get('hidden_blocks')):\n",
        "        filters = best_hp1.get(f'n_filters{i}')\n",
        "        kernel_size = best_hp1.get(f'size{i}')\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Aquí ajustamos solo los parámetros nuevos\n",
        "    dense_units = hp.Int('dense_units', min_value=16, max_value=128, step=8)\n",
        "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_final_model(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner_2 = kt.BayesianOptimization(\n",
        "    build_final_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage2',\n",
        "    project_name='cnn1d_dense_lr_batch'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "6DnGkCSIvH_h",
        "outputId": "0763117c-93aa-4313-ec4e-78ae6573516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │         \u001b[38;5;34m1,372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │           \u001b[38;5;34m112\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m5,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,101\u001b[0m (35.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,101</span> (35.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,981\u001b[0m (35.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,981</span> (35.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage2/cnn1d_dense_lr_batch/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_2.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
        "                    batch_size=kt.HyperParameters().Choice('batch_size', [128, 358, 537]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okut5Zt2GmPF",
        "outputId": "b6224996-120f-40e7-8d9a-2c09ada59879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.7332402169704437\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7618715167045593\n",
            "Total elapsed time: 01h 42m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp2 = tuner_2.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp2.values"
      ],
      "metadata": {
        "id": "w1IQLia14ibr",
        "outputId": "ee370ad5-4952-4a00-b0e0-2451b05df689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_units': 40, 'learning_rate': 0.0004578995948758916}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNb7pcumf33T"
      },
      "source": [
        "## 4.2. Optimización de hiperparámetros del mejor modelo conseguido"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_model_C1(hp):\n",
        "  model = Sequential()\n",
        "  filters1 = hp.Int('nfilters1', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters1, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters2 = hp.Int('nfilters2', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters2, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters3 = hp.Int('nfilters3', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters3, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Flatten())\n",
        "  dense_units = hp.Int('dense_units', min_value=16, max_value=64, step=4)\n",
        "  model.add(layers.Dense(dense_units, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "   # compilación del modelo\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "  return model\n",
        "\n",
        "model = build_model_C1(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model_C1,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning_stage',\n",
        "    project_name='TFG'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "KHuAnr0MfWC7",
        "outputId": "059a5330-06b0-449b-c789-7868f4b36636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,477\u001b[0m (5.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,477</span> (5.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,453\u001b[0m (5.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,453</span> (5.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage/TFG/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1T1WwGjonc",
        "outputId": "e77238f5-1c17-4c36-82ce-f681bd90a235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 27s]\n",
            "val_binary_accuracy: 0.7667597532272339\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7891061305999756\n",
            "Total elapsed time: 01h 01m 48s\n",
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nfilters1': 64, 'nfilters2': 52, 'nfilters3': 56, 'dense_units': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Optimización bayesiana de learning rate y optimizador\n",
        "\n",
        "Mercedes no utilizó validación cruzada; realmente no parece que haga falta porque el dataset no es tan pequeño (supera las 1000 muestras)"
      ],
      "metadata": {
        "id": "rjQqaNgvECTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Asegúrate de tener normed_train_data, train_labels definidos antes de esto\n",
        "\n",
        "# Añadir dimensión para Conv1D\n",
        "#X = np.expand_dims(normed_train_data.values, axis=2)\n",
        "#y = train_labels.values\n",
        "\n",
        "# Función de construcción del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,  # Número de combinaciones a probar\n",
        "    directory='bayesian_opt',\n",
        "    project_name='cnn_lr_opt'\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy',\n",
        "    patience=10, # Número de épocas sin mejora\n",
        "    restore_best_weights=True # Restaurar los pesos del modelo con la mejor val_loss\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500,\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# Muestra los mejores resultados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")"
      ],
      "metadata": {
        "id": "BD55-165EBGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización bayesiana intermedia"
      ],
      "metadata": {
        "id": "Y6CTLXLOdEma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Asegúrate de tener normed_train_data, train_labels definidos antes de esto\n",
        "\n",
        "# Añadir dimensión para Conv1D\n",
        "#X = np.expand_dims(normed_train_data.values, axis=2)\n",
        "#y = train_labels.values\n",
        "\n",
        "# Función de construcción del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18,\n",
        "                            hp.Int('size_conv3', min_value=2, max_value=6, step=1),\n",
        "                            padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(hp.Int('number_dense', min_value=16, max_value=64, step=4),\n",
        "                           activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,  # Número de combinaciones a probar\n",
        "    directory='bayesian_opt',\n",
        "    project_name='cnn_lr_opt'\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy',\n",
        "    patience=10, # Número de épocas sin mejora\n",
        "    restore_best_weights=True # Restaurar los pesos del modelo con la mejor val_loss\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500,\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# Muestra los mejores resultados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor tamaño de filtro: {best_hps.get('size_conv3')}\")\n",
        "print(f\"Mejor número de neuronas: {best_hps.get('number_dense')}\")\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")"
      ],
      "metadata": {
        "id": "4kWRzXBAdIPL",
        "outputId": "765d814b-1a90-4703-f316-9548becc7400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 21s]\n",
            "val_binary_accuracy: 0.41613924503326416\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.8037974834442139\n",
            "Total elapsed time: 00h 30m 17s\n",
            "Mejor optimizador: nadam\n",
            "Mejor learning rate: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NojFTse1dHJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Optimización bayesiana más completa"
      ],
      "metadata": {
        "id": "-pjdu1IsCHBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación simple"
      ],
      "metadata": {
        "id": "57WFLZh_C0k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations # activations is not strictly needed but was in original imports\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from keras_tuner import HyperParameters\n",
        "from sklearn.model_selection import train_test_split # Not used for the final explicit split, but kept from original\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "\n",
        "# Función de construcción del modelo con hiperparámetros extendidos\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Hiperparámetro: Regularización L2 para todas las capas convolucionales y densas\n",
        "    #hp_l2_reg = hp.Float('l2_reg', min_value=1e-6, max_value=1e-2, sampling='log')\n",
        "\n",
        "    # Capa Conv1D 1\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv1_filters', min_value=16, max_value=64, step=8), 2,\n",
        "        strides=1, padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg),\n",
        "        input_shape=(normed_train_data.shape[1], 1)\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv1', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    # Capa Conv1D 2\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv2_filters', min_value=16, max_value=64, step=8), 3,\n",
        "        padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg)\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv2', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    # Capa Conv1D 3\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv3_filters', min_value=16, max_value=64, step=8),\n",
        "        hp.Int('size_conv3_kernel', min_value=2, max_value=5, step=1),\n",
        "        padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg) # L2 Regularization\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv3', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(\n",
        "        hp.Int('dense_units', min_value=16, max_value=128, step=8),\n",
        "        activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg) # L2 Regularization\n",
        "    ))\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_dense', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    #hp_batch = hp.Choice('batch_size', [32, 64, 128, 256, ceil(train_size[0]*0.1)])\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score(name='f1_score')])\n",
        "    return model\n",
        "\n",
        "print(\"\\n==================== 📈 Optimización de Hiperparámetros (Validación Simple Mejorada) ====================\")\n",
        "\n",
        "# Re-modelar los datos de entrada para Conv1D (muestras, pasos, canales)\n",
        "# Los datos originales son (muestras, características)\n",
        "X_train_reshaped = np.expand_dims(normed_train_data.values, axis=2)\n",
        "X_test_reshaped = np.expand_dims(normed_test_data.values, axis=2)\n",
        "\n",
        "# 2. Configurar e iniciar Keras Tuner para la optimización de hiperparámetros\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    directory='keras_tuner_results_improved',\n",
        "    project_name='simple_split_optimization_improved',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy',\n",
        "    patience=15, # Número de épocas sin mejora\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500, # Max. épocas, early stopping lo detendrá antes si converge\n",
        "             # Ahora, el batch_size es un hiperparámetro. tuner.search lo gestionará internamente.\n",
        "             # Si se quisiera establecer un batch_size fijo aquí, se haría así:\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# 3. Obtener los mejores hiperparámetros encontrados\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"✅ Mejores Hiperparámetros Encontrados:\")\n",
        "print(f\"  Optimizador: {best_hp.get('optimizer')}\")\n",
        "print(f\"  Tasa de Aprendizaje: {best_hp.get('learning_rate'):.1e}\")\n",
        "print(f\"  Filtros Conv1: {best_hp.get('conv1_filters')}\")\n",
        "print(f\"  Filtros Conv2: {best_hp.get('conv2_filters')}\")\n",
        "print(f\"  Filtros Conv3: {best_hp.get('conv3_filters')}\")\n",
        "print(f\"  Unidades Dense: {best_hp.get('dense_units')}\")\n",
        "print(f\"  Dropout Conv: {best_hp.get('dropout_rate_conv1'):.2f} (ejemplo)\") # Se asume una tasa común para las tres capas Conv\n",
        "print(f\"  Dropout Dense: {best_hp.get('dropout_rate_dense'):.2f}\")\n",
        "print(f\"  L2 Reg: {best_hp.get('l2_reg'):.1e}\")\n",
        "print(f\"  Batch Size: {best_hp.get('batch_size')}\")"
      ],
      "metadata": {
        "id": "zhUc_U9qeD4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfftlXWEG-e"
      },
      "source": [
        "## 5. Entrenamiento y validación del modelo\n",
        "\n",
        "Reservamos el 20% de los datos de entrenamiento para la validación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Construir y entrenar el modelo final con los mejores HP en todo el conjunto de entrenamiento\n",
        "# (X_train_reshaped y train_labels)\n",
        "print(\"\\nEntrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento completo...\")\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor tamaño de filtro: {best_hps.get('size_conv3')}\")\n",
        "print(f\"Mejor número de neuronas: {best_hps.get('number_dense')}\")\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "final_model = tuner.hypermodel.build(best_hp)\n",
        "final_model.fit(normed_train_data, train_labels,\n",
        "                epochs=1000, # Max. épocas, early stopping lo detendrá\n",
        "                #batch_size=best_hp.get('batch_size'), # Usar el batch_size óptimo\n",
        "                batch_size=ceil(train_size[0]*0.1),\n",
        "                callbacks=[early_stopping_callback],\n",
        "                verbose=1) # Poner en 1 para ver el progreso del entrenamiento final\n",
        "\n",
        "# 5. Evaluar el modelo final en el conjunto de prueba independiente (normed_test_data)\n",
        "print(\"\\n==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\")\n",
        "#y_pred_probs = final_model.predict(normed_test_data)\n",
        "#y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "# Calcular métricas finales\n",
        "#acc = accuracy_score(test_labels, y_pred)\n",
        "#prec = precision_score(test_labels, y_pred)\n",
        "#rec = recall_score(test_labels, y_pred)\n",
        "#f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = final_model.evaluate(normed_test_data, test_labels, batch_size=(test_size[0]))\n",
        "\n",
        "print(f\"Accuracy en Conjunto de Prueba: {test_acc:.4f}\")\n",
        "print(f\"Precision en Conjunto de Prueba: {test_prec:.4f}\")\n",
        "print(f\"Recall en Conjunto de Prueba: {test_rec:.4f}\")\n",
        "print(f\"F1-Score en Conjunto de Prueba: {test_f1:.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "predictions = final_model.predict(normed_test_data)\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "# Muestra la matriz de confusión\n",
        "def plot_confusion_matrix(cm):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.title('Matriz de Confusión')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(cm)\n",
        "# Muestra métricas adicionales\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=['Clase 0', 'Clase 1']))"
      ],
      "metadata": {
        "id": "TpUm-PkTCZaX",
        "outputId": "14d92541-8083-4bd8-81e7-2441044bc0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento completo...\n",
            "Mejor tamaño de filtro: 2\n",
            "Mejor número de neuronas: 16\n",
            "Mejor optimizador: nadam\n",
            "Mejor learning rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 254ms/step - binary_accuracy: 0.5891 - f1_score: 0.7681 - loss: 0.7423 - precision: 0.6348 - recall: 0.8022\n",
            "Epoch 2/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6465 - f1_score: 0.7635 - loss: 0.6250 - precision: 0.6639 - recall: 0.8666 \n",
            "Epoch 3/1000\n",
            "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - binary_accuracy: 0.6677 - f1_score: 0.7823 - loss: 0.6138 - precision: 0.6725 - recall: 0.9409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: binary_accuracy,f1_score,loss,precision,recall\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6754 - f1_score: 0.7696 - loss: 0.5922 - precision: 0.6759 - recall: 0.9239 \n",
            "Epoch 4/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6921 - f1_score: 0.7719 - loss: 0.5681 - precision: 0.7227 - recall: 0.8286 \n",
            "Epoch 5/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7251 - f1_score: 0.7639 - loss: 0.5397 - precision: 0.7445 - recall: 0.8450 \n",
            "Epoch 6/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7235 - f1_score: 0.7561 - loss: 0.5304 - precision: 0.7410 - recall: 0.8384 \n",
            "Epoch 7/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7359 - f1_score: 0.7562 - loss: 0.5063 - precision: 0.7434 - recall: 0.8647 \n",
            "Epoch 8/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7650 - f1_score: 0.7650 - loss: 0.4811 - precision: 0.7728 - recall: 0.8795 \n",
            "Epoch 9/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7679 - f1_score: 0.7507 - loss: 0.4743 - precision: 0.7852 - recall: 0.8455 \n",
            "Epoch 10/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7715 - f1_score: 0.7686 - loss: 0.4519 - precision: 0.7954 - recall: 0.8542 \n",
            "Epoch 11/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7694 - f1_score: 0.7636 - loss: 0.4643 - precision: 0.7887 - recall: 0.8566 \n",
            "Epoch 12/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7952 - f1_score: 0.7637 - loss: 0.4241 - precision: 0.8085 - recall: 0.8764 \n",
            "Epoch 13/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8145 - f1_score: 0.7604 - loss: 0.3997 - precision: 0.8204 - recall: 0.8933 \n",
            "Epoch 14/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8218 - f1_score: 0.7625 - loss: 0.3889 - precision: 0.8299 - recall: 0.8943 \n",
            "Epoch 15/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8029 - f1_score: 0.7592 - loss: 0.3946 - precision: 0.8131 - recall: 0.8810 \n",
            "Epoch 16/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8246 - f1_score: 0.7718 - loss: 0.3688 - precision: 0.8349 - recall: 0.8979 \n",
            "Epoch 17/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8223 - f1_score: 0.7601 - loss: 0.3613 - precision: 0.8430 - recall: 0.8725 \n",
            "Epoch 18/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8225 - f1_score: 0.7533 - loss: 0.3612 - precision: 0.8424 - recall: 0.8692 \n",
            "Epoch 19/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8349 - f1_score: 0.7717 - loss: 0.3560 - precision: 0.8435 - recall: 0.9050 \n",
            "Epoch 20/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8448 - f1_score: 0.7582 - loss: 0.3380 - precision: 0.8601 - recall: 0.8908 \n",
            "Epoch 21/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8587 - f1_score: 0.7593 - loss: 0.3136 - precision: 0.8609 - recall: 0.9174 \n",
            "Epoch 22/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8491 - f1_score: 0.7618 - loss: 0.3137 - precision: 0.8569 - recall: 0.9059\n",
            "Epoch 23/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8804 - f1_score: 0.7764 - loss: 0.2802 - precision: 0.8869 - recall: 0.9290 \n",
            "Epoch 24/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8596 - f1_score: 0.7641 - loss: 0.2928 - precision: 0.8769 - recall: 0.8993 \n",
            "Epoch 25/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8921 - f1_score: 0.7719 - loss: 0.2673 - precision: 0.9076 - recall: 0.9218 \n",
            "Epoch 26/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8734 - f1_score: 0.7630 - loss: 0.2864 - precision: 0.8862 - recall: 0.9116 \n",
            "Epoch 27/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8728 - f1_score: 0.7675 - loss: 0.2762 - precision: 0.8828 - recall: 0.9172 \n",
            "Epoch 28/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8715 - f1_score: 0.7581 - loss: 0.2792 - precision: 0.8737 - recall: 0.9229 \n",
            "Epoch 29/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8950 - f1_score: 0.7655 - loss: 0.2585 - precision: 0.8956 - recall: 0.9399 \n",
            "Epoch 30/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8813 - f1_score: 0.7621 - loss: 0.2548 - precision: 0.8902 - recall: 0.9206 \n",
            "Epoch 31/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8940 - f1_score: 0.7629 - loss: 0.2519 - precision: 0.9107 - recall: 0.9177 \n",
            "Epoch 32/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8821 - f1_score: 0.7680 - loss: 0.2683 - precision: 0.8932 - recall: 0.9208 \n",
            "Epoch 33/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8880 - f1_score: 0.7612 - loss: 0.2496 - precision: 0.8956 - recall: 0.9255 \n",
            "Epoch 34/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9066 - f1_score: 0.7668 - loss: 0.2253 - precision: 0.9271 - recall: 0.9216 \n",
            "Epoch 35/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8876 - f1_score: 0.7523 - loss: 0.2452 - precision: 0.9012 - recall: 0.9127 \n",
            "Epoch 36/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9107 - f1_score: 0.7688 - loss: 0.2230 - precision: 0.9223 - recall: 0.9349 \n",
            "Epoch 37/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9091 - f1_score: 0.7697 - loss: 0.2210 - precision: 0.9206 - recall: 0.9342 \n",
            "Epoch 38/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9182 - f1_score: 0.7685 - loss: 0.2073 - precision: 0.9319 - recall: 0.9364 \n",
            "Epoch 39/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9103 - f1_score: 0.7751 - loss: 0.2028 - precision: 0.9153 - recall: 0.9445 \n",
            "Epoch 40/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8956 - f1_score: 0.7646 - loss: 0.2247 - precision: 0.9173 - recall: 0.9127 \n",
            "Epoch 41/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9085 - f1_score: 0.7575 - loss: 0.2169 - precision: 0.9300 - recall: 0.9189 \n",
            "Epoch 42/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9097 - f1_score: 0.7619 - loss: 0.2091 - precision: 0.9273 - recall: 0.9248 \n",
            "Epoch 43/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9113 - f1_score: 0.7714 - loss: 0.1927 - precision: 0.9254 - recall: 0.9330 \n",
            "Epoch 44/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8887 - f1_score: 0.7671 - loss: 0.2305 - precision: 0.9173 - recall: 0.9019 \n",
            "Epoch 45/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9080 - f1_score: 0.7663 - loss: 0.2067 - precision: 0.9309 - recall: 0.9196 \n",
            "Epoch 46/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9160 - f1_score: 0.7644 - loss: 0.2069 - precision: 0.9312 - recall: 0.9321 \n",
            "Epoch 47/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9212 - f1_score: 0.7553 - loss: 0.1873 - precision: 0.9346 - recall: 0.9347 \n",
            "Epoch 48/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9150 - f1_score: 0.7634 - loss: 0.2015 - precision: 0.9296 - recall: 0.9325 \n",
            "Epoch 49/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9219 - f1_score: 0.7647 - loss: 0.1927 - precision: 0.9480 - recall: 0.9234\n",
            "Epoch 50/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9093 - f1_score: 0.7720 - loss: 0.1911 - precision: 0.9195 - recall: 0.9363 \n",
            "Epoch 51/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9260 - f1_score: 0.7732 - loss: 0.1722 - precision: 0.9425 - recall: 0.9387 \n",
            "Epoch 52/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9352 - f1_score: 0.7613 - loss: 0.1656 - precision: 0.9504 - recall: 0.9431\n",
            "Epoch 53/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9277 - f1_score: 0.7695 - loss: 0.1757 - precision: 0.9437 - recall: 0.9394 \n",
            "Epoch 54/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9383 - f1_score: 0.7619 - loss: 0.1555 - precision: 0.9468 - recall: 0.9523\n",
            "Epoch 55/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9181 - f1_score: 0.7771 - loss: 0.1851 - precision: 0.9352 - recall: 0.9346\n",
            "Epoch 56/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9340 - f1_score: 0.7703 - loss: 0.1698 - precision: 0.9409 - recall: 0.9537 \n",
            "Epoch 57/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9284 - f1_score: 0.7741 - loss: 0.1710 - precision: 0.9487 - recall: 0.9362 \n",
            "Epoch 58/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9278 - f1_score: 0.7693 - loss: 0.1630 - precision: 0.9388 - recall: 0.9446\n",
            "Epoch 59/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9337 - f1_score: 0.7729 - loss: 0.1571 - precision: 0.9463 - recall: 0.9469\n",
            "Epoch 60/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9319 - f1_score: 0.7663 - loss: 0.1625 - precision: 0.9460 - recall: 0.9429 \n",
            "Epoch 61/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9311 - f1_score: 0.7652 - loss: 0.1598 - precision: 0.9481 - recall: 0.9389\n",
            "Epoch 62/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9187 - f1_score: 0.7741 - loss: 0.1903 - precision: 0.9358 - recall: 0.9335\n",
            "Epoch 63/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8973 - f1_score: 0.7668 - loss: 0.2252 - precision: 0.9117 - recall: 0.9219\n",
            "Epoch 64/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9276 - f1_score: 0.7652 - loss: 0.1698 - precision: 0.9414 - recall: 0.9398 \n",
            "Epoch 65/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9226 - f1_score: 0.7674 - loss: 0.1807 - precision: 0.9324 - recall: 0.9426 \n",
            "Epoch 66/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9316 - f1_score: 0.7680 - loss: 0.1640 - precision: 0.9370 - recall: 0.9532 \n",
            "Epoch 67/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9223 - f1_score: 0.7797 - loss: 0.1745 - precision: 0.9394 - recall: 0.9371 \n",
            "Epoch 68/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9281 - f1_score: 0.7735 - loss: 0.1721 - precision: 0.9416 - recall: 0.9428 \n",
            "Epoch 69/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9297 - f1_score: 0.7747 - loss: 0.1653 - precision: 0.9506 - recall: 0.9357 \n",
            "Epoch 70/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9302 - f1_score: 0.7735 - loss: 0.1637 - precision: 0.9441 - recall: 0.9441 \n",
            "Epoch 71/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9388 - f1_score: 0.7752 - loss: 0.1452 - precision: 0.9463 - recall: 0.9559 \n",
            "Epoch 72/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9363 - f1_score: 0.7625 - loss: 0.1524 - precision: 0.9564 - recall: 0.9380 \n",
            "Epoch 73/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9524 - f1_score: 0.7680 - loss: 0.1277 - precision: 0.9635 - recall: 0.9587 \n",
            "Epoch 74/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9325 - f1_score: 0.7635 - loss: 0.1556 - precision: 0.9458 - recall: 0.9431 \n",
            "Epoch 75/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9366 - f1_score: 0.7722 - loss: 0.1383 - precision: 0.9602 - recall: 0.9360 \n",
            "Epoch 76/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9498 - f1_score: 0.7728 - loss: 0.1264 - precision: 0.9503 - recall: 0.9697 \n",
            "Epoch 77/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9312 - f1_score: 0.7708 - loss: 0.1558 - precision: 0.9435 - recall: 0.9453 \n",
            "Epoch 78/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9460 - f1_score: 0.7688 - loss: 0.1258 - precision: 0.9555 - recall: 0.9566 \n",
            "Epoch 79/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9369 - f1_score: 0.7728 - loss: 0.1424 - precision: 0.9424 - recall: 0.9568 \n",
            "Epoch 80/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9497 - f1_score: 0.7667 - loss: 0.1269 - precision: 0.9610 - recall: 0.9568 \n",
            "Epoch 81/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9357 - f1_score: 0.7701 - loss: 0.1524 - precision: 0.9438 - recall: 0.9526 \n",
            "Epoch 82/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9415 - f1_score: 0.7595 - loss: 0.1474 - precision: 0.9524 - recall: 0.9506 \n",
            "Epoch 83/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9416 - f1_score: 0.7704 - loss: 0.1405 - precision: 0.9494 - recall: 0.9564 \n",
            "Epoch 84/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9381 - f1_score: 0.7716 - loss: 0.1522 - precision: 0.9550 - recall: 0.9442 \n",
            "Epoch 85/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9436 - f1_score: 0.7755 - loss: 0.1258 - precision: 0.9592 - recall: 0.9493 \n",
            "Epoch 86/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9437 - f1_score: 0.7694 - loss: 0.1327 - precision: 0.9536 - recall: 0.9550 \n",
            "Epoch 87/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9419 - f1_score: 0.7783 - loss: 0.1383 - precision: 0.9528 - recall: 0.9545 \n",
            "Epoch 88/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9461 - f1_score: 0.7746 - loss: 0.1166 - precision: 0.9568 - recall: 0.9559 \n",
            "Epoch 89/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9512 - f1_score: 0.7763 - loss: 0.1147 - precision: 0.9594 - recall: 0.9625 \n",
            "Epoch 90/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9519 - f1_score: 0.7762 - loss: 0.1174 - precision: 0.9578 - recall: 0.9650 \n",
            "Epoch 91/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9519 - f1_score: 0.7688 - loss: 0.1114 - precision: 0.9673 - recall: 0.9539 \n",
            "Epoch 92/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9517 - f1_score: 0.7675 - loss: 0.1170 - precision: 0.9615 - recall: 0.9590 \n",
            "Epoch 93/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9590 - f1_score: 0.7758 - loss: 0.1055 - precision: 0.9742 - recall: 0.9592 \n",
            "Epoch 94/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9464 - f1_score: 0.7720 - loss: 0.1164 - precision: 0.9583 - recall: 0.9540 \n",
            "Epoch 95/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9501 - f1_score: 0.7747 - loss: 0.1160 - precision: 0.9624 - recall: 0.9570 \n",
            "Epoch 96/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9524 - f1_score: 0.7866 - loss: 0.1161 - precision: 0.9622 - recall: 0.9626 \n",
            "Epoch 97/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9488 - f1_score: 0.7824 - loss: 0.1295 - precision: 0.9597 - recall: 0.9590 \n",
            "Epoch 98/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9500 - f1_score: 0.7833 - loss: 0.1251 - precision: 0.9582 - recall: 0.9626 \n",
            "Epoch 99/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9520 - f1_score: 0.7707 - loss: 0.1140 - precision: 0.9657 - recall: 0.9550 \n",
            "Epoch 100/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9527 - f1_score: 0.7702 - loss: 0.1126 - precision: 0.9639 - recall: 0.9583 \n",
            "Epoch 101/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9325 - f1_score: 0.7700 - loss: 0.1518 - precision: 0.9448 - recall: 0.9444 \n",
            "Epoch 102/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9387 - f1_score: 0.7732 - loss: 0.1386 - precision: 0.9518 - recall: 0.9483 \n",
            "Epoch 103/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9477 - f1_score: 0.7741 - loss: 0.1210 - precision: 0.9556 - recall: 0.9596 \n",
            "Epoch 104/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9499 - f1_score: 0.7765 - loss: 0.1109 - precision: 0.9643 - recall: 0.9547 \n",
            "Epoch 105/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9413 - f1_score: 0.7704 - loss: 0.1328 - precision: 0.9570 - recall: 0.9467 \n",
            "Epoch 106/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9523 - f1_score: 0.7809 - loss: 0.1258 - precision: 0.9629 - recall: 0.9604 \n",
            "Epoch 107/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9489 - f1_score: 0.7748 - loss: 0.1212 - precision: 0.9633 - recall: 0.9540 \n",
            "Epoch 108/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9524 - f1_score: 0.7628 - loss: 0.1222 - precision: 0.9661 - recall: 0.9547 \n",
            "Epoch 109/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9535 - f1_score: 0.7711 - loss: 0.1055 - precision: 0.9664 - recall: 0.9573 \n",
            "Epoch 110/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9651 - f1_score: 0.7719 - loss: 0.0941 - precision: 0.9710 - recall: 0.9721 \n",
            "Epoch 111/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9568 - f1_score: 0.7748 - loss: 0.1000 - precision: 0.9657 - recall: 0.9638 \n",
            "Epoch 112/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9518 - f1_score: 0.7702 - loss: 0.1056 - precision: 0.9579 - recall: 0.9632 \n",
            "Epoch 113/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9632 - f1_score: 0.7729 - loss: 0.0942 - precision: 0.9716 - recall: 0.9685 \n",
            "Epoch 114/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9617 - f1_score: 0.7817 - loss: 0.0921 - precision: 0.9634 - recall: 0.9754 \n",
            "Epoch 115/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9675 - f1_score: 0.7868 - loss: 0.0950 - precision: 0.9748 - recall: 0.9735 \n",
            "Epoch 116/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9528 - f1_score: 0.7802 - loss: 0.1068 - precision: 0.9667 - recall: 0.9575 \n",
            "Epoch 117/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9470 - f1_score: 0.7756 - loss: 0.1173 - precision: 0.9616 - recall: 0.9514 \n",
            "Epoch 118/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9470 - f1_score: 0.7844 - loss: 0.1196 - precision: 0.9545 - recall: 0.9618 \n",
            "Epoch 119/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9610 - f1_score: 0.7867 - loss: 0.0945 - precision: 0.9706 - recall: 0.9675 \n",
            "Epoch 120/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9523 - f1_score: 0.7750 - loss: 0.1049 - precision: 0.9557 - recall: 0.9670 \n",
            "Epoch 121/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9608 - f1_score: 0.7897 - loss: 0.0917 - precision: 0.9749 - recall: 0.9626 \n",
            "Epoch 122/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9641 - f1_score: 0.7801 - loss: 0.0974 - precision: 0.9727 - recall: 0.9692 \n",
            "Epoch 123/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9556 - f1_score: 0.7760 - loss: 0.0929 - precision: 0.9694 - recall: 0.9583 \n",
            "Epoch 124/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9552 - f1_score: 0.7827 - loss: 0.1119 - precision: 0.9688 - recall: 0.9589 \n",
            "Epoch 125/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9551 - f1_score: 0.7868 - loss: 0.1068 - precision: 0.9738 - recall: 0.9544 \n",
            "Epoch 126/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9622 - f1_score: 0.7812 - loss: 0.0882 - precision: 0.9701 - recall: 0.9688 \n",
            "Epoch 127/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9604 - f1_score: 0.7831 - loss: 0.0973 - precision: 0.9740 - recall: 0.9619 \n",
            "Epoch 128/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9497 - f1_score: 0.7783 - loss: 0.1070 - precision: 0.9609 - recall: 0.9575 \n",
            "Epoch 129/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9591 - f1_score: 0.7814 - loss: 0.0948 - precision: 0.9709 - recall: 0.9627 \n",
            "Epoch 130/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9566 - f1_score: 0.7809 - loss: 0.1013 - precision: 0.9716 - recall: 0.9575 \n",
            "Epoch 131/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9526 - f1_score: 0.7860 - loss: 0.1024 - precision: 0.9720 - recall: 0.9507 \n",
            "Epoch 132/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9398 - f1_score: 0.7915 - loss: 0.1409 - precision: 0.9560 - recall: 0.9472 \n",
            "Epoch 133/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9480 - f1_score: 0.7810 - loss: 0.1418 - precision: 0.9589 - recall: 0.9574 \n",
            "Epoch 134/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9497 - f1_score: 0.7817 - loss: 0.1257 - precision: 0.9567 - recall: 0.9623 \n",
            "Epoch 135/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9519 - f1_score: 0.7792 - loss: 0.1081 - precision: 0.9622 - recall: 0.9590 \n",
            "Epoch 136/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9611 - f1_score: 0.7851 - loss: 0.0987 - precision: 0.9671 - recall: 0.9701 \n",
            "Epoch 137/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9432 - f1_score: 0.7857 - loss: 0.1229 - precision: 0.9717 - recall: 0.9357 \n",
            "Epoch 138/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9614 - f1_score: 0.7879 - loss: 0.0902 - precision: 0.9686 - recall: 0.9689 \n",
            "Epoch 139/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9555 - f1_score: 0.7779 - loss: 0.1131 - precision: 0.9682 - recall: 0.9582 \n",
            "Epoch 140/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9628 - f1_score: 0.7813 - loss: 0.0923 - precision: 0.9702 - recall: 0.9693 \n",
            "Epoch 141/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9581 - f1_score: 0.7843 - loss: 0.0979 - precision: 0.9685 - recall: 0.9633 \n",
            "Epoch 142/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9612 - f1_score: 0.7922 - loss: 0.0994 - precision: 0.9695 - recall: 0.9684 \n",
            "Epoch 143/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9637 - f1_score: 0.7847 - loss: 0.0921 - precision: 0.9734 - recall: 0.9675 \n",
            "Epoch 144/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9526 - f1_score: 0.7859 - loss: 0.1057 - precision: 0.9586 - recall: 0.9654 \n",
            "Epoch 145/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9472 - f1_score: 0.7839 - loss: 0.1253 - precision: 0.9702 - recall: 0.9439 \n",
            "Epoch 146/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9594 - f1_score: 0.7798 - loss: 0.0983 - precision: 0.9709 - recall: 0.9627 \n",
            "Epoch 147/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9626 - f1_score: 0.7927 - loss: 0.0903 - precision: 0.9704 - recall: 0.9699 \n",
            "Epoch 148/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9596 - f1_score: 0.7859 - loss: 0.0963 - precision: 0.9672 - recall: 0.9670 \n",
            "Epoch 149/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9631 - f1_score: 0.7888 - loss: 0.0953 - precision: 0.9770 - recall: 0.9635 \n",
            "Epoch 150/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9573 - f1_score: 0.7885 - loss: 0.1075 - precision: 0.9682 - recall: 0.9631 \n",
            "Epoch 151/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9540 - f1_score: 0.7883 - loss: 0.1041 - precision: 0.9707 - recall: 0.9558 \n",
            "Epoch 152/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9538 - f1_score: 0.7670 - loss: 0.1228 - precision: 0.9698 - recall: 0.9519 \n",
            "Epoch 153/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9545 - f1_score: 0.7774 - loss: 0.0990 - precision: 0.9589 - recall: 0.9671\n",
            "Epoch 154/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9552 - f1_score: 0.7784 - loss: 0.1057 - precision: 0.9647 - recall: 0.9613\n",
            "Epoch 155/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9483 - f1_score: 0.7902 - loss: 0.1152 - precision: 0.9638 - recall: 0.9539\n",
            "Epoch 156/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9475 - f1_score: 0.7734 - loss: 0.1169 - precision: 0.9589 - recall: 0.9541\n",
            "Epoch 157/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9629 - f1_score: 0.7757 - loss: 0.0874 - precision: 0.9713 - recall: 0.9677\n",
            "Epoch 158/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - binary_accuracy: 0.9573 - f1_score: 0.7805 - loss: 0.1073 - precision: 0.9665 - recall: 0.9638\n",
            "Epoch 159/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - binary_accuracy: 0.9417 - f1_score: 0.7767 - loss: 0.1265 - precision: 0.9536 - recall: 0.9502\n",
            "Epoch 160/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9685 - f1_score: 0.7857 - loss: 0.0859 - precision: 0.9762 - recall: 0.9730\n",
            "Epoch 161/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9666 - f1_score: 0.7897 - loss: 0.0792 - precision: 0.9749 - recall: 0.9710  \n",
            "Epoch 162/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9642 - f1_score: 0.7910 - loss: 0.0825 - precision: 0.9764 - recall: 0.9659 \n",
            "Epoch 163/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9691 - f1_score: 0.7855 - loss: 0.0775 - precision: 0.9802 - recall: 0.9697 \n",
            "Epoch 164/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9713 - f1_score: 0.7856 - loss: 0.0687 - precision: 0.9829 - recall: 0.9701 \n",
            "Epoch 165/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9587 - f1_score: 0.7857 - loss: 0.0903 - precision: 0.9667 - recall: 0.9661 \n",
            "Epoch 166/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9693 - f1_score: 0.7855 - loss: 0.0789 - precision: 0.9786 - recall: 0.9713 \n",
            "Epoch 167/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9661 - f1_score: 0.7822 - loss: 0.0690 - precision: 0.9773 - recall: 0.9678 \n",
            "Epoch 168/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9630 - f1_score: 0.7786 - loss: 0.0921 - precision: 0.9745 - recall: 0.9640 \n",
            "Epoch 169/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9551 - f1_score: 0.7964 - loss: 0.0931 - precision: 0.9703 - recall: 0.9582 \n",
            "Epoch 170/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9617 - f1_score: 0.7889 - loss: 0.0915 - precision: 0.9662 - recall: 0.9718 \n",
            "Epoch 171/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9613 - f1_score: 0.7796 - loss: 0.0981 - precision: 0.9678 - recall: 0.9690 \n",
            "Epoch 172/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9581 - f1_score: 0.7895 - loss: 0.0939 - precision: 0.9661 - recall: 0.9658 \n",
            "Epoch 173/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9597 - f1_score: 0.7872 - loss: 0.0943 - precision: 0.9702 - recall: 0.9646 \n",
            "Epoch 174/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9479 - f1_score: 0.7884 - loss: 0.1210 - precision: 0.9718 - recall: 0.9436 \n",
            "Epoch 175/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9622 - f1_score: 0.7872 - loss: 0.0941 - precision: 0.9748 - recall: 0.9634 \n",
            "Epoch 176/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9569 - f1_score: 0.7828 - loss: 0.1059 - precision: 0.9695 - recall: 0.9599 \n",
            "Epoch 177/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9590 - f1_score: 0.7862 - loss: 0.0939 - precision: 0.9661 - recall: 0.9671 \n",
            "Epoch 178/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9538 - f1_score: 0.7832 - loss: 0.1081 - precision: 0.9646 - recall: 0.9597 \n",
            "Epoch 179/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9659 - f1_score: 0.7910 - loss: 0.0901 - precision: 0.9732 - recall: 0.9714 \n",
            "Epoch 180/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9661 - f1_score: 0.7927 - loss: 0.0887 - precision: 0.9787 - recall: 0.9672 \n",
            "Epoch 181/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9601 - f1_score: 0.7841 - loss: 0.0930 - precision: 0.9701 - recall: 0.9651 \n",
            "Epoch 182/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9659 - f1_score: 0.7859 - loss: 0.0860 - precision: 0.9847 - recall: 0.9592 \n",
            "Epoch 183/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9598 - f1_score: 0.7887 - loss: 0.0975 - precision: 0.9703 - recall: 0.9649 \n",
            "Epoch 184/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9753 - f1_score: 0.7884 - loss: 0.0725 - precision: 0.9804 - recall: 0.9798 \n",
            "Epoch 185/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9686 - f1_score: 0.7848 - loss: 0.0746 - precision: 0.9774 - recall: 0.9720 \n",
            "Epoch 186/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9707 - f1_score: 0.7885 - loss: 0.0699 - precision: 0.9778 - recall: 0.9748 \n",
            "Epoch 187/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9611 - f1_score: 0.7755 - loss: 0.0866 - precision: 0.9679 - recall: 0.9682 \n",
            "Epoch 188/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9585 - f1_score: 0.7840 - loss: 0.0982 - precision: 0.9667 - recall: 0.9655 \n",
            "Epoch 189/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9652 - f1_score: 0.7877 - loss: 0.0780 - precision: 0.9743 - recall: 0.9692 \n",
            "Epoch 190/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9693 - f1_score: 0.7820 - loss: 0.0711 - precision: 0.9791 - recall: 0.9703 \n",
            "Epoch 191/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9677 - f1_score: 0.7990 - loss: 0.0737 - precision: 0.9751 - recall: 0.9734 \n",
            "Epoch 192/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9669 - f1_score: 0.7888 - loss: 0.0791 - precision: 0.9803 - recall: 0.9660 \n",
            "Epoch 193/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9681 - f1_score: 0.7878 - loss: 0.0766 - precision: 0.9807 - recall: 0.9671 \n",
            "Epoch 194/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9667 - f1_score: 0.7821 - loss: 0.0878 - precision: 0.9743 - recall: 0.9714 \n",
            "Epoch 195/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9642 - f1_score: 0.7883 - loss: 0.0779 - precision: 0.9717 - recall: 0.9700 \n",
            "Epoch 196/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9690 - f1_score: 0.7962 - loss: 0.0750 - precision: 0.9811 - recall: 0.9690 \n",
            "Epoch 197/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7887 - loss: 0.0699 - precision: 0.9759 - recall: 0.9785 \n",
            "Epoch 198/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9660 - f1_score: 0.7902 - loss: 0.0740 - precision: 0.9771 - recall: 0.9677 \n",
            "Epoch 199/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9766 - f1_score: 0.7943 - loss: 0.0569 - precision: 0.9854 - recall: 0.9770 \n",
            "Epoch 200/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9621 - f1_score: 0.7864 - loss: 0.0922 - precision: 0.9714 - recall: 0.9666 \n",
            "Epoch 201/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9676 - f1_score: 0.7882 - loss: 0.0757 - precision: 0.9798 - recall: 0.9673 \n",
            "Epoch 202/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9719 - f1_score: 0.7889 - loss: 0.0711 - precision: 0.9807 - recall: 0.9729 \n",
            "Epoch 203/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9619 - f1_score: 0.8011 - loss: 0.0878 - precision: 0.9752 - recall: 0.9636 \n",
            "Epoch 204/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9703 - f1_score: 0.8042 - loss: 0.0689 - precision: 0.9769 - recall: 0.9759 \n",
            "Epoch 205/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9717 - f1_score: 0.7980 - loss: 0.0678 - precision: 0.9774 - recall: 0.9768 \n",
            "Epoch 206/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9540 - f1_score: 0.8039 - loss: 0.1059 - precision: 0.9684 - recall: 0.9583 \n",
            "Epoch 207/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9604 - f1_score: 0.7912 - loss: 0.0920 - precision: 0.9734 - recall: 0.9608 \n",
            "Epoch 208/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9623 - f1_score: 0.8041 - loss: 0.0882 - precision: 0.9731 - recall: 0.9660 \n",
            "Epoch 209/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9631 - f1_score: 0.7977 - loss: 0.0868 - precision: 0.9780 - recall: 0.9624 \n",
            "Epoch 210/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9679 - f1_score: 0.7893 - loss: 0.0814 - precision: 0.9779 - recall: 0.9695 \n",
            "Epoch 211/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9433 - f1_score: 0.7874 - loss: 0.1330 - precision: 0.9479 - recall: 0.9609 \n",
            "Epoch 212/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9581 - f1_score: 0.7948 - loss: 0.0895 - precision: 0.9641 - recall: 0.9684 \n",
            "Epoch 213/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9703 - f1_score: 0.7976 - loss: 0.0746 - precision: 0.9827 - recall: 0.9691 \n",
            "Epoch 214/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.8068 - loss: 0.0782 - precision: 0.9801 - recall: 0.9758 \n",
            "Epoch 215/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9657 - f1_score: 0.7987 - loss: 0.0903 - precision: 0.9738 - recall: 0.9707 \n",
            "Epoch 216/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9655 - f1_score: 0.7948 - loss: 0.0783 - precision: 0.9763 - recall: 0.9673 \n",
            "Epoch 217/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9663 - f1_score: 0.7964 - loss: 0.0745 - precision: 0.9729 - recall: 0.9734 \n",
            "Epoch 218/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.8022 - loss: 0.0682 - precision: 0.9830 - recall: 0.9728 \n",
            "Epoch 219/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9732 - f1_score: 0.7931 - loss: 0.0673 - precision: 0.9846 - recall: 0.9710 \n",
            "Epoch 220/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9645 - f1_score: 0.8004 - loss: 0.0938 - precision: 0.9718 - recall: 0.9718 \n",
            "Epoch 221/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9663 - f1_score: 0.8055 - loss: 0.0800 - precision: 0.9761 - recall: 0.9695 \n",
            "Epoch 222/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9708 - f1_score: 0.7820 - loss: 0.0699 - precision: 0.9818 - recall: 0.9693 \n",
            "Epoch 223/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9675 - f1_score: 0.7901 - loss: 0.0831 - precision: 0.9739 - recall: 0.9725 \n",
            "Epoch 224/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9731 - f1_score: 0.7906 - loss: 0.0741 - precision: 0.9769 - recall: 0.9792 \n",
            "Epoch 225/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9657 - f1_score: 0.7954 - loss: 0.0809 - precision: 0.9730 - recall: 0.9714 \n",
            "Epoch 226/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9689 - f1_score: 0.8062 - loss: 0.0750 - precision: 0.9766 - recall: 0.9735 \n",
            "Epoch 227/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9694 - f1_score: 0.7916 - loss: 0.0653 - precision: 0.9733 - recall: 0.9767 \n",
            "Epoch 228/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9671 - f1_score: 0.7947 - loss: 0.0784 - precision: 0.9726 - recall: 0.9737\n",
            "Epoch 229/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - binary_accuracy: 0.9719 - f1_score: 0.8018 - loss: 0.0770 - precision: 0.9812 - recall: 0.9736\n",
            "Epoch 230/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - binary_accuracy: 0.9711 - f1_score: 0.8074 - loss: 0.0655 - precision: 0.9752 - recall: 0.9792\n",
            "Epoch 231/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9717 - f1_score: 0.8025 - loss: 0.0738 - precision: 0.9787 - recall: 0.9756  \n",
            "Epoch 232/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9651 - f1_score: 0.7977 - loss: 0.0764 - precision: 0.9727 - recall: 0.9703 \n",
            "Epoch 233/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9606 - f1_score: 0.7986 - loss: 0.0869 - precision: 0.9754 - recall: 0.9610 \n",
            "Epoch 234/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - binary_accuracy: 0.9748 - f1_score: 0.8012 - loss: 0.0672 - precision: 0.9816 - recall: 0.9779\n",
            "Epoch 235/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9758 - f1_score: 0.7844 - loss: 0.0583 - precision: 0.9841 - recall: 0.9758\n",
            "Epoch 236/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - binary_accuracy: 0.9779 - f1_score: 0.8058 - loss: 0.0575 - precision: 0.9851 - recall: 0.9796\n",
            "Epoch 237/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9794 - f1_score: 0.8024 - loss: 0.0589 - precision: 0.9851 - recall: 0.9817 \n",
            "Epoch 238/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9688 - f1_score: 0.8015 - loss: 0.0704 - precision: 0.9736 - recall: 0.9763\n",
            "Epoch 239/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9628 - f1_score: 0.7933 - loss: 0.0867 - precision: 0.9689 - recall: 0.9702  \n",
            "Epoch 240/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9697 - f1_score: 0.8010 - loss: 0.0678 - precision: 0.9777 - recall: 0.9737\n",
            "Epoch 241/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9622 - f1_score: 0.7955 - loss: 0.0934 - precision: 0.9679 - recall: 0.9702\n",
            "Epoch 242/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9701 - f1_score: 0.7966 - loss: 0.0826 - precision: 0.9797 - recall: 0.9716\n",
            "Epoch 243/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9650 - f1_score: 0.8071 - loss: 0.0972 - precision: 0.9765 - recall: 0.9674\n",
            "Epoch 244/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9726 - f1_score: 0.8071 - loss: 0.0726 - precision: 0.9762 - recall: 0.9794\n",
            "Epoch 245/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9760 - f1_score: 0.8066 - loss: 0.0707 - precision: 0.9819 - recall: 0.9795\n",
            "Epoch 246/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9681 - f1_score: 0.7973 - loss: 0.0780 - precision: 0.9710 - recall: 0.9773\n",
            "Epoch 247/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9700 - f1_score: 0.7965 - loss: 0.0708 - precision: 0.9784 - recall: 0.9731\n",
            "Epoch 248/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9546 - f1_score: 0.7933 - loss: 0.1136 - precision: 0.9658 - recall: 0.9599\n",
            "Epoch 249/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9703 - f1_score: 0.8043 - loss: 0.0763 - precision: 0.9780 - recall: 0.9736\n",
            "Epoch 250/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9679 - f1_score: 0.8003 - loss: 0.0758 - precision: 0.9780 - recall: 0.9697 \n",
            "Epoch 251/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9719 - f1_score: 0.7991 - loss: 0.0701 - precision: 0.9785 - recall: 0.9759 \n",
            "Epoch 252/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9728 - f1_score: 0.8006 - loss: 0.0616 - precision: 0.9808 - recall: 0.9747 \n",
            "Epoch 253/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9699 - f1_score: 0.8041 - loss: 0.0645 - precision: 0.9777 - recall: 0.9738 \n",
            "Epoch 254/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9671 - f1_score: 0.7998 - loss: 0.0788 - precision: 0.9755 - recall: 0.9714 \n",
            "Epoch 255/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9556 - f1_score: 0.7962 - loss: 0.1168 - precision: 0.9672 - recall: 0.9597 \n",
            "Epoch 256/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9674 - f1_score: 0.7883 - loss: 0.0883 - precision: 0.9705 - recall: 0.9751 \n",
            "Epoch 257/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9693 - f1_score: 0.7999 - loss: 0.0702 - precision: 0.9746 - recall: 0.9751 \n",
            "Epoch 258/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9622 - f1_score: 0.7952 - loss: 0.0914 - precision: 0.9692 - recall: 0.9696 \n",
            "Epoch 259/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9717 - f1_score: 0.8099 - loss: 0.0744 - precision: 0.9767 - recall: 0.9780\n",
            "Epoch 260/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9679 - f1_score: 0.8036 - loss: 0.0773 - precision: 0.9758 - recall: 0.9722 \n",
            "Epoch 261/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.7977 - loss: 0.0671 - precision: 0.9814 - recall: 0.9752 \n",
            "Epoch 262/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9729 - f1_score: 0.8072 - loss: 0.0662 - precision: 0.9768 - recall: 0.9794 \n",
            "Epoch 263/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.8086 - loss: 0.0614 - precision: 0.9844 - recall: 0.9768 \n",
            "Epoch 264/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9780 - f1_score: 0.8102 - loss: 0.0587 - precision: 0.9822 - recall: 0.9827 \n",
            "Epoch 265/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8099 - loss: 0.0540 - precision: 0.9866 - recall: 0.9787 \n",
            "Epoch 266/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9729 - f1_score: 0.7965 - loss: 0.0708 - precision: 0.9819 - recall: 0.9741 \n",
            "Epoch 267/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9768 - f1_score: 0.8142 - loss: 0.0571 - precision: 0.9837 - recall: 0.9792\n",
            "Epoch 268/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9748 - f1_score: 0.8018 - loss: 0.0593 - precision: 0.9768 - recall: 0.9820 \n",
            "Epoch 269/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9699 - f1_score: 0.8081 - loss: 0.0755 - precision: 0.9765 - recall: 0.9749 \n",
            "Epoch 270/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9824 - f1_score: 0.8035 - loss: 0.0503 - precision: 0.9880 - recall: 0.9833 \n",
            "Epoch 271/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9744 - f1_score: 0.7986 - loss: 0.0724 - precision: 0.9777 - recall: 0.9806 \n",
            "Epoch 272/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9750 - f1_score: 0.8073 - loss: 0.0701 - precision: 0.9823 - recall: 0.9773 \n",
            "Epoch 273/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9768 - f1_score: 0.8054 - loss: 0.0586 - precision: 0.9801 - recall: 0.9823 \n",
            "Epoch 274/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.7983 - loss: 0.0695 - precision: 0.9766 - recall: 0.9797 \n",
            "Epoch 275/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.8086 - loss: 0.0645 - precision: 0.9745 - recall: 0.9814 \n",
            "Epoch 276/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.8039 - loss: 0.0899 - precision: 0.9707 - recall: 0.9808 \n",
            "Epoch 277/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.8103 - loss: 0.0737 - precision: 0.9699 - recall: 0.9822 \n",
            "Epoch 278/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9710 - f1_score: 0.8038 - loss: 0.0695 - precision: 0.9805 - recall: 0.9718 \n",
            "Epoch 279/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9720 - f1_score: 0.8202 - loss: 0.0746 - precision: 0.9798 - recall: 0.9756 \n",
            "Epoch 280/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9698 - f1_score: 0.8010 - loss: 0.0727 - precision: 0.9781 - recall: 0.9725 \n",
            "Epoch 281/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.8013 - loss: 0.0804 - precision: 0.9739 - recall: 0.9762 \n",
            "Epoch 282/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9765 - f1_score: 0.7994 - loss: 0.0580 - precision: 0.9786 - recall: 0.9830 \n",
            "Epoch 283/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9726 - f1_score: 0.8063 - loss: 0.0696 - precision: 0.9778 - recall: 0.9774 \n",
            "Epoch 284/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9788 - f1_score: 0.8142 - loss: 0.0631 - precision: 0.9823 - recall: 0.9839 \n",
            "Epoch 285/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9693 - f1_score: 0.8094 - loss: 0.0680 - precision: 0.9692 - recall: 0.9814 \n",
            "Epoch 286/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9768 - f1_score: 0.8108 - loss: 0.0584 - precision: 0.9830 - recall: 0.9795 \n",
            "Epoch 287/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.8047 - loss: 0.0635 - precision: 0.9797 - recall: 0.9810 \n",
            "Epoch 288/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9710 - f1_score: 0.8046 - loss: 0.0680 - precision: 0.9754 - recall: 0.9776 \n",
            "Epoch 289/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7987 - loss: 0.0719 - precision: 0.9775 - recall: 0.9764 \n",
            "Epoch 290/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9706 - f1_score: 0.8202 - loss: 0.0704 - precision: 0.9813 - recall: 0.9720 \n",
            "Epoch 291/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9679 - f1_score: 0.8023 - loss: 0.0803 - precision: 0.9783 - recall: 0.9689 \n",
            "Epoch 292/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9687 - f1_score: 0.7973 - loss: 0.0709 - precision: 0.9750 - recall: 0.9733 \n",
            "Epoch 293/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9703 - f1_score: 0.8067 - loss: 0.0771 - precision: 0.9759 - recall: 0.9764 \n",
            "Epoch 294/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9705 - f1_score: 0.8004 - loss: 0.0820 - precision: 0.9797 - recall: 0.9718 \n",
            "Epoch 295/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.7942 - loss: 0.0917 - precision: 0.9763 - recall: 0.9731 \n",
            "Epoch 296/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9645 - f1_score: 0.7976 - loss: 0.0965 - precision: 0.9721 - recall: 0.9690 \n",
            "Epoch 297/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9690 - f1_score: 0.7983 - loss: 0.0811 - precision: 0.9757 - recall: 0.9738 \n",
            "Epoch 298/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9792 - f1_score: 0.8049 - loss: 0.0541 - precision: 0.9784 - recall: 0.9882 \n",
            "Epoch 299/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9742 - f1_score: 0.8143 - loss: 0.0616 - precision: 0.9815 - recall: 0.9767 \n",
            "Epoch 300/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9763 - f1_score: 0.8188 - loss: 0.0624 - precision: 0.9787 - recall: 0.9835 \n",
            "Epoch 301/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9759 - f1_score: 0.7947 - loss: 0.0671 - precision: 0.9777 - recall: 0.9826 \n",
            "Epoch 302/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9754 - f1_score: 0.8160 - loss: 0.0693 - precision: 0.9815 - recall: 0.9791 \n",
            "Epoch 303/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9602 - f1_score: 0.7972 - loss: 0.0968 - precision: 0.9657 - recall: 0.9691 \n",
            "Epoch 304/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9698 - f1_score: 0.8063 - loss: 0.0740 - precision: 0.9736 - recall: 0.9778 \n",
            "Epoch 305/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9660 - f1_score: 0.8029 - loss: 0.0804 - precision: 0.9793 - recall: 0.9656 \n",
            "Epoch 306/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9745 - f1_score: 0.8076 - loss: 0.0666 - precision: 0.9788 - recall: 0.9798 \n",
            "Epoch 307/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9781 - f1_score: 0.8134 - loss: 0.0599 - precision: 0.9812 - recall: 0.9840 \n",
            "Epoch 308/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9744 - f1_score: 0.8058 - loss: 0.0620 - precision: 0.9812 - recall: 0.9773 \n",
            "Epoch 309/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8048 - loss: 0.0535 - precision: 0.9825 - recall: 0.9866 \n",
            "Epoch 310/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9747 - f1_score: 0.8107 - loss: 0.0607 - precision: 0.9830 - recall: 0.9762\n",
            "Epoch 311/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9782 - f1_score: 0.8106 - loss: 0.0542 - precision: 0.9823 - recall: 0.9826 \n",
            "Epoch 312/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9782 - f1_score: 0.7992 - loss: 0.0580 - precision: 0.9821 - recall: 0.9823 \n",
            "Epoch 313/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.8026 - loss: 0.0607 - precision: 0.9835 - recall: 0.9734 \n",
            "Epoch 314/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9697 - f1_score: 0.8171 - loss: 0.0729 - precision: 0.9733 - recall: 0.9785 \n",
            "Epoch 315/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9720 - f1_score: 0.8050 - loss: 0.0750 - precision: 0.9756 - recall: 0.9792 \n",
            "Epoch 316/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9704 - f1_score: 0.7999 - loss: 0.0627 - precision: 0.9749 - recall: 0.9767 \n",
            "Epoch 317/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9732 - f1_score: 0.8088 - loss: 0.0726 - precision: 0.9789 - recall: 0.9780 \n",
            "Epoch 318/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9561 - f1_score: 0.8145 - loss: 0.0989 - precision: 0.9690 - recall: 0.9608 \n",
            "Epoch 319/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9745 - f1_score: 0.7978 - loss: 0.0642 - precision: 0.9787 - recall: 0.9801 \n",
            "Epoch 320/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9779 - f1_score: 0.8051 - loss: 0.0570 - precision: 0.9831 - recall: 0.9814 \n",
            "Epoch 321/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8097 - loss: 0.0477 - precision: 0.9864 - recall: 0.9867 \n",
            "Epoch 322/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9769 - f1_score: 0.8044 - loss: 0.0554 - precision: 0.9812 - recall: 0.9811 \n",
            "Epoch 323/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9768 - f1_score: 0.8084 - loss: 0.0587 - precision: 0.9800 - recall: 0.9822 \n",
            "Epoch 324/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9791 - f1_score: 0.8179 - loss: 0.0631 - precision: 0.9828 - recall: 0.9837 \n",
            "Epoch 325/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9783 - f1_score: 0.8058 - loss: 0.0583 - precision: 0.9801 - recall: 0.9845 \n",
            "Epoch 326/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9804 - f1_score: 0.8113 - loss: 0.0507 - precision: 0.9873 - recall: 0.9809 \n",
            "Epoch 327/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9789 - f1_score: 0.8047 - loss: 0.0487 - precision: 0.9790 - recall: 0.9869 \n",
            "Epoch 328/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9804 - f1_score: 0.8051 - loss: 0.0555 - precision: 0.9846 - recall: 0.9836 \n",
            "Epoch 329/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9764 - f1_score: 0.8101 - loss: 0.0637 - precision: 0.9788 - recall: 0.9829 \n",
            "Epoch 330/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9754 - f1_score: 0.8131 - loss: 0.0744 - precision: 0.9767 - recall: 0.9838 \n",
            "Epoch 331/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.8052 - loss: 0.0732 - precision: 0.9805 - recall: 0.9747 \n",
            "Epoch 332/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9804 - f1_score: 0.8032 - loss: 0.0525 - precision: 0.9889 - recall: 0.9789 \n",
            "Epoch 333/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9815 - f1_score: 0.8122 - loss: 0.0508 - precision: 0.9832 - recall: 0.9872\n",
            "Epoch 334/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9836 - f1_score: 0.8139 - loss: 0.0452 - precision: 0.9873 - recall: 0.9861\n",
            "Epoch 335/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9775 - f1_score: 0.8104 - loss: 0.0641 - precision: 0.9800 - recall: 0.9840\n",
            "Epoch 336/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9779 - f1_score: 0.8034 - loss: 0.0594 - precision: 0.9791 - recall: 0.9850\n",
            "Epoch 337/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9826 - f1_score: 0.8201 - loss: 0.0499 - precision: 0.9861 - recall: 0.9861\n",
            "Epoch 338/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9788 - f1_score: 0.8074 - loss: 0.0596 - precision: 0.9794 - recall: 0.9864\n",
            "Epoch 339/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9850 - f1_score: 0.8133 - loss: 0.0493 - precision: 0.9918 - recall: 0.9841\n",
            "Epoch 340/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9737 - f1_score: 0.7938 - loss: 0.0691 - precision: 0.9844 - recall: 0.9721\n",
            "Epoch 341/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9795 - f1_score: 0.7942 - loss: 0.0508 - precision: 0.9784 - recall: 0.9882\n",
            "Epoch 342/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9749 - f1_score: 0.8054 - loss: 0.0631 - precision: 0.9727 - recall: 0.9868\n",
            "Epoch 343/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9785 - f1_score: 0.8156 - loss: 0.0613 - precision: 0.9811 - recall: 0.9845\n",
            "Epoch 344/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8070 - loss: 0.0514 - precision: 0.9826 - recall: 0.9824 \n",
            "Epoch 345/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9778 - f1_score: 0.8132 - loss: 0.0546 - precision: 0.9810 - recall: 0.9833 \n",
            "Epoch 346/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9768 - f1_score: 0.8085 - loss: 0.0533 - precision: 0.9823 - recall: 0.9799 \n",
            "Epoch 347/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9826 - f1_score: 0.8134 - loss: 0.0436 - precision: 0.9857 - recall: 0.9865 \n",
            "Epoch 348/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9802 - f1_score: 0.8078 - loss: 0.0549 - precision: 0.9840 - recall: 0.9839\n",
            "Epoch 349/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8094 - loss: 0.0412 - precision: 0.9865 - recall: 0.9886 \n",
            "Epoch 350/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9843 - f1_score: 0.7995 - loss: 0.0466 - precision: 0.9892 - recall: 0.9847 \n",
            "Epoch 351/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9796 - f1_score: 0.8015 - loss: 0.0478 - precision: 0.9849 - recall: 0.9817 \n",
            "Epoch 352/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9739 - f1_score: 0.8152 - loss: 0.0627 - precision: 0.9808 - recall: 0.9777 \n",
            "Epoch 353/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.8029 - loss: 0.0480 - precision: 0.9797 - recall: 0.9870 \n",
            "Epoch 354/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.8047 - loss: 0.0610 - precision: 0.9761 - recall: 0.9893 \n",
            "Epoch 355/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.8079 - loss: 0.0401 - precision: 0.9896 - recall: 0.9861 \n",
            "Epoch 356/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9681 - f1_score: 0.8074 - loss: 0.0793 - precision: 0.9733 - recall: 0.9746 \n",
            "Epoch 357/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9731 - f1_score: 0.8110 - loss: 0.0615 - precision: 0.9784 - recall: 0.9777 \n",
            "Epoch 358/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9795 - f1_score: 0.8065 - loss: 0.0496 - precision: 0.9796 - recall: 0.9868 \n",
            "Epoch 359/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8037 - loss: 0.0476 - precision: 0.9848 - recall: 0.9806 \n",
            "Epoch 360/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.8092 - loss: 0.0485 - precision: 0.9893 - recall: 0.9811 \n",
            "Epoch 361/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9756 - f1_score: 0.8161 - loss: 0.0576 - precision: 0.9794 - recall: 0.9814 \n",
            "Epoch 362/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.8213 - loss: 0.0659 - precision: 0.9802 - recall: 0.9772 \n",
            "Epoch 363/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9809 - f1_score: 0.8030 - loss: 0.0482 - precision: 0.9873 - recall: 0.9816 \n",
            "Epoch 364/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.8083 - loss: 0.0402 - precision: 0.9856 - recall: 0.9901 \n",
            "Epoch 365/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9802 - f1_score: 0.8119 - loss: 0.0448 - precision: 0.9833 - recall: 0.9845\n",
            "Epoch 366/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9808 - f1_score: 0.8181 - loss: 0.0543 - precision: 0.9823 - recall: 0.9869 \n",
            "Epoch 367/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9819 - f1_score: 0.8186 - loss: 0.0445 - precision: 0.9854 - recall: 0.9856 \n",
            "Epoch 368/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9764 - f1_score: 0.8148 - loss: 0.0671 - precision: 0.9774 - recall: 0.9847 \n",
            "Epoch 369/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9817 - f1_score: 0.8097 - loss: 0.0519 - precision: 0.9860 - recall: 0.9838 \n",
            "Epoch 370/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8147 - loss: 0.0540 - precision: 0.9841 - recall: 0.9874 \n",
            "Epoch 371/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9788 - f1_score: 0.8198 - loss: 0.0476 - precision: 0.9801 - recall: 0.9861 \n",
            "Epoch 372/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8096 - loss: 0.0436 - precision: 0.9876 - recall: 0.9874 \n",
            "Epoch 373/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9884 - f1_score: 0.8129 - loss: 0.0417 - precision: 0.9928 - recall: 0.9884 \n",
            "Epoch 374/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9790 - f1_score: 0.8149 - loss: 0.0530 - precision: 0.9799 - recall: 0.9863 \n",
            "Epoch 375/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9748 - f1_score: 0.8198 - loss: 0.0633 - precision: 0.9800 - recall: 0.9794 \n",
            "Epoch 376/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9755 - f1_score: 0.8027 - loss: 0.0589 - precision: 0.9789 - recall: 0.9809 \n",
            "Epoch 377/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9784 - f1_score: 0.8152 - loss: 0.0603 - precision: 0.9827 - recall: 0.9826 \n",
            "Epoch 378/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9721 - f1_score: 0.8151 - loss: 0.0667 - precision: 0.9768 - recall: 0.9784 \n",
            "Epoch 379/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9806 - f1_score: 0.8225 - loss: 0.0562 - precision: 0.9868 - recall: 0.9823 \n",
            "Epoch 380/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9747 - f1_score: 0.8234 - loss: 0.0604 - precision: 0.9795 - recall: 0.9799 \n",
            "Epoch 381/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.8024 - loss: 0.0688 - precision: 0.9722 - recall: 0.9789 \n",
            "Epoch 382/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9756 - f1_score: 0.8204 - loss: 0.0663 - precision: 0.9836 - recall: 0.9774 \n",
            "Epoch 383/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8176 - loss: 0.0556 - precision: 0.9888 - recall: 0.9815 \n",
            "Epoch 384/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9831 - f1_score: 0.8185 - loss: 0.0465 - precision: 0.9837 - recall: 0.9891 \n",
            "Epoch 385/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.8195 - loss: 0.0548 - precision: 0.9814 - recall: 0.9862 \n",
            "Epoch 386/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.8056 - loss: 0.0549 - precision: 0.9838 - recall: 0.9835 \n",
            "Epoch 387/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9767 - f1_score: 0.7990 - loss: 0.0593 - precision: 0.9805 - recall: 0.9806 \n",
            "Epoch 388/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9830 - f1_score: 0.8035 - loss: 0.0451 - precision: 0.9870 - recall: 0.9852 \n",
            "Epoch 389/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9775 - f1_score: 0.8137 - loss: 0.0596 - precision: 0.9807 - recall: 0.9833 \n",
            "Epoch 390/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8107 - loss: 0.0443 - precision: 0.9878 - recall: 0.9902 \n",
            "Epoch 391/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9796 - f1_score: 0.8171 - loss: 0.0548 - precision: 0.9868 - recall: 0.9806 \n",
            "Epoch 392/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9759 - f1_score: 0.8082 - loss: 0.0677 - precision: 0.9786 - recall: 0.9826 \n",
            "Epoch 393/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.8185 - loss: 0.0622 - precision: 0.9839 - recall: 0.9775 \n",
            "Epoch 394/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8201 - loss: 0.0598 - precision: 0.9825 - recall: 0.9826 \n",
            "Epoch 395/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9771 - f1_score: 0.8208 - loss: 0.0584 - precision: 0.9801 - recall: 0.9831 \n",
            "Epoch 396/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9790 - f1_score: 0.8228 - loss: 0.0562 - precision: 0.9841 - recall: 0.9819 \n",
            "Epoch 397/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9824 - f1_score: 0.8189 - loss: 0.0478 - precision: 0.9858 - recall: 0.9858 \n",
            "Epoch 398/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8112 - loss: 0.0515 - precision: 0.9894 - recall: 0.9799 \n",
            "Epoch 399/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9841 - f1_score: 0.8154 - loss: 0.0392 - precision: 0.9838 - recall: 0.9908 \n",
            "Epoch 400/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9812 - f1_score: 0.8148 - loss: 0.0435 - precision: 0.9882 - recall: 0.9813 \n",
            "Epoch 401/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9811 - f1_score: 0.8134 - loss: 0.0465 - precision: 0.9863 - recall: 0.9828 \n",
            "Epoch 402/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9740 - f1_score: 0.8191 - loss: 0.0798 - precision: 0.9840 - recall: 0.9742 \n",
            "Epoch 403/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.8063 - loss: 0.0575 - precision: 0.9857 - recall: 0.9815 \n",
            "Epoch 404/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9726 - f1_score: 0.8174 - loss: 0.0768 - precision: 0.9792 - recall: 0.9769 \n",
            "Epoch 405/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9829 - f1_score: 0.8162 - loss: 0.0532 - precision: 0.9872 - recall: 0.9846 \n",
            "Epoch 406/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9770 - f1_score: 0.8166 - loss: 0.0585 - precision: 0.9799 - recall: 0.9827 \n",
            "Epoch 407/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9765 - f1_score: 0.8195 - loss: 0.0667 - precision: 0.9794 - recall: 0.9829 \n",
            "Epoch 408/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9828 - f1_score: 0.8054 - loss: 0.0478 - precision: 0.9850 - recall: 0.9867 \n",
            "Epoch 409/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9793 - f1_score: 0.8302 - loss: 0.0541 - precision: 0.9867 - recall: 0.9804 \n",
            "Epoch 410/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9830 - f1_score: 0.8215 - loss: 0.0454 - precision: 0.9851 - recall: 0.9876 \n",
            "Epoch 411/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9773 - f1_score: 0.8234 - loss: 0.0532 - precision: 0.9816 - recall: 0.9817 \n",
            "Epoch 412/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9790 - f1_score: 0.8277 - loss: 0.0547 - precision: 0.9833 - recall: 0.9830 \n",
            "Epoch 413/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.8176 - loss: 0.0501 - precision: 0.9872 - recall: 0.9857 \n",
            "Epoch 414/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9812 - f1_score: 0.8199 - loss: 0.0547 - precision: 0.9862 - recall: 0.9829 \n",
            "Epoch 415/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.8205 - loss: 0.0788 - precision: 0.9740 - recall: 0.9819 \n",
            "Epoch 416/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9804 - f1_score: 0.8209 - loss: 0.0527 - precision: 0.9818 - recall: 0.9865 \n",
            "Epoch 417/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9763 - f1_score: 0.8174 - loss: 0.0681 - precision: 0.9825 - recall: 0.9784 \n",
            "Epoch 418/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9812 - f1_score: 0.8155 - loss: 0.0467 - precision: 0.9842 - recall: 0.9851 \n",
            "Epoch 419/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9681 - f1_score: 0.8145 - loss: 0.0705 - precision: 0.9727 - recall: 0.9758 \n",
            "Epoch 420/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9784 - f1_score: 0.8139 - loss: 0.0635 - precision: 0.9789 - recall: 0.9860 \n",
            "Epoch 421/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.8130 - loss: 0.0742 - precision: 0.9708 - recall: 0.9838 \n",
            "Epoch 422/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9782 - f1_score: 0.8150 - loss: 0.0597 - precision: 0.9806 - recall: 0.9839 \n",
            "Epoch 423/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9794 - f1_score: 0.8207 - loss: 0.0557 - precision: 0.9803 - recall: 0.9867 \n",
            "Epoch 424/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.8144 - loss: 0.0482 - precision: 0.9864 - recall: 0.9844 \n",
            "Epoch 425/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9739 - f1_score: 0.8249 - loss: 0.0689 - precision: 0.9792 - recall: 0.9785 \n",
            "Epoch 426/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9778 - f1_score: 0.8190 - loss: 0.0579 - precision: 0.9866 - recall: 0.9771 \n",
            "Epoch 427/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9750 - f1_score: 0.8231 - loss: 0.0547 - precision: 0.9807 - recall: 0.9787\n",
            "Epoch 428/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9851 - f1_score: 0.8254 - loss: 0.0449 - precision: 0.9873 - recall: 0.9889\n",
            "Epoch 429/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9779 - f1_score: 0.8246 - loss: 0.0503 - precision: 0.9832 - recall: 0.9810\n",
            "Epoch 430/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9843 - f1_score: 0.8178 - loss: 0.0478 - precision: 0.9894 - recall: 0.9851\n",
            "Epoch 431/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9752 - f1_score: 0.8204 - loss: 0.0627 - precision: 0.9734 - recall: 0.9871\n",
            "Epoch 432/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9834 - f1_score: 0.8185 - loss: 0.0436 - precision: 0.9825 - recall: 0.9906\n",
            "Epoch 433/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9830 - f1_score: 0.8261 - loss: 0.0489 - precision: 0.9895 - recall: 0.9831\n",
            "Epoch 434/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9867 - f1_score: 0.8145 - loss: 0.0403 - precision: 0.9891 - recall: 0.9892\n",
            "Epoch 435/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9822 - f1_score: 0.8195 - loss: 0.0492 - precision: 0.9879 - recall: 0.9833\n",
            "Epoch 436/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9841 - f1_score: 0.8198 - loss: 0.0446 - precision: 0.9809 - recall: 0.9936\n",
            "Epoch 437/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8233 - loss: 0.0469 - precision: 0.9842 - recall: 0.9886 \n",
            "Epoch 438/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9840 - f1_score: 0.8269 - loss: 0.0424 - precision: 0.9867 - recall: 0.9874 \n",
            "Epoch 439/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9771 - f1_score: 0.8283 - loss: 0.0568 - precision: 0.9787 - recall: 0.9851 \n",
            "Epoch 440/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9827 - f1_score: 0.8150 - loss: 0.0424 - precision: 0.9870 - recall: 0.9849 \n",
            "Epoch 441/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8109 - loss: 0.0404 - precision: 0.9881 - recall: 0.9886 \n",
            "Epoch 442/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8139 - loss: 0.0497 - precision: 0.9830 - recall: 0.9853 \n",
            "Epoch 443/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9836 - f1_score: 0.8214 - loss: 0.0446 - precision: 0.9898 - recall: 0.9837 \n",
            "Epoch 444/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9822 - f1_score: 0.8188 - loss: 0.0452 - precision: 0.9835 - recall: 0.9876 \n",
            "Epoch 445/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8152 - loss: 0.0546 - precision: 0.9843 - recall: 0.9857 \n",
            "Epoch 446/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9841 - f1_score: 0.8170 - loss: 0.0518 - precision: 0.9895 - recall: 0.9848 \n",
            "Epoch 447/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.8150 - loss: 0.0538 - precision: 0.9831 - recall: 0.9834 \n",
            "Epoch 448/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9806 - f1_score: 0.8213 - loss: 0.0516 - precision: 0.9814 - recall: 0.9870 \n",
            "Epoch 449/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9778 - f1_score: 0.8274 - loss: 0.0516 - precision: 0.9844 - recall: 0.9796 \n",
            "Epoch 450/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9796 - f1_score: 0.8169 - loss: 0.0485 - precision: 0.9812 - recall: 0.9851 \n",
            "Epoch 451/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9784 - f1_score: 0.8258 - loss: 0.0558 - precision: 0.9824 - recall: 0.9832 \n",
            "Epoch 452/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9804 - f1_score: 0.8170 - loss: 0.0541 - precision: 0.9800 - recall: 0.9883\n",
            "Epoch 453/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9717 - f1_score: 0.8206 - loss: 0.0814 - precision: 0.9798 - recall: 0.9743 \n",
            "Epoch 454/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9837 - f1_score: 0.8158 - loss: 0.0509 - precision: 0.9855 - recall: 0.9879 \n",
            "Epoch 455/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9751 - f1_score: 0.8176 - loss: 0.0587 - precision: 0.9751 - recall: 0.9842 \n",
            "Epoch 456/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.8288 - loss: 0.0488 - precision: 0.9863 - recall: 0.9846 \n",
            "Epoch 457/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9811 - f1_score: 0.8321 - loss: 0.0584 - precision: 0.9845 - recall: 0.9853 \n",
            "Epoch 458/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.8198 - loss: 0.0496 - precision: 0.9823 - recall: 0.9888 \n",
            "Epoch 459/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9770 - f1_score: 0.8120 - loss: 0.0580 - precision: 0.9850 - recall: 0.9762 \n",
            "Epoch 460/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9731 - f1_score: 0.8132 - loss: 0.0706 - precision: 0.9808 - recall: 0.9753 \n",
            "Epoch 461/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.8260 - loss: 0.0501 - precision: 0.9863 - recall: 0.9847 \n",
            "Epoch 462/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8266 - loss: 0.0445 - precision: 0.9895 - recall: 0.9863 \n",
            "Epoch 463/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8160 - loss: 0.0567 - precision: 0.9857 - recall: 0.9839 \n",
            "Epoch 464/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9813 - f1_score: 0.7996 - loss: 0.0471 - precision: 0.9853 - recall: 0.9835 \n",
            "Epoch 465/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8128 - loss: 0.0391 - precision: 0.9856 - recall: 0.9919 \n",
            "Epoch 466/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8181 - loss: 0.0453 - precision: 0.9900 - recall: 0.9854 \n",
            "Epoch 467/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9788 - f1_score: 0.8170 - loss: 0.0517 - precision: 0.9854 - recall: 0.9796 \n",
            "Epoch 468/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9878 - f1_score: 0.8266 - loss: 0.0390 - precision: 0.9912 - recall: 0.9891 \n",
            "Epoch 469/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8308 - loss: 0.0351 - precision: 0.9894 - recall: 0.9888 \n",
            "Epoch 470/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8105 - loss: 0.0406 - precision: 0.9910 - recall: 0.9882 \n",
            "Epoch 471/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8217 - loss: 0.0425 - precision: 0.9886 - recall: 0.9897 \n",
            "Epoch 472/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9851 - f1_score: 0.8253 - loss: 0.0404 - precision: 0.9888 - recall: 0.9872 \n",
            "Epoch 473/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8213 - loss: 0.0421 - precision: 0.9895 - recall: 0.9882 \n",
            "Epoch 474/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9809 - f1_score: 0.8178 - loss: 0.0559 - precision: 0.9852 - recall: 0.9839 \n",
            "Epoch 475/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8244 - loss: 0.0439 - precision: 0.9910 - recall: 0.9860 \n",
            "Epoch 476/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9849 - f1_score: 0.8170 - loss: 0.0433 - precision: 0.9881 - recall: 0.9873 \n",
            "Epoch 477/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8284 - loss: 0.0325 - precision: 0.9864 - recall: 0.9918 \n",
            "Epoch 478/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8310 - loss: 0.0345 - precision: 0.9910 - recall: 0.9897 \n",
            "Epoch 479/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8259 - loss: 0.0469 - precision: 0.9853 - recall: 0.9901 \n",
            "Epoch 480/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9855 - f1_score: 0.8272 - loss: 0.0393 - precision: 0.9905 - recall: 0.9862 \n",
            "Epoch 481/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9869 - f1_score: 0.8170 - loss: 0.0321 - precision: 0.9871 - recall: 0.9917 \n",
            "Epoch 482/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8251 - loss: 0.0413 - precision: 0.9903 - recall: 0.9822 \n",
            "Epoch 483/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.8258 - loss: 0.0491 - precision: 0.9888 - recall: 0.9870 \n",
            "Epoch 484/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.8252 - loss: 0.0562 - precision: 0.9871 - recall: 0.9775 \n",
            "Epoch 485/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9889 - f1_score: 0.8161 - loss: 0.0365 - precision: 0.9881 - recall: 0.9938 \n",
            "Epoch 486/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9775 - f1_score: 0.8253 - loss: 0.0602 - precision: 0.9799 - recall: 0.9835 \n",
            "Epoch 487/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8145 - loss: 0.0554 - precision: 0.9795 - recall: 0.9853 \n",
            "Epoch 488/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9825 - f1_score: 0.8251 - loss: 0.0465 - precision: 0.9834 - recall: 0.9882\n",
            "Epoch 489/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8275 - loss: 0.0431 - precision: 0.9864 - recall: 0.9868 \n",
            "Epoch 490/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8200 - loss: 0.0441 - precision: 0.9879 - recall: 0.9850 \n",
            "Epoch 491/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9842 - f1_score: 0.8206 - loss: 0.0503 - precision: 0.9859 - recall: 0.9888 \n",
            "Epoch 492/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8340 - loss: 0.0370 - precision: 0.9885 - recall: 0.9909 \n",
            "Epoch 493/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9780 - f1_score: 0.8281 - loss: 0.0521 - precision: 0.9763 - recall: 0.9887 \n",
            "Epoch 494/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8293 - loss: 0.0428 - precision: 0.9903 - recall: 0.9900 \n",
            "Epoch 495/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8288 - loss: 0.0333 - precision: 0.9895 - recall: 0.9883 \n",
            "Epoch 496/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9887 - f1_score: 0.8365 - loss: 0.0367 - precision: 0.9907 - recall: 0.9910 \n",
            "Epoch 497/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8258 - loss: 0.0508 - precision: 0.9839 - recall: 0.9915 \n",
            "Epoch 498/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9824 - f1_score: 0.8230 - loss: 0.0448 - precision: 0.9858 - recall: 0.9856 \n",
            "Epoch 499/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.8248 - loss: 0.0617 - precision: 0.9789 - recall: 0.9863 \n",
            "Epoch 500/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9842 - f1_score: 0.8232 - loss: 0.0398 - precision: 0.9861 - recall: 0.9887 \n",
            "Epoch 501/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9818 - f1_score: 0.8263 - loss: 0.0524 - precision: 0.9862 - recall: 0.9842 \n",
            "Epoch 502/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9796 - f1_score: 0.8319 - loss: 0.0469 - precision: 0.9835 - recall: 0.9836 \n",
            "Epoch 503/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8282 - loss: 0.0435 - precision: 0.9852 - recall: 0.9884 \n",
            "Epoch 504/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8226 - loss: 0.0351 - precision: 0.9878 - recall: 0.9913 \n",
            "Epoch 505/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9798 - f1_score: 0.8228 - loss: 0.0494 - precision: 0.9809 - recall: 0.9865 \n",
            "Epoch 506/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9800 - f1_score: 0.8267 - loss: 0.0550 - precision: 0.9841 - recall: 0.9837 \n",
            "Epoch 507/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8250 - loss: 0.0452 - precision: 0.9878 - recall: 0.9884 \n",
            "Epoch 508/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9790 - f1_score: 0.8119 - loss: 0.0682 - precision: 0.9791 - recall: 0.9863 \n",
            "Epoch 509/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9689 - f1_score: 0.8154 - loss: 0.0914 - precision: 0.9733 - recall: 0.9762\n",
            "Epoch 510/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9843 - f1_score: 0.8181 - loss: 0.0607 - precision: 0.9872 - recall: 0.9872 \n",
            "Epoch 511/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.8280 - loss: 0.0685 - precision: 0.9835 - recall: 0.9844 \n",
            "Epoch 512/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.8166 - loss: 0.0678 - precision: 0.9813 - recall: 0.9794 \n",
            "Epoch 513/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.8267 - loss: 0.0543 - precision: 0.9819 - recall: 0.9852 \n",
            "Epoch 514/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8251 - loss: 0.0457 - precision: 0.9923 - recall: 0.9850 \n",
            "Epoch 515/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8316 - loss: 0.0392 - precision: 0.9910 - recall: 0.9869 \n",
            "Epoch 516/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9816 - f1_score: 0.8102 - loss: 0.0509 - precision: 0.9837 - recall: 0.9859\n",
            "Epoch 517/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9805 - f1_score: 0.8272 - loss: 0.0613 - precision: 0.9820 - recall: 0.9868\n",
            "Epoch 518/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9863 - f1_score: 0.8164 - loss: 0.0470 - precision: 0.9889 - recall: 0.9890\n",
            "Epoch 519/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9759 - f1_score: 0.8211 - loss: 0.0618 - precision: 0.9798 - recall: 0.9812\n",
            "Epoch 520/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9767 - f1_score: 0.8225 - loss: 0.0636 - precision: 0.9794 - recall: 0.9827\n",
            "Epoch 521/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9857 - f1_score: 0.8148 - loss: 0.0391 - precision: 0.9897 - recall: 0.9872\n",
            "Epoch 522/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9868 - f1_score: 0.8170 - loss: 0.0358 - precision: 0.9885 - recall: 0.9899\n",
            "Epoch 523/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9819 - f1_score: 0.8319 - loss: 0.0461 - precision: 0.9829 - recall: 0.9884\n",
            "Epoch 524/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9886 - f1_score: 0.8297 - loss: 0.0333 - precision: 0.9896 - recall: 0.9921\n",
            "Epoch 525/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8233 - loss: 0.0333 - precision: 0.9911 - recall: 0.9909  \n",
            "Epoch 526/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.8229 - loss: 0.0384 - precision: 0.9896 - recall: 0.9854 \n",
            "Epoch 527/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9750 - f1_score: 0.8184 - loss: 0.0557 - precision: 0.9806 - recall: 0.9790 \n",
            "Epoch 528/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9891 - f1_score: 0.8183 - loss: 0.0333 - precision: 0.9908 - recall: 0.9916 \n",
            "Epoch 529/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.8207 - loss: 0.0460 - precision: 0.9852 - recall: 0.9906 \n",
            "Epoch 530/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9835 - f1_score: 0.8260 - loss: 0.0361 - precision: 0.9842 - recall: 0.9893 \n",
            "Epoch 531/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8129 - loss: 0.0476 - precision: 0.9877 - recall: 0.9854 \n",
            "Epoch 532/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8218 - loss: 0.0362 - precision: 0.9843 - recall: 0.9914 \n",
            "Epoch 533/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8249 - loss: 0.0403 - precision: 0.9865 - recall: 0.9911 \n",
            "Epoch 534/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9815 - f1_score: 0.8261 - loss: 0.0399 - precision: 0.9835 - recall: 0.9865 \n",
            "Epoch 535/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8191 - loss: 0.0399 - precision: 0.9925 - recall: 0.9848 \n",
            "Epoch 536/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9822 - f1_score: 0.8247 - loss: 0.0389 - precision: 0.9842 - recall: 0.9869 \n",
            "Epoch 537/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9899 - f1_score: 0.8277 - loss: 0.0281 - precision: 0.9921 - recall: 0.9914 \n",
            "Epoch 538/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.8249 - loss: 0.0397 - precision: 0.9823 - recall: 0.9885 \n",
            "Epoch 539/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9789 - f1_score: 0.8216 - loss: 0.0435 - precision: 0.9881 - recall: 0.9776 \n",
            "Epoch 540/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9786 - f1_score: 0.8249 - loss: 0.0583 - precision: 0.9855 - recall: 0.9799 \n",
            "Epoch 541/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9780 - f1_score: 0.8297 - loss: 0.0598 - precision: 0.9835 - recall: 0.9807 \n",
            "Epoch 542/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9792 - f1_score: 0.8174 - loss: 0.0643 - precision: 0.9839 - recall: 0.9821 \n",
            "Epoch 543/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9811 - f1_score: 0.8222 - loss: 0.0514 - precision: 0.9817 - recall: 0.9872 \n",
            "Epoch 544/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8218 - loss: 0.0347 - precision: 0.9940 - recall: 0.9924 \n",
            "Epoch 545/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9841 - f1_score: 0.8370 - loss: 0.0441 - precision: 0.9864 - recall: 0.9882 \n",
            "Epoch 546/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9812 - f1_score: 0.8131 - loss: 0.0446 - precision: 0.9864 - recall: 0.9829 \n",
            "Epoch 547/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9835 - f1_score: 0.8382 - loss: 0.0407 - precision: 0.9897 - recall: 0.9841 \n",
            "Epoch 548/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8236 - loss: 0.0361 - precision: 0.9878 - recall: 0.9855 \n",
            "Epoch 549/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8178 - loss: 0.0383 - precision: 0.9884 - recall: 0.9885 \n",
            "Epoch 550/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9802 - f1_score: 0.8225 - loss: 0.0539 - precision: 0.9859 - recall: 0.9822 \n",
            "Epoch 551/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8307 - loss: 0.0351 - precision: 0.9850 - recall: 0.9910 \n",
            "Epoch 552/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8253 - loss: 0.0302 - precision: 0.9899 - recall: 0.9928 \n",
            "Epoch 553/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8352 - loss: 0.0268 - precision: 0.9909 - recall: 0.9914 \n",
            "Epoch 554/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9915 - f1_score: 0.8395 - loss: 0.0250 - precision: 0.9950 - recall: 0.9913 \n",
            "Epoch 555/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8195 - loss: 0.0281 - precision: 0.9942 - recall: 0.9904 \n",
            "Epoch 556/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8282 - loss: 0.0351 - precision: 0.9903 - recall: 0.9871 \n",
            "Epoch 557/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8245 - loss: 0.0364 - precision: 0.9891 - recall: 0.9902 \n",
            "Epoch 558/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8182 - loss: 0.0383 - precision: 0.9891 - recall: 0.9894 \n",
            "Epoch 559/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9802 - f1_score: 0.8293 - loss: 0.0626 - precision: 0.9862 - recall: 0.9820 \n",
            "Epoch 560/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9830 - f1_score: 0.8278 - loss: 0.0446 - precision: 0.9887 - recall: 0.9838 \n",
            "Epoch 561/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.8328 - loss: 0.0446 - precision: 0.9876 - recall: 0.9799 \n",
            "Epoch 562/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9842 - f1_score: 0.8250 - loss: 0.0402 - precision: 0.9862 - recall: 0.9881 \n",
            "Epoch 563/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9842 - f1_score: 0.8209 - loss: 0.0420 - precision: 0.9845 - recall: 0.9898\n",
            "Epoch 564/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.8315 - loss: 0.0451 - precision: 0.9874 - recall: 0.9893 \n",
            "Epoch 565/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8332 - loss: 0.0305 - precision: 0.9911 - recall: 0.9909 \n",
            "Epoch 566/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9841 - f1_score: 0.8277 - loss: 0.0432 - precision: 0.9881 - recall: 0.9860 \n",
            "Epoch 567/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9796 - f1_score: 0.8257 - loss: 0.0571 - precision: 0.9815 - recall: 0.9852 \n",
            "Epoch 568/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8293 - loss: 0.0456 - precision: 0.9811 - recall: 0.9874 \n",
            "Epoch 569/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8386 - loss: 0.0356 - precision: 0.9898 - recall: 0.9884 \n",
            "Epoch 570/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8215 - loss: 0.0421 - precision: 0.9844 - recall: 0.9903 \n",
            "Epoch 571/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8160 - loss: 0.0371 - precision: 0.9908 - recall: 0.9901 \n",
            "Epoch 572/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9789 - f1_score: 0.8229 - loss: 0.0540 - precision: 0.9792 - recall: 0.9866\n",
            "Epoch 573/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8350 - loss: 0.0481 - precision: 0.9885 - recall: 0.9852 \n",
            "Epoch 574/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.8320 - loss: 0.0498 - precision: 0.9893 - recall: 0.9848 \n",
            "Epoch 575/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9774 - f1_score: 0.8289 - loss: 0.0616 - precision: 0.9813 - recall: 0.9829 \n",
            "Epoch 576/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8336 - loss: 0.0554 - precision: 0.9855 - recall: 0.9825 \n",
            "Epoch 577/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8279 - loss: 0.0398 - precision: 0.9926 - recall: 0.9827 \n",
            "Epoch 578/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9842 - f1_score: 0.8266 - loss: 0.0408 - precision: 0.9852 - recall: 0.9894 \n",
            "Epoch 579/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.8248 - loss: 0.0371 - precision: 0.9868 - recall: 0.9869 \n",
            "Epoch 580/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8312 - loss: 0.0343 - precision: 0.9907 - recall: 0.9878 \n",
            "Epoch 581/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8334 - loss: 0.0328 - precision: 0.9918 - recall: 0.9888 \n",
            "Epoch 582/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8288 - loss: 0.0278 - precision: 0.9929 - recall: 0.9936 \n",
            "Epoch 583/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9849 - f1_score: 0.8258 - loss: 0.0395 - precision: 0.9891 - recall: 0.9860 \n",
            "Epoch 584/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9829 - f1_score: 0.8334 - loss: 0.0509 - precision: 0.9876 - recall: 0.9847 \n",
            "Epoch 585/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9815 - f1_score: 0.8290 - loss: 0.0605 - precision: 0.9857 - recall: 0.9845 \n",
            "Epoch 586/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9697 - f1_score: 0.8316 - loss: 0.0830 - precision: 0.9823 - recall: 0.9687 \n",
            "Epoch 587/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9764 - f1_score: 0.8316 - loss: 0.0618 - precision: 0.9832 - recall: 0.9785 \n",
            "Epoch 588/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9754 - f1_score: 0.8277 - loss: 0.0626 - precision: 0.9860 - recall: 0.9741 \n",
            "Epoch 589/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9763 - f1_score: 0.8311 - loss: 0.0658 - precision: 0.9821 - recall: 0.9802\n",
            "Epoch 590/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9773 - f1_score: 0.8251 - loss: 0.0547 - precision: 0.9823 - recall: 0.9805 \n",
            "Epoch 591/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9803 - f1_score: 0.8215 - loss: 0.0545 - precision: 0.9859 - recall: 0.9818 \n",
            "Epoch 592/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9799 - f1_score: 0.8362 - loss: 0.0489 - precision: 0.9786 - recall: 0.9895 \n",
            "Epoch 593/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8271 - loss: 0.0413 - precision: 0.9919 - recall: 0.9871 \n",
            "Epoch 594/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.8356 - loss: 0.0499 - precision: 0.9826 - recall: 0.9854 \n",
            "Epoch 595/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9771 - f1_score: 0.8201 - loss: 0.0516 - precision: 0.9828 - recall: 0.9787 \n",
            "Epoch 596/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.8237 - loss: 0.0432 - precision: 0.9861 - recall: 0.9877 \n",
            "Epoch 597/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8351 - loss: 0.0384 - precision: 0.9846 - recall: 0.9883 \n",
            "Epoch 598/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9855 - f1_score: 0.8186 - loss: 0.0421 - precision: 0.9875 - recall: 0.9887 \n",
            "Epoch 599/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9846 - f1_score: 0.8380 - loss: 0.0447 - precision: 0.9854 - recall: 0.9901 \n",
            "Epoch 600/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9819 - f1_score: 0.8192 - loss: 0.0570 - precision: 0.9873 - recall: 0.9833 \n",
            "Epoch 601/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8239 - loss: 0.0587 - precision: 0.9880 - recall: 0.9807 \n",
            "Epoch 602/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9803 - f1_score: 0.8291 - loss: 0.0523 - precision: 0.9818 - recall: 0.9865 \n",
            "Epoch 603/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8189 - loss: 0.0407 - precision: 0.9916 - recall: 0.9835 \n",
            "Epoch 604/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8327 - loss: 0.0476 - precision: 0.9847 - recall: 0.9884 \n",
            "Epoch 605/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.8246 - loss: 0.0529 - precision: 0.9873 - recall: 0.9880 \n",
            "Epoch 606/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9732 - f1_score: 0.8158 - loss: 0.0691 - precision: 0.9824 - recall: 0.9738 \n",
            "Epoch 607/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9840 - f1_score: 0.8299 - loss: 0.0500 - precision: 0.9904 - recall: 0.9835\n",
            "Epoch 608/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8433 - loss: 0.0582 - precision: 0.9837 - recall: 0.9881 \n",
            "Epoch 609/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9749 - f1_score: 0.8231 - loss: 0.0653 - precision: 0.9839 - recall: 0.9748 \n",
            "Epoch 610/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9806 - f1_score: 0.8315 - loss: 0.0489 - precision: 0.9818 - recall: 0.9867 \n",
            "Epoch 611/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9861 - f1_score: 0.8301 - loss: 0.0455 - precision: 0.9882 - recall: 0.9889\n",
            "Epoch 612/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9858 - f1_score: 0.8241 - loss: 0.0401 - precision: 0.9897 - recall: 0.9872\n",
            "Epoch 613/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9824 - f1_score: 0.8313 - loss: 0.0517 - precision: 0.9802 - recall: 0.9913\n",
            "Epoch 614/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9869 - f1_score: 0.8226 - loss: 0.0361 - precision: 0.9906 - recall: 0.9881\n",
            "Epoch 615/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9805 - f1_score: 0.8256 - loss: 0.0414 - precision: 0.9825 - recall: 0.9861\n",
            "Epoch 616/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9873 - f1_score: 0.8278 - loss: 0.0426 - precision: 0.9905 - recall: 0.9887\n",
            "Epoch 617/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9897 - f1_score: 0.8372 - loss: 0.0317 - precision: 0.9895 - recall: 0.9940\n",
            "Epoch 618/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9884 - f1_score: 0.8250 - loss: 0.0310 - precision: 0.9919 - recall: 0.9886\n",
            "Epoch 619/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8292 - loss: 0.0303 - precision: 0.9916 - recall: 0.9915  \n",
            "Epoch 620/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8314 - loss: 0.0335 - precision: 0.9893 - recall: 0.9908 \n",
            "Epoch 621/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9907 - f1_score: 0.8313 - loss: 0.0299 - precision: 0.9922 - recall: 0.9927 \n",
            "Epoch 622/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9907 - f1_score: 0.8251 - loss: 0.0266 - precision: 0.9911 - recall: 0.9940 \n",
            "Epoch 623/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9889 - f1_score: 0.8353 - loss: 0.0295 - precision: 0.9929 - recall: 0.9889 \n",
            "Epoch 624/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9903 - f1_score: 0.8352 - loss: 0.0264 - precision: 0.9912 - recall: 0.9931 \n",
            "Epoch 625/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8321 - loss: 0.0221 - precision: 0.9925 - recall: 0.9963 \n",
            "Epoch 626/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8349 - loss: 0.0308 - precision: 0.9901 - recall: 0.9906 \n",
            "Epoch 627/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8435 - loss: 0.0292 - precision: 0.9929 - recall: 0.9909 \n",
            "Epoch 628/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8291 - loss: 0.0324 - precision: 0.9919 - recall: 0.9937 \n",
            "Epoch 629/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8360 - loss: 0.0277 - precision: 0.9903 - recall: 0.9934 \n",
            "Epoch 630/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8442 - loss: 0.0343 - precision: 0.9858 - recall: 0.9930 \n",
            "Epoch 631/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8320 - loss: 0.0293 - precision: 0.9928 - recall: 0.9904 \n",
            "Epoch 632/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8309 - loss: 0.0405 - precision: 0.9859 - recall: 0.9874 \n",
            "Epoch 633/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8431 - loss: 0.0348 - precision: 0.9881 - recall: 0.9908 \n",
            "Epoch 634/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8340 - loss: 0.0531 - precision: 0.9885 - recall: 0.9864 \n",
            "Epoch 635/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8324 - loss: 0.0416 - precision: 0.9859 - recall: 0.9876 \n",
            "Epoch 636/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9876 - f1_score: 0.8380 - loss: 0.0344 - precision: 0.9898 - recall: 0.9902 \n",
            "Epoch 637/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8328 - loss: 0.0301 - precision: 0.9902 - recall: 0.9929 \n",
            "Epoch 638/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9901 - f1_score: 0.8307 - loss: 0.0296 - precision: 0.9919 - recall: 0.9921 \n",
            "Epoch 639/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9904 - f1_score: 0.8368 - loss: 0.0273 - precision: 0.9932 - recall: 0.9913\n",
            "Epoch 640/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9926 - f1_score: 0.8397 - loss: 0.0241 - precision: 0.9930 - recall: 0.9951 \n",
            "Epoch 641/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8329 - loss: 0.0364 - precision: 0.9888 - recall: 0.9915 \n",
            "Epoch 642/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9908 - f1_score: 0.8280 - loss: 0.0259 - precision: 0.9917 - recall: 0.9931 \n",
            "Epoch 643/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8408 - loss: 0.0246 - precision: 0.9928 - recall: 0.9938 \n",
            "Epoch 644/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9875 - f1_score: 0.8336 - loss: 0.0340 - precision: 0.9903 - recall: 0.9895 \n",
            "Epoch 645/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8459 - loss: 0.0327 - precision: 0.9912 - recall: 0.9920 \n",
            "Epoch 646/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8395 - loss: 0.0308 - precision: 0.9906 - recall: 0.9910 \n",
            "Epoch 647/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8376 - loss: 0.0304 - precision: 0.9895 - recall: 0.9894 \n",
            "Epoch 648/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9913 - f1_score: 0.8420 - loss: 0.0260 - precision: 0.9922 - recall: 0.9939\n",
            "Epoch 649/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8281 - loss: 0.0318 - precision: 0.9920 - recall: 0.9871 \n",
            "Epoch 650/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9901 - f1_score: 0.8316 - loss: 0.0290 - precision: 0.9895 - recall: 0.9944 \n",
            "Epoch 651/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8513 - loss: 0.0297 - precision: 0.9933 - recall: 0.9904 \n",
            "Epoch 652/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9895 - f1_score: 0.8362 - loss: 0.0315 - precision: 0.9882 - recall: 0.9947 \n",
            "Epoch 653/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8465 - loss: 0.0297 - precision: 0.9917 - recall: 0.9862 \n",
            "Epoch 654/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8384 - loss: 0.0358 - precision: 0.9851 - recall: 0.9931 \n",
            "Epoch 655/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8320 - loss: 0.0390 - precision: 0.9895 - recall: 0.9893 \n",
            "Epoch 656/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8406 - loss: 0.0362 - precision: 0.9910 - recall: 0.9865 \n",
            "Epoch 657/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9876 - f1_score: 0.8398 - loss: 0.0310 - precision: 0.9931 - recall: 0.9868 \n",
            "Epoch 658/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8364 - loss: 0.0364 - precision: 0.9926 - recall: 0.9864 \n",
            "Epoch 659/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9819 - f1_score: 0.8454 - loss: 0.0591 - precision: 0.9861 - recall: 0.9851 \n",
            "Epoch 660/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.8385 - loss: 0.0823 - precision: 0.9741 - recall: 0.9777 \n",
            "Epoch 661/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9757 - f1_score: 0.8237 - loss: 0.0775 - precision: 0.9825 - recall: 0.9779 \n",
            "Epoch 662/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9730 - f1_score: 0.8318 - loss: 0.0713 - precision: 0.9783 - recall: 0.9779 \n",
            "Epoch 663/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9676 - f1_score: 0.8265 - loss: 0.0799 - precision: 0.9712 - recall: 0.9759 \n",
            "Epoch 664/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9809 - f1_score: 0.8388 - loss: 0.0572 - precision: 0.9855 - recall: 0.9834 \n",
            "Epoch 665/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8376 - loss: 0.0507 - precision: 0.9869 - recall: 0.9820 \n",
            "Epoch 666/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9746 - f1_score: 0.8438 - loss: 0.0545 - precision: 0.9822 - recall: 0.9772 \n",
            "Epoch 667/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8322 - loss: 0.0407 - precision: 0.9897 - recall: 0.9863 \n",
            "Epoch 668/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8218 - loss: 0.0612 - precision: 0.9866 - recall: 0.9885 \n",
            "Epoch 669/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9839 - f1_score: 0.8276 - loss: 0.0501 - precision: 0.9873 - recall: 0.9865 \n",
            "Epoch 670/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9818 - f1_score: 0.8375 - loss: 0.0563 - precision: 0.9844 - recall: 0.9862 \n",
            "Epoch 671/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9760 - f1_score: 0.8291 - loss: 0.0714 - precision: 0.9825 - recall: 0.9788 \n",
            "Epoch 672/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8319 - loss: 0.0464 - precision: 0.9882 - recall: 0.9865 \n",
            "Epoch 673/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9831 - f1_score: 0.8249 - loss: 0.0444 - precision: 0.9855 - recall: 0.9870\n",
            "Epoch 674/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.8261 - loss: 0.0427 - precision: 0.9821 - recall: 0.9891 \n",
            "Epoch 675/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8255 - loss: 0.0382 - precision: 0.9854 - recall: 0.9897 \n",
            "Epoch 676/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8370 - loss: 0.0465 - precision: 0.9871 - recall: 0.9864 \n",
            "Epoch 677/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9806 - f1_score: 0.8286 - loss: 0.0492 - precision: 0.9822 - recall: 0.9867 \n",
            "Epoch 678/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.8482 - loss: 0.0371 - precision: 0.9884 - recall: 0.9886 \n",
            "Epoch 679/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8378 - loss: 0.0324 - precision: 0.9920 - recall: 0.9894 \n",
            "Epoch 680/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8445 - loss: 0.0373 - precision: 0.9870 - recall: 0.9905 \n",
            "Epoch 681/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8406 - loss: 0.0454 - precision: 0.9878 - recall: 0.9890 \n",
            "Epoch 682/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8488 - loss: 0.0446 - precision: 0.9864 - recall: 0.9871 \n",
            "Epoch 683/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8380 - loss: 0.0457 - precision: 0.9884 - recall: 0.9864 \n",
            "Epoch 684/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8390 - loss: 0.0317 - precision: 0.9925 - recall: 0.9908 \n",
            "Epoch 685/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9889 - f1_score: 0.8329 - loss: 0.0333 - precision: 0.9915 - recall: 0.9905 \n",
            "Epoch 686/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9800 - f1_score: 0.8257 - loss: 0.0540 - precision: 0.9798 - recall: 0.9872 \n",
            "Epoch 687/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9816 - f1_score: 0.8369 - loss: 0.0497 - precision: 0.9847 - recall: 0.9853 \n",
            "Epoch 688/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8288 - loss: 0.0346 - precision: 0.9911 - recall: 0.9876 \n",
            "Epoch 689/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9799 - f1_score: 0.8242 - loss: 0.0540 - precision: 0.9871 - recall: 0.9799 \n",
            "Epoch 690/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9920 - f1_score: 0.8365 - loss: 0.0283 - precision: 0.9924 - recall: 0.9948 \n",
            "Epoch 691/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9829 - f1_score: 0.8226 - loss: 0.0498 - precision: 0.9872 - recall: 0.9849 \n",
            "Epoch 692/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8327 - loss: 0.0359 - precision: 0.9885 - recall: 0.9906 \n",
            "Epoch 693/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8386 - loss: 0.0312 - precision: 0.9886 - recall: 0.9940 \n",
            "Epoch 694/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8291 - loss: 0.0414 - precision: 0.9900 - recall: 0.9897 \n",
            "Epoch 695/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8345 - loss: 0.0288 - precision: 0.9933 - recall: 0.9919 \n",
            "Epoch 696/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8348 - loss: 0.0319 - precision: 0.9886 - recall: 0.9897 \n",
            "Epoch 697/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9881 - f1_score: 0.8384 - loss: 0.0317 - precision: 0.9884 - recall: 0.9927\n",
            "Epoch 698/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9845 - f1_score: 0.8424 - loss: 0.0394 - precision: 0.9880 - recall: 0.9870\n",
            "Epoch 699/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9862 - f1_score: 0.8377 - loss: 0.0369 - precision: 0.9870 - recall: 0.9908\n",
            "Epoch 700/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9887 - f1_score: 0.8363 - loss: 0.0305 - precision: 0.9912 - recall: 0.9905\n",
            "Epoch 701/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - binary_accuracy: 0.9852 - f1_score: 0.8322 - loss: 0.0413 - precision: 0.9881 - recall: 0.9881\n",
            "Epoch 702/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - binary_accuracy: 0.9901 - f1_score: 0.8397 - loss: 0.0278 - precision: 0.9925 - recall: 0.9915\n",
            "Epoch 703/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - binary_accuracy: 0.9874 - f1_score: 0.8440 - loss: 0.0429 - precision: 0.9887 - recall: 0.9913\n",
            "Epoch 704/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9852 - f1_score: 0.8304 - loss: 0.0386 - precision: 0.9885 - recall: 0.9875\n",
            "Epoch 705/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9887 - f1_score: 0.8304 - loss: 0.0280 - precision: 0.9863 - recall: 0.9954\n",
            "Epoch 706/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9907 - f1_score: 0.8137 - loss: 0.0260 - precision: 0.9919 - recall: 0.9929\n",
            "Epoch 707/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8263 - loss: 0.0270 - precision: 0.9937 - recall: 0.9926 \n",
            "Epoch 708/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9887 - f1_score: 0.8369 - loss: 0.0295 - precision: 0.9912 - recall: 0.9907 \n",
            "Epoch 709/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8296 - loss: 0.0364 - precision: 0.9880 - recall: 0.9879 \n",
            "Epoch 710/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9901 - f1_score: 0.8169 - loss: 0.0400 - precision: 0.9925 - recall: 0.9909 \n",
            "Epoch 711/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9919 - f1_score: 0.8282 - loss: 0.0245 - precision: 0.9935 - recall: 0.9934 \n",
            "Epoch 712/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9904 - f1_score: 0.8316 - loss: 0.0229 - precision: 0.9915 - recall: 0.9932 \n",
            "Epoch 713/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8408 - loss: 0.0246 - precision: 0.9916 - recall: 0.9923 \n",
            "Epoch 714/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9881 - f1_score: 0.8339 - loss: 0.0381 - precision: 0.9924 - recall: 0.9882\n",
            "Epoch 715/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9880 - f1_score: 0.8329 - loss: 0.0363 - precision: 0.9916 - recall: 0.9887 \n",
            "Epoch 716/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8362 - loss: 0.0372 - precision: 0.9905 - recall: 0.9879 \n",
            "Epoch 717/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8459 - loss: 0.0288 - precision: 0.9922 - recall: 0.9909 \n",
            "Epoch 718/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8359 - loss: 0.0359 - precision: 0.9900 - recall: 0.9876 \n",
            "Epoch 719/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8314 - loss: 0.0298 - precision: 0.9922 - recall: 0.9941 \n",
            "Epoch 720/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8437 - loss: 0.0318 - precision: 0.9934 - recall: 0.9897 \n",
            "Epoch 721/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9925 - f1_score: 0.8447 - loss: 0.0270 - precision: 0.9955 - recall: 0.9925 \n",
            "Epoch 722/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8361 - loss: 0.0364 - precision: 0.9893 - recall: 0.9876 \n",
            "Epoch 723/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8381 - loss: 0.0346 - precision: 0.9889 - recall: 0.9869 \n",
            "Epoch 724/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8370 - loss: 0.0502 - precision: 0.9827 - recall: 0.9861 \n",
            "Epoch 725/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.8351 - loss: 0.0539 - precision: 0.9815 - recall: 0.9827 \n",
            "Epoch 726/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8345 - loss: 0.0641 - precision: 0.9802 - recall: 0.9851 \n",
            "Epoch 727/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8469 - loss: 0.0290 - precision: 0.9953 - recall: 0.9882 \n",
            "Epoch 728/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9838 - f1_score: 0.8297 - loss: 0.0447 - precision: 0.9882 - recall: 0.9851 \n",
            "Epoch 729/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8320 - loss: 0.0396 - precision: 0.9901 - recall: 0.9874 \n",
            "Epoch 730/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8286 - loss: 0.0364 - precision: 0.9836 - recall: 0.9926 \n",
            "Epoch 731/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8367 - loss: 0.0286 - precision: 0.9917 - recall: 0.9893 \n",
            "Epoch 732/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8402 - loss: 0.0390 - precision: 0.9881 - recall: 0.9905 \n",
            "Epoch 733/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9876 - f1_score: 0.8384 - loss: 0.0374 - precision: 0.9920 - recall: 0.9878 \n",
            "Epoch 734/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8284 - loss: 0.0327 - precision: 0.9915 - recall: 0.9933 \n",
            "Epoch 735/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8395 - loss: 0.0381 - precision: 0.9868 - recall: 0.9902 \n",
            "Epoch 736/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9869 - f1_score: 0.8398 - loss: 0.0356 - precision: 0.9897 - recall: 0.9889\n",
            "Epoch 737/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8443 - loss: 0.0364 - precision: 0.9892 - recall: 0.9877 \n",
            "Epoch 738/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8269 - loss: 0.0281 - precision: 0.9914 - recall: 0.9888 \n",
            "Epoch 739/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9854 - f1_score: 0.8385 - loss: 0.0386 - precision: 0.9876 - recall: 0.9891 \n",
            "Epoch 740/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8383 - loss: 0.0488 - precision: 0.9847 - recall: 0.9838 \n",
            "Epoch 741/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8432 - loss: 0.0399 - precision: 0.9881 - recall: 0.9933 \n",
            "Epoch 742/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8478 - loss: 0.0266 - precision: 0.9913 - recall: 0.9950 \n",
            "Epoch 743/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8454 - loss: 0.0290 - precision: 0.9880 - recall: 0.9930 \n",
            "Epoch 744/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9873 - f1_score: 0.8422 - loss: 0.0346 - precision: 0.9913 - recall: 0.9881 \n",
            "Epoch 745/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9852 - f1_score: 0.8464 - loss: 0.0346 - precision: 0.9901 - recall: 0.9861 \n",
            "Epoch 746/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9828 - f1_score: 0.8353 - loss: 0.0420 - precision: 0.9889 - recall: 0.9827 \n",
            "Epoch 747/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8502 - loss: 0.0293 - precision: 0.9908 - recall: 0.9898 \n",
            "Epoch 748/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9908 - f1_score: 0.8390 - loss: 0.0237 - precision: 0.9915 - recall: 0.9936 \n",
            "Epoch 749/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8424 - loss: 0.0254 - precision: 0.9950 - recall: 0.9906 \n",
            "Epoch 750/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9938 - f1_score: 0.8247 - loss: 0.0212 - precision: 0.9932 - recall: 0.9967 \n",
            "Epoch 751/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8347 - loss: 0.0235 - precision: 0.9931 - recall: 0.9941 \n",
            "Epoch 752/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9932 - f1_score: 0.8388 - loss: 0.0182 - precision: 0.9940 - recall: 0.9951 \n",
            "Epoch 753/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9911 - f1_score: 0.8410 - loss: 0.0254 - precision: 0.9925 - recall: 0.9931 \n",
            "Epoch 754/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8456 - loss: 0.0245 - precision: 0.9946 - recall: 0.9903 \n",
            "Epoch 755/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9947 - f1_score: 0.8447 - loss: 0.0221 - precision: 0.9942 - recall: 0.9973 \n",
            "Epoch 756/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8357 - loss: 0.0450 - precision: 0.9862 - recall: 0.9915 \n",
            "Epoch 757/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8401 - loss: 0.0301 - precision: 0.9846 - recall: 0.9939 \n",
            "Epoch 758/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9884 - f1_score: 0.8399 - loss: 0.0311 - precision: 0.9892 - recall: 0.9917 \n",
            "Epoch 759/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9891 - f1_score: 0.8359 - loss: 0.0304 - precision: 0.9906 - recall: 0.9916 \n",
            "Epoch 760/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8367 - loss: 0.0316 - precision: 0.9920 - recall: 0.9967 \n",
            "Epoch 761/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8369 - loss: 0.0386 - precision: 0.9902 - recall: 0.9870 \n",
            "Epoch 762/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9913 - f1_score: 0.8418 - loss: 0.0255 - precision: 0.9937 - recall: 0.9922\n",
            "Epoch 763/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8384 - loss: 0.0312 - precision: 0.9902 - recall: 0.9896 \n",
            "Epoch 764/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8316 - loss: 0.0399 - precision: 0.9907 - recall: 0.9849 \n",
            "Epoch 765/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8436 - loss: 0.0472 - precision: 0.9873 - recall: 0.9908 \n",
            "Epoch 766/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8319 - loss: 0.0318 - precision: 0.9904 - recall: 0.9897 \n",
            "Epoch 767/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8445 - loss: 0.0294 - precision: 0.9902 - recall: 0.9916 \n",
            "Epoch 768/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8389 - loss: 0.0376 - precision: 0.9901 - recall: 0.9882 \n",
            "Epoch 769/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8453 - loss: 0.0388 - precision: 0.9885 - recall: 0.9906 \n",
            "Epoch 770/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9884 - f1_score: 0.8387 - loss: 0.0336 - precision: 0.9891 - recall: 0.9921 \n",
            "Epoch 771/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8405 - loss: 0.0366 - precision: 0.9899 - recall: 0.9904 \n",
            "Epoch 772/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8262 - loss: 0.0375 - precision: 0.9905 - recall: 0.9882 \n",
            "Epoch 773/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8328 - loss: 0.0298 - precision: 0.9927 - recall: 0.9896 \n",
            "Epoch 774/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8282 - loss: 0.0318 - precision: 0.9916 - recall: 0.9853 \n",
            "Epoch 775/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8329 - loss: 0.0315 - precision: 0.9882 - recall: 0.9933 \n",
            "Epoch 776/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9902 - f1_score: 0.8368 - loss: 0.0271 - precision: 0.9904 - recall: 0.9938 \n",
            "Epoch 777/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9802 - f1_score: 0.8405 - loss: 0.0484 - precision: 0.9814 - recall: 0.9866 \n",
            "Epoch 778/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.8387 - loss: 0.0335 - precision: 0.9859 - recall: 0.9906 \n",
            "Epoch 779/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9891 - f1_score: 0.8549 - loss: 0.0331 - precision: 0.9890 - recall: 0.9938\n",
            "Epoch 780/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9919 - f1_score: 0.8573 - loss: 0.0249 - precision: 0.9939 - recall: 0.9932 \n",
            "Epoch 781/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8422 - loss: 0.0333 - precision: 0.9927 - recall: 0.9907 \n",
            "Epoch 782/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9907 - f1_score: 0.8482 - loss: 0.0322 - precision: 0.9914 - recall: 0.9935 \n",
            "Epoch 783/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8465 - loss: 0.0314 - precision: 0.9920 - recall: 0.9892 \n",
            "Epoch 784/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8455 - loss: 0.0238 - precision: 0.9936 - recall: 0.9922 \n",
            "Epoch 785/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9942 - f1_score: 0.8442 - loss: 0.0219 - precision: 0.9956 - recall: 0.9950 \n",
            "Epoch 786/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9920 - f1_score: 0.8495 - loss: 0.0237 - precision: 0.9924 - recall: 0.9944 \n",
            "Epoch 787/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9933 - f1_score: 0.8430 - loss: 0.0234 - precision: 0.9939 - recall: 0.9951\n",
            "Epoch 788/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9888 - f1_score: 0.8539 - loss: 0.0314 - precision: 0.9892 - recall: 0.9929\n",
            "Epoch 789/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9893 - f1_score: 0.8377 - loss: 0.0266 - precision: 0.9911 - recall: 0.9915\n",
            "Epoch 790/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9896 - f1_score: 0.8456 - loss: 0.0246 - precision: 0.9907 - recall: 0.9924\n",
            "Epoch 791/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9946 - f1_score: 0.8470 - loss: 0.0173 - precision: 0.9969 - recall: 0.9943\n",
            "Epoch 792/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9900 - f1_score: 0.8483 - loss: 0.0274 - precision: 0.9888 - recall: 0.9953\n",
            "Epoch 793/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9893 - f1_score: 0.8594 - loss: 0.0291 - precision: 0.9916 - recall: 0.9913\n",
            "Epoch 794/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9819 - f1_score: 0.8337 - loss: 0.0504 - precision: 0.9833 - recall: 0.9876\n",
            "Epoch 795/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9803 - f1_score: 0.8451 - loss: 0.0617 - precision: 0.9812 - recall: 0.9866\n",
            "Epoch 796/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9813 - f1_score: 0.8398 - loss: 0.0482 - precision: 0.9810 - recall: 0.9886\n",
            "Epoch 797/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8375 - loss: 0.0309 - precision: 0.9914 - recall: 0.9914 \n",
            "Epoch 798/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9802 - f1_score: 0.8463 - loss: 0.0587 - precision: 0.9867 - recall: 0.9810 \n",
            "Epoch 799/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8362 - loss: 0.0332 - precision: 0.9880 - recall: 0.9946 \n",
            "Epoch 800/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9818 - f1_score: 0.8421 - loss: 0.0498 - precision: 0.9865 - recall: 0.9842 \n",
            "Epoch 801/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8482 - loss: 0.0467 - precision: 0.9853 - recall: 0.9845 \n",
            "Epoch 802/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8490 - loss: 0.0395 - precision: 0.9897 - recall: 0.9890 \n",
            "Epoch 803/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9788 - f1_score: 0.8296 - loss: 0.0661 - precision: 0.9820 - recall: 0.9831 \n",
            "Epoch 804/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9693 - f1_score: 0.8360 - loss: 0.1023 - precision: 0.9784 - recall: 0.9706\n",
            "Epoch 805/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9789 - f1_score: 0.8290 - loss: 0.0593 - precision: 0.9853 - recall: 0.9797 \n",
            "Epoch 806/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9745 - f1_score: 0.8353 - loss: 0.0878 - precision: 0.9829 - recall: 0.9759 \n",
            "Epoch 807/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9741 - f1_score: 0.8288 - loss: 0.0887 - precision: 0.9878 - recall: 0.9691 \n",
            "Epoch 808/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.8453 - loss: 0.0487 - precision: 0.9881 - recall: 0.9887 \n",
            "Epoch 809/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8365 - loss: 0.0490 - precision: 0.9846 - recall: 0.9870 \n",
            "Epoch 810/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9709 - f1_score: 0.8294 - loss: 0.0777 - precision: 0.9758 - recall: 0.9768 \n",
            "Epoch 811/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8290 - loss: 0.0336 - precision: 0.9885 - recall: 0.9925 \n",
            "Epoch 812/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9843 - f1_score: 0.8366 - loss: 0.0446 - precision: 0.9834 - recall: 0.9911 \n",
            "Epoch 813/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8270 - loss: 0.0350 - precision: 0.9882 - recall: 0.9896 \n",
            "Epoch 814/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9855 - f1_score: 0.8319 - loss: 0.0367 - precision: 0.9870 - recall: 0.9894 \n",
            "Epoch 815/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8387 - loss: 0.0387 - precision: 0.9883 - recall: 0.9926 \n",
            "Epoch 816/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8351 - loss: 0.0311 - precision: 0.9889 - recall: 0.9884 \n",
            "Epoch 817/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8274 - loss: 0.0300 - precision: 0.9877 - recall: 0.9937 \n",
            "Epoch 818/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8331 - loss: 0.0310 - precision: 0.9916 - recall: 0.9914 \n",
            "Epoch 819/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8331 - loss: 0.0244 - precision: 0.9925 - recall: 0.9955 \n",
            "Epoch 820/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8430 - loss: 0.0221 - precision: 0.9944 - recall: 0.9942 \n",
            "Epoch 821/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9932 - f1_score: 0.8523 - loss: 0.0217 - precision: 0.9945 - recall: 0.9946 \n",
            "Epoch 822/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8392 - loss: 0.0216 - precision: 0.9932 - recall: 0.9941 \n",
            "Epoch 823/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9908 - f1_score: 0.8437 - loss: 0.0244 - precision: 0.9917 - recall: 0.9936 \n",
            "Epoch 824/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8450 - loss: 0.0295 - precision: 0.9931 - recall: 0.9876 \n",
            "Epoch 825/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9933 - f1_score: 0.8422 - loss: 0.0217 - precision: 0.9955 - recall: 0.9934 \n",
            "Epoch 826/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8418 - loss: 0.0198 - precision: 0.9930 - recall: 0.9951 \n",
            "Epoch 827/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9963 - f1_score: 0.8425 - loss: 0.0198 - precision: 0.9971 - recall: 0.9968 \n",
            "Epoch 828/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9928 - f1_score: 0.8429 - loss: 0.0214 - precision: 0.9936 - recall: 0.9946 \n",
            "Epoch 829/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8494 - loss: 0.0233 - precision: 0.9924 - recall: 0.9897 \n",
            "Epoch 830/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9912 - f1_score: 0.8472 - loss: 0.0234 - precision: 0.9948 - recall: 0.9909 \n",
            "Epoch 831/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8480 - loss: 0.0301 - precision: 0.9953 - recall: 0.9876 \n",
            "Epoch 832/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9907 - f1_score: 0.8454 - loss: 0.0305 - precision: 0.9926 - recall: 0.9925 \n",
            "Epoch 833/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9924 - f1_score: 0.8444 - loss: 0.0216 - precision: 0.9919 - recall: 0.9958 \n",
            "Epoch 834/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8324 - loss: 0.0201 - precision: 0.9942 - recall: 0.9936 \n",
            "Epoch 835/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8476 - loss: 0.0316 - precision: 0.9911 - recall: 0.9918 \n",
            "Epoch 836/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9893 - f1_score: 0.8464 - loss: 0.0264 - precision: 0.9903 - recall: 0.9922 \n",
            "Epoch 837/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8448 - loss: 0.0236 - precision: 0.9930 - recall: 0.9943 \n",
            "Epoch 838/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9934 - f1_score: 0.8481 - loss: 0.0204 - precision: 0.9953 - recall: 0.9939 \n",
            "Epoch 839/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9937 - f1_score: 0.8457 - loss: 0.0213 - precision: 0.9965 - recall: 0.9933 \n",
            "Epoch 840/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8421 - loss: 0.0310 - precision: 0.9923 - recall: 0.9914 \n",
            "Epoch 841/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9902 - f1_score: 0.8466 - loss: 0.0270 - precision: 0.9946 - recall: 0.9896 \n",
            "Epoch 842/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9855 - f1_score: 0.8463 - loss: 0.0331 - precision: 0.9854 - recall: 0.9915 \n",
            "Epoch 843/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8565 - loss: 0.0277 - precision: 0.9939 - recall: 0.9917 \n",
            "Epoch 844/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8467 - loss: 0.0230 - precision: 0.9941 - recall: 0.9942 \n",
            "Epoch 845/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8353 - loss: 0.0299 - precision: 0.9905 - recall: 0.9908 \n",
            "Epoch 846/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9893 - f1_score: 0.8372 - loss: 0.0240 - precision: 0.9914 - recall: 0.9912 \n",
            "Epoch 847/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8574 - loss: 0.0289 - precision: 0.9978 - recall: 0.9886 \n",
            "Epoch 848/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9958 - f1_score: 0.8436 - loss: 0.0200 - precision: 0.9961 - recall: 0.9970 \n",
            "Epoch 849/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8537 - loss: 0.0213 - precision: 0.9946 - recall: 0.9935 \n",
            "Epoch 850/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8481 - loss: 0.0210 - precision: 0.9922 - recall: 0.9961 \n",
            "Epoch 851/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8580 - loss: 0.0256 - precision: 0.9875 - recall: 0.9961 \n",
            "Epoch 852/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9959 - f1_score: 0.8468 - loss: 0.0153 - precision: 0.9972 - recall: 0.9962 \n",
            "Epoch 853/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8469 - loss: 0.0187 - precision: 0.9929 - recall: 0.9958 \n",
            "Epoch 854/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9909 - f1_score: 0.8586 - loss: 0.0255 - precision: 0.9931 - recall: 0.9924\n",
            "Epoch 855/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8519 - loss: 0.0256 - precision: 0.9920 - recall: 0.9936 \n",
            "Epoch 856/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9910 - f1_score: 0.8392 - loss: 0.0250 - precision: 0.9925 - recall: 0.9926 \n",
            "Epoch 857/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8559 - loss: 0.0233 - precision: 0.9891 - recall: 0.9944 \n",
            "Epoch 858/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9935 - f1_score: 0.8458 - loss: 0.0198 - precision: 0.9937 - recall: 0.9956 \n",
            "Epoch 859/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8528 - loss: 0.0247 - precision: 0.9923 - recall: 0.9925 \n",
            "Epoch 860/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8551 - loss: 0.0238 - precision: 0.9912 - recall: 0.9949 \n",
            "Epoch 861/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8438 - loss: 0.0311 - precision: 0.9896 - recall: 0.9934 \n",
            "Epoch 862/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9906 - f1_score: 0.8399 - loss: 0.0307 - precision: 0.9899 - recall: 0.9947 \n",
            "Epoch 863/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8488 - loss: 0.0236 - precision: 0.9918 - recall: 0.9928 \n",
            "Epoch 864/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9899 - f1_score: 0.8572 - loss: 0.0298 - precision: 0.9914 - recall: 0.9921 \n",
            "Epoch 865/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9831 - f1_score: 0.8595 - loss: 0.0481 - precision: 0.9884 - recall: 0.9844 \n",
            "Epoch 866/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8527 - loss: 0.0335 - precision: 0.9882 - recall: 0.9896 \n",
            "Epoch 867/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8437 - loss: 0.0371 - precision: 0.9830 - recall: 0.9882 \n",
            "Epoch 868/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8463 - loss: 0.0238 - precision: 0.9945 - recall: 0.9914 \n",
            "Epoch 869/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8523 - loss: 0.0256 - precision: 0.9937 - recall: 0.9927 \n",
            "Epoch 870/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8478 - loss: 0.0309 - precision: 0.9911 - recall: 0.9900 \n",
            "Epoch 871/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9902 - f1_score: 0.8458 - loss: 0.0304 - precision: 0.9909 - recall: 0.9932\n",
            "Epoch 872/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9923 - f1_score: 0.8536 - loss: 0.0192 - precision: 0.9917 - recall: 0.9960 \n",
            "Epoch 873/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9875 - f1_score: 0.8580 - loss: 0.0367 - precision: 0.9887 - recall: 0.9914 \n",
            "Epoch 874/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8516 - loss: 0.0337 - precision: 0.9894 - recall: 0.9891 \n",
            "Epoch 875/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9910 - f1_score: 0.8434 - loss: 0.0266 - precision: 0.9941 - recall: 0.9912 \n",
            "Epoch 876/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8404 - loss: 0.0334 - precision: 0.9889 - recall: 0.9894 \n",
            "Epoch 877/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9852 - f1_score: 0.8544 - loss: 0.0341 - precision: 0.9869 - recall: 0.9896\n",
            "Epoch 878/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9907 - f1_score: 0.8499 - loss: 0.0305 - precision: 0.9910 - recall: 0.9942\n",
            "Epoch 879/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9886 - f1_score: 0.8380 - loss: 0.0458 - precision: 0.9919 - recall: 0.9893\n",
            "Epoch 880/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9792 - f1_score: 0.8497 - loss: 0.0526 - precision: 0.9831 - recall: 0.9833\n",
            "Epoch 881/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9819 - f1_score: 0.8491 - loss: 0.0502 - precision: 0.9868 - recall: 0.9834\n",
            "Epoch 882/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9841 - f1_score: 0.8439 - loss: 0.0384 - precision: 0.9857 - recall: 0.9882\n",
            "Epoch 883/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9791 - f1_score: 0.8395 - loss: 0.0828 - precision: 0.9811 - recall: 0.9845\n",
            "Epoch 884/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9766 - f1_score: 0.8473 - loss: 0.0709 - precision: 0.9792 - recall: 0.9831\n",
            "Epoch 885/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9739 - f1_score: 0.8534 - loss: 0.0789 - precision: 0.9818 - recall: 0.9766\n",
            "Epoch 886/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8462 - loss: 0.0517 - precision: 0.9875 - recall: 0.9835  \n",
            "Epoch 887/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9800 - f1_score: 0.8542 - loss: 0.0512 - precision: 0.9818 - recall: 0.9861\n",
            "Epoch 888/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8428 - loss: 0.0458 - precision: 0.9859 - recall: 0.9905 \n",
            "Epoch 889/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8525 - loss: 0.0416 - precision: 0.9898 - recall: 0.9885 \n",
            "Epoch 890/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9804 - f1_score: 0.8405 - loss: 0.0474 - precision: 0.9819 - recall: 0.9862 \n",
            "Epoch 891/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9878 - f1_score: 0.8487 - loss: 0.0344 - precision: 0.9936 - recall: 0.9867 \n",
            "Epoch 892/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9876 - f1_score: 0.8525 - loss: 0.0353 - precision: 0.9894 - recall: 0.9909 \n",
            "Epoch 893/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9888 - f1_score: 0.8499 - loss: 0.0297 - precision: 0.9884 - recall: 0.9936 \n",
            "Epoch 894/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8365 - loss: 0.0500 - precision: 0.9865 - recall: 0.9844 \n",
            "Epoch 895/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9780 - f1_score: 0.8467 - loss: 0.0531 - precision: 0.9814 - recall: 0.9830 \n",
            "Epoch 896/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9876 - f1_score: 0.8324 - loss: 0.0383 - precision: 0.9884 - recall: 0.9913 \n",
            "Epoch 897/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8357 - loss: 0.0594 - precision: 0.9837 - recall: 0.9846 \n",
            "Epoch 898/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8437 - loss: 0.0337 - precision: 0.9912 - recall: 0.9903 \n",
            "Epoch 899/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9891 - f1_score: 0.8366 - loss: 0.0381 - precision: 0.9899 - recall: 0.9924 \n",
            "Epoch 900/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8370 - loss: 0.0356 - precision: 0.9855 - recall: 0.9916 \n",
            "Epoch 901/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8443 - loss: 0.0425 - precision: 0.9896 - recall: 0.9860 \n",
            "Epoch 902/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8361 - loss: 0.0422 - precision: 0.9902 - recall: 0.9856 \n",
            "Epoch 903/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9857 - f1_score: 0.8508 - loss: 0.0576 - precision: 0.9899 - recall: 0.9871 \n",
            "Epoch 904/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9869 - f1_score: 0.8386 - loss: 0.0479 - precision: 0.9875 - recall: 0.9916 \n",
            "Epoch 905/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8392 - loss: 0.0430 - precision: 0.9858 - recall: 0.9902 \n",
            "Epoch 906/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8446 - loss: 0.0420 - precision: 0.9851 - recall: 0.9929 \n",
            "Epoch 907/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8484 - loss: 0.0340 - precision: 0.9942 - recall: 0.9866 \n",
            "Epoch 908/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8512 - loss: 0.0299 - precision: 0.9950 - recall: 0.9860 \n",
            "Epoch 909/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8387 - loss: 0.0305 - precision: 0.9866 - recall: 0.9945 \n",
            "Epoch 910/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8330 - loss: 0.0277 - precision: 0.9904 - recall: 0.9943 \n",
            "Epoch 911/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9856 - f1_score: 0.8365 - loss: 0.0343 - precision: 0.9915 - recall: 0.9848 \n",
            "Epoch 912/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8373 - loss: 0.0387 - precision: 0.9894 - recall: 0.9883 \n",
            "Epoch 913/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9851 - f1_score: 0.8393 - loss: 0.0459 - precision: 0.9927 - recall: 0.9832 \n",
            "Epoch 914/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8367 - loss: 0.0406 - precision: 0.9871 - recall: 0.9912 \n",
            "Epoch 915/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8333 - loss: 0.0611 - precision: 0.9847 - recall: 0.9844 \n",
            "Epoch 916/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8393 - loss: 0.0348 - precision: 0.9891 - recall: 0.9919 \n",
            "Epoch 917/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.8394 - loss: 0.0331 - precision: 0.9905 - recall: 0.9880 \n",
            "Epoch 918/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8405 - loss: 0.0272 - precision: 0.9906 - recall: 0.9928 \n",
            "Epoch 919/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8475 - loss: 0.0244 - precision: 0.9938 - recall: 0.9910 \n",
            "Epoch 920/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9923 - f1_score: 0.8306 - loss: 0.0284 - precision: 0.9949 - recall: 0.9925\n",
            "Epoch 921/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8299 - loss: 0.0291 - precision: 0.9933 - recall: 0.9895 \n",
            "Epoch 922/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8389 - loss: 0.0229 - precision: 0.9923 - recall: 0.9936 \n",
            "Epoch 923/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9925 - f1_score: 0.8389 - loss: 0.0255 - precision: 0.9943 - recall: 0.9934 \n",
            "Epoch 924/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9935 - f1_score: 0.8456 - loss: 0.0215 - precision: 0.9931 - recall: 0.9966 \n",
            "Epoch 925/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8379 - loss: 0.0248 - precision: 0.9908 - recall: 0.9896 \n",
            "Epoch 926/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8473 - loss: 0.0225 - precision: 0.9908 - recall: 0.9953 \n",
            "Epoch 927/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9923 - f1_score: 0.8490 - loss: 0.0229 - precision: 0.9933 - recall: 0.9941 \n",
            "Epoch 928/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8382 - loss: 0.0269 - precision: 0.9924 - recall: 0.9917 \n",
            "Epoch 929/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9928 - f1_score: 0.8453 - loss: 0.0237 - precision: 0.9937 - recall: 0.9946 \n",
            "Epoch 930/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8426 - loss: 0.0221 - precision: 0.9922 - recall: 0.9958 \n",
            "Epoch 931/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8418 - loss: 0.0218 - precision: 0.9948 - recall: 0.9931 \n",
            "Epoch 932/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9904 - f1_score: 0.8507 - loss: 0.0214 - precision: 0.9929 - recall: 0.9916 \n",
            "Epoch 933/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8513 - loss: 0.0305 - precision: 0.9894 - recall: 0.9903 \n",
            "Epoch 934/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8453 - loss: 0.0220 - precision: 0.9953 - recall: 0.9922 \n",
            "Epoch 935/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8370 - loss: 0.0255 - precision: 0.9940 - recall: 0.9920 \n",
            "Epoch 936/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8436 - loss: 0.0293 - precision: 0.9936 - recall: 0.9885 \n",
            "Epoch 937/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9877 - f1_score: 0.8539 - loss: 0.0318 - precision: 0.9918 - recall: 0.9885 \n",
            "Epoch 938/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9926 - f1_score: 0.8573 - loss: 0.0247 - precision: 0.9947 - recall: 0.9932 \n",
            "Epoch 939/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9905 - f1_score: 0.8572 - loss: 0.0256 - precision: 0.9917 - recall: 0.9928 \n",
            "Epoch 940/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9907 - f1_score: 0.8560 - loss: 0.0261 - precision: 0.9945 - recall: 0.9905\n",
            "Epoch 941/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8475 - loss: 0.0285 - precision: 0.9920 - recall: 0.9935 \n",
            "Epoch 942/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8483 - loss: 0.0260 - precision: 0.9919 - recall: 0.9922 \n",
            "Epoch 943/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8527 - loss: 0.0230 - precision: 0.9930 - recall: 0.9958 \n",
            "Epoch 944/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9917 - f1_score: 0.8444 - loss: 0.0240 - precision: 0.9962 - recall: 0.9903 \n",
            "Epoch 945/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8493 - loss: 0.0336 - precision: 0.9897 - recall: 0.9897 \n",
            "Epoch 946/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9721 - f1_score: 0.8416 - loss: 0.0857 - precision: 0.9748 - recall: 0.9803 \n",
            "Epoch 947/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9921 - f1_score: 0.8473 - loss: 0.0262 - precision: 0.9933 - recall: 0.9938 \n",
            "Epoch 948/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8515 - loss: 0.0295 - precision: 0.9888 - recall: 0.9947 \n",
            "Epoch 949/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8506 - loss: 0.0463 - precision: 0.9874 - recall: 0.9856 \n",
            "Epoch 950/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8466 - loss: 0.0587 - precision: 0.9873 - recall: 0.9897 \n",
            "Epoch 951/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9932 - f1_score: 0.8468 - loss: 0.0248 - precision: 0.9931 - recall: 0.9958 \n",
            "Epoch 952/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9907 - f1_score: 0.8387 - loss: 0.0345 - precision: 0.9941 - recall: 0.9906\n",
            "Epoch 953/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8539 - loss: 0.0365 - precision: 0.9890 - recall: 0.9880 \n",
            "Epoch 954/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8463 - loss: 0.0399 - precision: 0.9934 - recall: 0.9848 \n",
            "Epoch 955/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8388 - loss: 0.0525 - precision: 0.9852 - recall: 0.9859 \n",
            "Epoch 956/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8584 - loss: 0.0384 - precision: 0.9870 - recall: 0.9906 \n",
            "Epoch 957/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8399 - loss: 0.0415 - precision: 0.9898 - recall: 0.9893 \n",
            "Epoch 958/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8423 - loss: 0.0370 - precision: 0.9899 - recall: 0.9879 \n",
            "Epoch 959/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8471 - loss: 0.0318 - precision: 0.9887 - recall: 0.9907 \n",
            "Epoch 960/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9910 - f1_score: 0.8508 - loss: 0.0323 - precision: 0.9916 - recall: 0.9939 \n",
            "Epoch 961/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9949 - f1_score: 0.8524 - loss: 0.0210 - precision: 0.9960 - recall: 0.9957 \n",
            "Epoch 962/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8524 - loss: 0.0227 - precision: 0.9932 - recall: 0.9933 \n",
            "Epoch 963/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8544 - loss: 0.0381 - precision: 0.9859 - recall: 0.9913 \n",
            "Epoch 964/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9873 - f1_score: 0.8424 - loss: 0.0326 - precision: 0.9905 - recall: 0.9890\n",
            "Epoch 965/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9887 - f1_score: 0.8575 - loss: 0.0322 - precision: 0.9904 - recall: 0.9912\n",
            "Epoch 966/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9899 - f1_score: 0.8492 - loss: 0.0265 - precision: 0.9932 - recall: 0.9903\n",
            "Epoch 967/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9947 - f1_score: 0.8511 - loss: 0.0169 - precision: 0.9978 - recall: 0.9937\n",
            "Epoch 968/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9932 - f1_score: 0.8573 - loss: 0.0186 - precision: 0.9935 - recall: 0.9954\n",
            "Epoch 969/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9895 - f1_score: 0.8531 - loss: 0.0261 - precision: 0.9927 - recall: 0.9902\n",
            "Epoch 970/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9892 - f1_score: 0.8475 - loss: 0.0259 - precision: 0.9934 - recall: 0.9890\n",
            "Epoch 971/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9882 - f1_score: 0.8509 - loss: 0.0303 - precision: 0.9910 - recall: 0.9898\n",
            "Epoch 972/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9923 - f1_score: 0.8489 - loss: 0.0215 - precision: 0.9919 - recall: 0.9956 \n",
            "Epoch 973/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9910 - f1_score: 0.8408 - loss: 0.0244 - precision: 0.9950 - recall: 0.9902 \n",
            "Epoch 974/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8541 - loss: 0.0237 - precision: 0.9935 - recall: 0.9927 \n",
            "Epoch 975/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8396 - loss: 0.0283 - precision: 0.9951 - recall: 0.9929 \n",
            "Epoch 976/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9910 - f1_score: 0.8553 - loss: 0.0238 - precision: 0.9945 - recall: 0.9911 \n",
            "Epoch 977/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9937 - f1_score: 0.8539 - loss: 0.0186 - precision: 0.9950 - recall: 0.9950 \n",
            "Epoch 978/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9964 - f1_score: 0.8511 - loss: 0.0161 - precision: 0.9980 - recall: 0.9962 \n",
            "Epoch 979/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9915 - f1_score: 0.8576 - loss: 0.0216 - precision: 0.9945 - recall: 0.9919 \n",
            "Epoch 980/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9929 - f1_score: 0.8497 - loss: 0.0217 - precision: 0.9943 - recall: 0.9943 \n",
            "Epoch 981/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9924 - f1_score: 0.8585 - loss: 0.0210 - precision: 0.9928 - recall: 0.9951 \n",
            "Epoch 982/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9855 - f1_score: 0.8510 - loss: 0.0418 - precision: 0.9886 - recall: 0.9879 \n",
            "Epoch 983/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8523 - loss: 0.0271 - precision: 0.9949 - recall: 0.9880 \n",
            "Epoch 984/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8427 - loss: 0.0327 - precision: 0.9918 - recall: 0.9914 \n",
            "Epoch 985/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9956 - f1_score: 0.8579 - loss: 0.0171 - precision: 0.9954 - recall: 0.9975 \n",
            "Epoch 986/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9940 - f1_score: 0.8537 - loss: 0.0189 - precision: 0.9938 - recall: 0.9965 \n",
            "Epoch 987/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9901 - f1_score: 0.8571 - loss: 0.0263 - precision: 0.9920 - recall: 0.9921 \n",
            "Epoch 988/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9889 - f1_score: 0.8551 - loss: 0.0341 - precision: 0.9916 - recall: 0.9906 \n",
            "Epoch 989/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9921 - f1_score: 0.8526 - loss: 0.0222 - precision: 0.9946 - recall: 0.9926 \n",
            "Epoch 990/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9891 - f1_score: 0.8605 - loss: 0.0281 - precision: 0.9910 - recall: 0.9916 \n",
            "Epoch 991/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8410 - loss: 0.0220 - precision: 0.9952 - recall: 0.9905 \n",
            "Epoch 992/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9891 - f1_score: 0.8543 - loss: 0.0305 - precision: 0.9893 - recall: 0.9931 \n",
            "Epoch 993/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8511 - loss: 0.0307 - precision: 0.9893 - recall: 0.9919 \n",
            "Epoch 994/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9914 - f1_score: 0.8549 - loss: 0.0275 - precision: 0.9928 - recall: 0.9931 \n",
            "Epoch 995/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8505 - loss: 0.0245 - precision: 0.9922 - recall: 0.9935 \n",
            "Epoch 996/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8553 - loss: 0.0282 - precision: 0.9904 - recall: 0.9914 \n",
            "Epoch 997/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9887 - f1_score: 0.8488 - loss: 0.0289 - precision: 0.9915 - recall: 0.9901 \n",
            "Epoch 998/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9924 - f1_score: 0.8518 - loss: 0.0245 - precision: 0.9949 - recall: 0.9927 \n",
            "Epoch 999/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9881 - f1_score: 0.8550 - loss: 0.0279 - precision: 0.9939 - recall: 0.9867 \n",
            "Epoch 1000/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9880 - f1_score: 0.8433 - loss: 0.0309 - precision: 0.9883 - recall: 0.9923\n",
            "\n",
            "==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - binary_accuracy: 0.8354 - f1_score: 0.8091 - loss: 1.8452 - precision: 0.8480 - recall: 0.8932\n",
            "Accuracy en Conjunto de Prueba: 0.8354\n",
            "Precision en Conjunto de Prueba: 0.8480\n",
            "Recall en Conjunto de Prueba: 0.8932\n",
            "F1-Score en Conjunto de Prueba: 0.8091\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Clase 0       0.81      0.74      0.78       303\n",
            "     Clase 1       0.85      0.89      0.87       487\n",
            "\n",
            "    accuracy                           0.84       790\n",
            "   macro avg       0.83      0.82      0.82       790\n",
            "weighted avg       0.83      0.84      0.83       790\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}