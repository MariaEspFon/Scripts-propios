{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaEspFon/Scripts-propios/blob/main/TensorFlow/CNN_model_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNAOn5Ia7pG"
      },
      "source": [
        "# OPTIMIZACIÓN DE HIPERPARÁMETROS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhxVlFL7j4N6"
      },
      "source": [
        "## 1. Inicialización de Keras y TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcFrOCQOYU1R",
        "outputId": "d61e7fc3-611d-4e1a-ee48-393012d0f401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version:  2.18.0\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "#print(\"Keras version: \", tf.keras.__version__)\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtndO_D__Z2T"
      },
      "source": [
        "## 2. Carga de datos EDA desde Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niPo3Nfh-bVz",
        "outputId": "cb698876-2293-4af8-9144-44935bac31c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset: (3949, 21)\n",
            "Recuento de instancias por clase:\n",
            "State\n",
            "1    2435\n",
            "0    1514\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/MariaEspFon/Scripts-propios/main/MATLAB/EDA_D7.2_EMA.csv'\n",
        "column_names = ['Mean','Median', 'Standard Dev', 'Max Value', 'Min Value', 'Standard Dev 1st diff', 'Median 1st diff', 'Standard Dev 2nd diff',\n",
        "                'Total Area', 'Kurtosis', 'SCR', 'Power', '99% Bandwidth', 'Top Bandwidth Frequency',\n",
        "                'Phasic mean', 'Phasic Stdev', 'Phasic AuC', 'Tonic mean', 'Tonic Stdev', 'Tonic AuC',\n",
        "                'State']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names, sep=',', skipinitialspace=True)\n",
        "\n",
        "size = raw_dataset.shape\n",
        "print(f'Formato del dataset: {size}')\n",
        "\n",
        "class_counts = raw_dataset['State'].value_counts()\n",
        "print(\"Recuento de instancias por clase:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WEvgfenf-pEf",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "e677a28f-e000-4bb7-aefe-a863ab215bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Mean    Median  Standard Dev  Max Value  Min Value  \\\n",
              "4466  1.466113  1.566922      1.261131   3.142194  -0.076818   \n",
              "4467  0.540481  0.034924      0.963236   3.007747  -0.231767   \n",
              "4468  2.449819  2.981136      1.047429   3.098601   0.061658   \n",
              "4469  2.944428  2.946765      0.031031   3.030734   2.796635   \n",
              "4470  2.840264  2.868869      0.263836   2.909742   0.000000   \n",
              "\n",
              "      Standard Dev 1st diff  Median 1st diff  Standard Dev 2nd diff  \\\n",
              "4466               0.183625         0.002763               0.093909   \n",
              "4467               0.171018         0.000410               0.068237   \n",
              "4468               0.102151         0.000678               0.043690   \n",
              "4469               0.014701        -0.000828               0.009593   \n",
              "4470               0.257542        -0.000595               0.258572   \n",
              "\n",
              "      Total Area    Kurtosis  ...        Power  99% Bandwidth  \\\n",
              "4466  174.826977    1.231085  ...   447.202123       0.517393   \n",
              "4467   63.761552    3.701841  ...   145.465354       0.969150   \n",
              "4468  292.429905    3.509624  ...   850.749576       0.402680   \n",
              "4469  350.382482   10.605559  ...  1040.473268       0.016502   \n",
              "4470  339.376835  113.812119  ...   976.335639       0.806445   \n",
              "\n",
              "      Top Bandwidth Frequency  Phasic mean  Phasic Stdev  Phasic AuC  \\\n",
              "4466                 0.517538     2.650141      3.726599   78.992107   \n",
              "4467                 0.969496     1.919576      2.938044   54.869583   \n",
              "4468                 0.402778     1.049711      1.670153   31.491325   \n",
              "4469                 0.016585     0.072713      0.296073    2.045646   \n",
              "4470                 0.806529     0.539952      1.058184   16.198553   \n",
              "\n",
              "      Tonic mean  Tonic Stdev   Tonic AuC  State  \n",
              "4466   -3.209107     1.263214  -95.019918      1  \n",
              "4467   -3.763126     1.339107 -111.580315      1  \n",
              "4468   -0.741003     1.967254  -21.775323      1  \n",
              "4469    1.257076     0.145131   37.424606      1  \n",
              "4470    0.802859     0.775748   23.916348      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943dd167-7b22-4994-b1a4-4fdfd511c5c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Standard Dev</th>\n",
              "      <th>Max Value</th>\n",
              "      <th>Min Value</th>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <th>Median 1st diff</th>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <th>Total Area</th>\n",
              "      <th>Kurtosis</th>\n",
              "      <th>...</th>\n",
              "      <th>Power</th>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <th>Phasic mean</th>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <th>Phasic AuC</th>\n",
              "      <th>Tonic mean</th>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <th>Tonic AuC</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>1.466113</td>\n",
              "      <td>1.566922</td>\n",
              "      <td>1.261131</td>\n",
              "      <td>3.142194</td>\n",
              "      <td>-0.076818</td>\n",
              "      <td>0.183625</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.093909</td>\n",
              "      <td>174.826977</td>\n",
              "      <td>1.231085</td>\n",
              "      <td>...</td>\n",
              "      <td>447.202123</td>\n",
              "      <td>0.517393</td>\n",
              "      <td>0.517538</td>\n",
              "      <td>2.650141</td>\n",
              "      <td>3.726599</td>\n",
              "      <td>78.992107</td>\n",
              "      <td>-3.209107</td>\n",
              "      <td>1.263214</td>\n",
              "      <td>-95.019918</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>0.540481</td>\n",
              "      <td>0.034924</td>\n",
              "      <td>0.963236</td>\n",
              "      <td>3.007747</td>\n",
              "      <td>-0.231767</td>\n",
              "      <td>0.171018</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.068237</td>\n",
              "      <td>63.761552</td>\n",
              "      <td>3.701841</td>\n",
              "      <td>...</td>\n",
              "      <td>145.465354</td>\n",
              "      <td>0.969150</td>\n",
              "      <td>0.969496</td>\n",
              "      <td>1.919576</td>\n",
              "      <td>2.938044</td>\n",
              "      <td>54.869583</td>\n",
              "      <td>-3.763126</td>\n",
              "      <td>1.339107</td>\n",
              "      <td>-111.580315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4468</th>\n",
              "      <td>2.449819</td>\n",
              "      <td>2.981136</td>\n",
              "      <td>1.047429</td>\n",
              "      <td>3.098601</td>\n",
              "      <td>0.061658</td>\n",
              "      <td>0.102151</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.043690</td>\n",
              "      <td>292.429905</td>\n",
              "      <td>3.509624</td>\n",
              "      <td>...</td>\n",
              "      <td>850.749576</td>\n",
              "      <td>0.402680</td>\n",
              "      <td>0.402778</td>\n",
              "      <td>1.049711</td>\n",
              "      <td>1.670153</td>\n",
              "      <td>31.491325</td>\n",
              "      <td>-0.741003</td>\n",
              "      <td>1.967254</td>\n",
              "      <td>-21.775323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4469</th>\n",
              "      <td>2.944428</td>\n",
              "      <td>2.946765</td>\n",
              "      <td>0.031031</td>\n",
              "      <td>3.030734</td>\n",
              "      <td>2.796635</td>\n",
              "      <td>0.014701</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>0.009593</td>\n",
              "      <td>350.382482</td>\n",
              "      <td>10.605559</td>\n",
              "      <td>...</td>\n",
              "      <td>1040.473268</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>0.016585</td>\n",
              "      <td>0.072713</td>\n",
              "      <td>0.296073</td>\n",
              "      <td>2.045646</td>\n",
              "      <td>1.257076</td>\n",
              "      <td>0.145131</td>\n",
              "      <td>37.424606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4470</th>\n",
              "      <td>2.840264</td>\n",
              "      <td>2.868869</td>\n",
              "      <td>0.263836</td>\n",
              "      <td>2.909742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257542</td>\n",
              "      <td>-0.000595</td>\n",
              "      <td>0.258572</td>\n",
              "      <td>339.376835</td>\n",
              "      <td>113.812119</td>\n",
              "      <td>...</td>\n",
              "      <td>976.335639</td>\n",
              "      <td>0.806445</td>\n",
              "      <td>0.806529</td>\n",
              "      <td>0.539952</td>\n",
              "      <td>1.058184</td>\n",
              "      <td>16.198553</td>\n",
              "      <td>0.802859</td>\n",
              "      <td>0.775748</td>\n",
              "      <td>23.916348</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943dd167-7b22-4994-b1a4-4fdfd511c5c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "raw_dataset.tail() # muestra las últimas 5 filas por defecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Cqjf_xnwpw"
      },
      "outputs": [],
      "source": [
        "raw_dataset.head() # muestra las primeras 5 filas por defecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9-FGkx3glzZ"
      },
      "source": [
        "## 3. Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBXjhOwa_eFh"
      },
      "source": [
        "### 3.1. Extracción de los conjuntos de entrenamiento, prueba y validación\n",
        "\n",
        "*   Datos de **entrenamiento**: para el aprendizaje de parámetros.\n",
        "*   Datos de **prueba**: para hacer test de predicciones.\n",
        "*   Datos de **validación**: para afinar hiperparámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wtq9cEZV_V-m"
      },
      "outputs": [],
      "source": [
        "# Extracción de subconjuntos: bloque de código para mantener la proporción de clases\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = raw_dataset.drop('State', axis=1)\n",
        "labels = raw_dataset['State']\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "FekCNTKP_WBI",
        "outputId": "81ff29ac-0f52-4a32-8118-dd6e4ba31de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count         mean          std           min  \\\n",
              "Mean                     3159.0     1.461257     2.688161  2.881417e-04   \n",
              "Median                   3159.0     1.466649     2.710469  0.000000e+00   \n",
              "Standard Dev             3159.0     0.144952     0.381106  4.706701e-04   \n",
              "Max Value                3159.0     1.704078     2.942718  4.779257e-03   \n",
              "Min Value                3159.0     1.193842     2.469216  0.000000e+00   \n",
              "Standard Dev 1st diff    3159.0     0.022006     0.039530  3.494808e-04   \n",
              "Median 1st diff          3159.0    -0.000315     0.003921 -1.093078e-01   \n",
              "Standard Dev 2nd diff    3159.0     0.018383     0.029861  4.191872e-04   \n",
              "Total Area               3159.0   173.890366   319.923866  3.457700e-02   \n",
              "Kurtosis                 3159.0     5.549862     7.382169  1.057126e+00   \n",
              "SCR                      3159.0     1.063944     2.344673  0.000000e+00   \n",
              "Power                    3159.0  1142.881747  3839.609331  1.060477e-04   \n",
              "99% Bandwidth            3159.0     0.182056     0.350587  1.650002e-02   \n",
              "Top Bandwidth Frequency  3159.0     0.182157     0.350636  1.658335e-02   \n",
              "Phasic mean              3159.0     0.606996     1.303538  4.475971e-08   \n",
              "Phasic Stdev             3159.0     0.966032     1.883792  1.652074e-08   \n",
              "Phasic AuC               3159.0    18.063914    38.840793  1.331816e-06   \n",
              "Tonic mean               3159.0    -0.782682     1.836786 -2.952807e+01   \n",
              "Tonic Stdev              3159.0     0.433241     0.832538  1.055206e-04   \n",
              "Tonic AuC                3159.0   -23.288679    54.738380 -8.829021e+02   \n",
              "\n",
              "                               25%        50%         75%           max  \n",
              "Mean                      0.249013   0.433919    1.120415     16.873588  \n",
              "Median                    0.241514   0.431638    1.125672     17.060042  \n",
              "Standard Dev              0.005087   0.024107    0.121097      6.510492  \n",
              "Max Value                 0.293813   0.496918    1.504204     17.572616  \n",
              "Min Value                 0.140055   0.314706    0.660940     16.098618  \n",
              "Standard Dev 1st diff     0.001248   0.005013    0.023161      0.471897  \n",
              "Median 1st diff          -0.000351  -0.000024    0.000155      0.048991  \n",
              "Standard Dev 2nd diff     0.001694   0.004379    0.020992      0.258629  \n",
              "Total Area               29.601951  51.637832  133.571556   2013.300593  \n",
              "Kurtosis                  2.075404   2.857487    5.505709    113.896441  \n",
              "SCR                       0.000000   0.000000    1.000000     24.000000  \n",
              "Power                     7.913682  23.449923  171.273761  34363.988284  \n",
              "99% Bandwidth             0.016504   0.016529    0.167778      1.982856  \n",
              "Top Bandwidth Frequency   0.016587   0.016612    0.167895      1.983451  \n",
              "Phasic mean               0.018716   0.101285    0.523234     21.397006  \n",
              "Phasic Stdev              0.053579   0.223113    0.967546     35.095213  \n",
              "Phasic AuC                0.551897   2.997145   15.523808    638.941089  \n",
              "Tonic mean               -1.153674  -0.500970    0.136751      3.422684  \n",
              "Tonic Stdev               0.027316   0.098597    0.515756     16.795811  \n",
              "Tonic AuC               -34.324767 -14.913256    4.080784    101.863348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c00c946c-54b5-44e1-a365-39a667a2068f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.461257</td>\n",
              "      <td>2.688161</td>\n",
              "      <td>2.881417e-04</td>\n",
              "      <td>0.249013</td>\n",
              "      <td>0.433919</td>\n",
              "      <td>1.120415</td>\n",
              "      <td>16.873588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.466649</td>\n",
              "      <td>2.710469</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.241514</td>\n",
              "      <td>0.431638</td>\n",
              "      <td>1.125672</td>\n",
              "      <td>17.060042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.144952</td>\n",
              "      <td>0.381106</td>\n",
              "      <td>4.706701e-04</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.024107</td>\n",
              "      <td>0.121097</td>\n",
              "      <td>6.510492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.704078</td>\n",
              "      <td>2.942718</td>\n",
              "      <td>4.779257e-03</td>\n",
              "      <td>0.293813</td>\n",
              "      <td>0.496918</td>\n",
              "      <td>1.504204</td>\n",
              "      <td>17.572616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.193842</td>\n",
              "      <td>2.469216</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.314706</td>\n",
              "      <td>0.660940</td>\n",
              "      <td>16.098618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.022006</td>\n",
              "      <td>0.039530</td>\n",
              "      <td>3.494808e-04</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0.023161</td>\n",
              "      <td>0.471897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>-1.093078e-01</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.048991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>0.029861</td>\n",
              "      <td>4.191872e-04</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.258629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>173.890366</td>\n",
              "      <td>319.923866</td>\n",
              "      <td>3.457700e-02</td>\n",
              "      <td>29.601951</td>\n",
              "      <td>51.637832</td>\n",
              "      <td>133.571556</td>\n",
              "      <td>2013.300593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.549862</td>\n",
              "      <td>7.382169</td>\n",
              "      <td>1.057126e+00</td>\n",
              "      <td>2.075404</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>5.505709</td>\n",
              "      <td>113.896441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.063944</td>\n",
              "      <td>2.344673</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1142.881747</td>\n",
              "      <td>3839.609331</td>\n",
              "      <td>1.060477e-04</td>\n",
              "      <td>7.913682</td>\n",
              "      <td>23.449923</td>\n",
              "      <td>171.273761</td>\n",
              "      <td>34363.988284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182056</td>\n",
              "      <td>0.350587</td>\n",
              "      <td>1.650002e-02</td>\n",
              "      <td>0.016504</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.167778</td>\n",
              "      <td>1.982856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182157</td>\n",
              "      <td>0.350636</td>\n",
              "      <td>1.658335e-02</td>\n",
              "      <td>0.016587</td>\n",
              "      <td>0.016612</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>1.983451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.606996</td>\n",
              "      <td>1.303538</td>\n",
              "      <td>4.475971e-08</td>\n",
              "      <td>0.018716</td>\n",
              "      <td>0.101285</td>\n",
              "      <td>0.523234</td>\n",
              "      <td>21.397006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.966032</td>\n",
              "      <td>1.883792</td>\n",
              "      <td>1.652074e-08</td>\n",
              "      <td>0.053579</td>\n",
              "      <td>0.223113</td>\n",
              "      <td>0.967546</td>\n",
              "      <td>35.095213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>18.063914</td>\n",
              "      <td>38.840793</td>\n",
              "      <td>1.331816e-06</td>\n",
              "      <td>0.551897</td>\n",
              "      <td>2.997145</td>\n",
              "      <td>15.523808</td>\n",
              "      <td>638.941089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.782682</td>\n",
              "      <td>1.836786</td>\n",
              "      <td>-2.952807e+01</td>\n",
              "      <td>-1.153674</td>\n",
              "      <td>-0.500970</td>\n",
              "      <td>0.136751</td>\n",
              "      <td>3.422684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.832538</td>\n",
              "      <td>1.055206e-04</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.098597</td>\n",
              "      <td>0.515756</td>\n",
              "      <td>16.795811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-23.288679</td>\n",
              "      <td>54.738380</td>\n",
              "      <td>-8.829021e+02</td>\n",
              "      <td>-34.324767</td>\n",
              "      <td>-14.913256</td>\n",
              "      <td>4.080784</td>\n",
              "      <td>101.863348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c00c946c-54b5-44e1-a365-39a667a2068f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c00c946c-54b5-44e1-a365-39a667a2068f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c00c946c-54b5-44e1-a365-39a667a2068f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c04cf89b-8d12-4cbe-8ded-f76614cfa5ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c04cf89b-8d12-4cbe-8ded-f76614cfa5ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c04cf89b-8d12-4cbe-8ded-f76614cfa5ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e9b09b12-da6b-43e3-a24e-d1f5b72443d5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e9b09b12-da6b-43e3-a24e-d1f5b72443d5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_stats",
              "summary": "{\n  \"name\": \"train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.43774243066844,\n        \"min\": -23.288679302492756,\n        \"max\": 1142.8817465910665,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.4612569864023432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856.3494010607636,\n        \"min\": 0.003920865966528552,\n        \"max\": 3839.6093312957755,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.688160769255659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.1982611498348,\n        \"min\": -882.902109713819,\n        \"max\": 1.05712563449178,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0002881416666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.567138491113965,\n        \"min\": -34.3247668007665,\n        \"max\": 29.601950522781898,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.24901303990454848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.034024453837553,\n        \"min\": -14.9132560124876,\n        \"max\": 51.6378323985219,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.43391925352509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.88127532395101,\n        \"min\": 0.000155043576272,\n        \"max\": 171.27376076324,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.120414963183705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7661.905667264518,\n        \"min\": 0.0489910736836237,\n        \"max\": 34363.988283576,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          16.873587916458\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_size = train_dataset.shape\n",
        "test_size = test_dataset.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syU3bAgjhaZb"
      },
      "source": [
        "### 3.2. Normalización y estandarización de todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "V6-D516VCSUe",
        "outputId": "9af1586a-134d-4999-e80c-fddcf2c833fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count          mean  std        min       25%  \\\n",
              "Mean                     3159.0  8.997059e-18  1.0  -0.543483 -0.450957   \n",
              "Median                   3159.0 -1.462022e-17  1.0  -0.541105 -0.452001   \n",
              "Standard Dev             3159.0  6.410405e-17  1.0  -0.379110 -0.366997   \n",
              "Max Value                3159.0 -3.261434e-17  1.0  -0.577459 -0.479239   \n",
              "Min Value                3159.0  1.349559e-17  1.0  -0.483490 -0.426770   \n",
              "Standard Dev 1st diff    3159.0  8.997059e-17  1.0  -0.547850 -0.525124   \n",
              "Median 1st diff          3159.0  8.997059e-18  1.0 -27.798013 -0.008976   \n",
              "Standard Dev 2nd diff    3159.0  1.012169e-16  1.0  -0.601592 -0.558901   \n",
              "Total Area               3159.0 -1.135879e-16  1.0  -0.543429 -0.451009   \n",
              "Kurtosis                 3159.0 -5.848088e-17  1.0  -0.608593 -0.470655   \n",
              "SCR                      3159.0 -3.036507e-17  1.0  -0.453771 -0.453771   \n",
              "Power                    3159.0 -2.249265e-17  1.0  -0.297656 -0.295595   \n",
              "99% Bandwidth            3159.0 -2.474191e-17  1.0  -0.472226 -0.472214   \n",
              "Top Bandwidth Frequency  3159.0 -6.185478e-18  1.0  -0.472211 -0.472199   \n",
              "Phasic mean              3159.0 -2.305496e-17  1.0  -0.465652 -0.451294   \n",
              "Phasic Stdev             3159.0  5.623162e-19  1.0  -0.512813 -0.484370   \n",
              "Phasic AuC               3159.0 -1.433906e-17  1.0  -0.465076 -0.450867   \n",
              "Tonic mean               3159.0 -5.117077e-17  1.0 -15.649830 -0.201979   \n",
              "Tonic Stdev              3159.0  2.924044e-17  1.0  -0.520259 -0.487576   \n",
              "Tonic AuC                3159.0 -6.579099e-17  1.0 -15.704035 -0.201615   \n",
              "\n",
              "                              50%       75%        max  \n",
              "Mean                    -0.382171 -0.126794   5.733411  \n",
              "Median                  -0.381857 -0.125800   5.753023  \n",
              "Standard Dev            -0.317089 -0.062595  16.702809  \n",
              "Max Value               -0.410220 -0.067921   5.392477  \n",
              "Min Value               -0.356038 -0.215818   6.036239  \n",
              "Standard Dev 1st diff   -0.429885  0.029211  11.380875  \n",
              "Median 1st diff          0.074262  0.120010  12.575429  \n",
              "Standard Dev 2nd diff   -0.468976  0.087356   8.045450  \n",
              "Total Area              -0.382130 -0.126026   5.749525  \n",
              "Kurtosis                -0.364713 -0.005981  14.676795  \n",
              "SCR                     -0.453771 -0.027272   9.782197  \n",
              "Power                   -0.291548 -0.253049   8.652210  \n",
              "99% Bandwidth           -0.472143 -0.040728   5.136521  \n",
              "Top Bandwidth Frequency -0.472128 -0.040677   5.137217  \n",
              "Phasic mean             -0.387952 -0.064257  15.948907  \n",
              "Phasic Stdev            -0.394374  0.000804  18.117274  \n",
              "Phasic AuC              -0.387911 -0.065398  15.985183  \n",
              "Tonic mean               0.153372  0.500566   2.289524  \n",
              "Tonic Stdev             -0.401957  0.099112  19.653834  \n",
              "Tonic AuC                0.153008  0.500005   2.286367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80fba74f-e9b4-438f-bbda-ef7eb80244f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543483</td>\n",
              "      <td>-0.450957</td>\n",
              "      <td>-0.382171</td>\n",
              "      <td>-0.126794</td>\n",
              "      <td>5.733411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.462022e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.541105</td>\n",
              "      <td>-0.452001</td>\n",
              "      <td>-0.381857</td>\n",
              "      <td>-0.125800</td>\n",
              "      <td>5.753023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>6.410405e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.379110</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-0.317089</td>\n",
              "      <td>-0.062595</td>\n",
              "      <td>16.702809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.261434e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.577459</td>\n",
              "      <td>-0.479239</td>\n",
              "      <td>-0.410220</td>\n",
              "      <td>-0.067921</td>\n",
              "      <td>5.392477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.349559e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.483490</td>\n",
              "      <td>-0.426770</td>\n",
              "      <td>-0.356038</td>\n",
              "      <td>-0.215818</td>\n",
              "      <td>6.036239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.547850</td>\n",
              "      <td>-0.525124</td>\n",
              "      <td>-0.429885</td>\n",
              "      <td>0.029211</td>\n",
              "      <td>11.380875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-27.798013</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.074262</td>\n",
              "      <td>0.120010</td>\n",
              "      <td>12.575429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.012169e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.601592</td>\n",
              "      <td>-0.558901</td>\n",
              "      <td>-0.468976</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>8.045450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.135879e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543429</td>\n",
              "      <td>-0.451009</td>\n",
              "      <td>-0.382130</td>\n",
              "      <td>-0.126026</td>\n",
              "      <td>5.749525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.848088e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.608593</td>\n",
              "      <td>-0.470655</td>\n",
              "      <td>-0.364713</td>\n",
              "      <td>-0.005981</td>\n",
              "      <td>14.676795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.036507e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.027272</td>\n",
              "      <td>9.782197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.249265e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.297656</td>\n",
              "      <td>-0.295595</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.253049</td>\n",
              "      <td>8.652210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.474191e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472226</td>\n",
              "      <td>-0.472214</td>\n",
              "      <td>-0.472143</td>\n",
              "      <td>-0.040728</td>\n",
              "      <td>5.136521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.185478e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472211</td>\n",
              "      <td>-0.472199</td>\n",
              "      <td>-0.472128</td>\n",
              "      <td>-0.040677</td>\n",
              "      <td>5.137217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.305496e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465652</td>\n",
              "      <td>-0.451294</td>\n",
              "      <td>-0.387952</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>15.948907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.623162e-19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.512813</td>\n",
              "      <td>-0.484370</td>\n",
              "      <td>-0.394374</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>18.117274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.433906e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465076</td>\n",
              "      <td>-0.450867</td>\n",
              "      <td>-0.387911</td>\n",
              "      <td>-0.065398</td>\n",
              "      <td>15.985183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.117077e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.649830</td>\n",
              "      <td>-0.201979</td>\n",
              "      <td>0.153372</td>\n",
              "      <td>0.500566</td>\n",
              "      <td>2.289524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>2.924044e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.520259</td>\n",
              "      <td>-0.487576</td>\n",
              "      <td>-0.401957</td>\n",
              "      <td>0.099112</td>\n",
              "      <td>19.653834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.579099e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.704035</td>\n",
              "      <td>-0.201615</td>\n",
              "      <td>0.153008</td>\n",
              "      <td>0.500005</td>\n",
              "      <td>2.286367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80fba74f-e9b4-438f-bbda-ef7eb80244f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80fba74f-e9b4-438f-bbda-ef7eb80244f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80fba74f-e9b4-438f-bbda-ef7eb80244f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3445c983-5b90-4050-8f20-322342cc6787\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3445c983-5b90-4050-8f20-322342cc6787')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3445c983-5b90-4050-8f20-322342cc6787 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e01fae83-50eb-4337-befa-c5e6d4e814ee\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('normed_train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e01fae83-50eb-4337-befa-c5e6d4e814ee button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('normed_train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "normed_train_stats",
              "summary": "{\n  \"name\": \"normed_train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.130827903032307e-17,\n        \"min\": -1.13587870072444e-16,\n        \"max\": 1.012169139259402e-16,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          8.997059015639129e-18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1848847376991577e-14,\n        \"min\": 0.9999999999999469,\n        \"max\": 1.000000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9999999999999469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.397919147016072,\n        \"min\": -27.798013059723413,\n        \"max\": -0.2976557097171227,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.5434826895194267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13303447554408515,\n        \"min\": -0.5589012867384386,\n        \"max\": -0.008976423627184933,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.4509566393357717\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1982775721363611,\n        \"min\": -0.47214325593943735,\n        \"max\": 0.15337222439091985,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.3821712393941821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19358796580988194,\n        \"min\": -0.2530486572965829,\n        \"max\": 0.500566267762931,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.12679376438970055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4656321224551565,\n        \"min\": 2.2863670387300563,\n        \"max\": 19.653834404298966,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          5.733411150971922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "train_size = normed_train_data.shape\n",
        "test_size = normed_test_data.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "normed_train_stats = normed_train_data.describe()\n",
        "normed_train_stats = normed_train_stats.transpose()\n",
        "normed_train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmNpCfOqCwqv"
      },
      "source": [
        "## 4.1. Optimización masiva de parámetros\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_conv_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(hp.Int('hidden_blocks', min_value=1, max_value=4)):\n",
        "        filters = hp.Int(f'n_filters{i}', min_value=4, max_value=32, step=4)\n",
        "        kernel_size = hp.Choice(f'size{i}', values=[2, 3, 4, 5])\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))  # Valor fijo para la etapa 1\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_conv_model(HyperParameters())\n",
        "\n",
        "tuner_1 = kt.BayesianOptimization(\n",
        "    build_conv_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage1',\n",
        "    project_name='cnn1d_conv_structure'\n",
        ")\n",
        "\n",
        "#28min 30s sin GPU"
      ],
      "metadata": {
        "id": "U_quo4A8uaj8",
        "outputId": "132e90ed-e37a-4eb8-fc64-143a289d0106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_1.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
        "\n",
        "best_hp1 = tuner_1.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp1.values"
      ],
      "metadata": {
        "id": "xgJLDUbVGQrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(best_hp1.get('hidden_blocks')):\n",
        "        filters = best_hp1.get(f'n_filters{i}')\n",
        "        kernel_size = best_hp1.get(f'size{i}')\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Aquí ajustamos solo los parámetros nuevos\n",
        "    dense_units = hp.Int('dense_units', min_value=16, max_value=128, step=8)\n",
        "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_final_model(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner_2 = kt.BayesianOptimization(\n",
        "    build_final_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage2',\n",
        "    project_name='cnn1d_dense_lr_batch'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "6DnGkCSIvH_h",
        "outputId": "0763117c-93aa-4313-ec4e-78ae6573516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │         \u001b[38;5;34m1,372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │           \u001b[38;5;34m112\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m5,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,101\u001b[0m (35.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,101</span> (35.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,981\u001b[0m (35.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,981</span> (35.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage2/cnn1d_dense_lr_batch/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_2.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
        "                    batch_size=kt.HyperParameters().Choice('batch_size', [128, 358, 537]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okut5Zt2GmPF",
        "outputId": "b6224996-120f-40e7-8d9a-2c09ada59879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.7332402169704437\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7618715167045593\n",
            "Total elapsed time: 01h 42m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp2 = tuner_2.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp2.values"
      ],
      "metadata": {
        "id": "w1IQLia14ibr",
        "outputId": "ee370ad5-4952-4a00-b0e0-2451b05df689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_units': 40, 'learning_rate': 0.0004578995948758916}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNb7pcumf33T"
      },
      "source": [
        "## 4.2. Optimización de hiperparámetros del mejor modelo conseguido"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_model_C1(hp):\n",
        "  model = Sequential()\n",
        "  filters1 = hp.Int('nfilters1', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters1, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters2 = hp.Int('nfilters2', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters2, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters3 = hp.Int('nfilters3', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters3, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Flatten())\n",
        "  dense_units = hp.Int('dense_units', min_value=16, max_value=64, step=4)\n",
        "  model.add(layers.Dense(dense_units, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "   # compilación del modelo\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "  return model\n",
        "\n",
        "model = build_model_C1(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model_C1,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning_stage',\n",
        "    project_name='TFG'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "KHuAnr0MfWC7",
        "outputId": "059a5330-06b0-449b-c789-7868f4b36636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,477\u001b[0m (5.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,477</span> (5.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,453\u001b[0m (5.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,453</span> (5.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage/TFG/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1T1WwGjonc",
        "outputId": "e77238f5-1c17-4c36-82ce-f681bd90a235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 27s]\n",
            "val_binary_accuracy: 0.7667597532272339\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7891061305999756\n",
            "Total elapsed time: 01h 01m 48s\n",
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nfilters1': 64, 'nfilters2': 52, 'nfilters3': 56, 'dense_units': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Optimización bayesiana con validación cruzada\n",
        "\n",
        "Mercedes no utilizó validación cruzada; realmente no parece que haga falta porque el dataset no es tan pequeño (supera las 1000 muestras)\n",
        "ESTÁ INCOMPLETO"
      ],
      "metadata": {
        "id": "rjQqaNgvECTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Asegúrate de tener normed_train_data, train_labels definidos antes de esto\n",
        "\n",
        "# Añadir dimensión para Conv1D\n",
        "#X = np.expand_dims(normed_train_data.values, axis=2)\n",
        "#y = train_labels.values\n",
        "\n",
        "# Función de construcción del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score()])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BD55-165EBGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación cruzada estratificada\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds_acc = []\n",
        "folds_precission = []\n",
        "folds_recall = []\n",
        "folds_f1 = []\n",
        "\n",
        "best_hyperparams = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(normed_train_data, train_labels)):\n",
        "    print(f'\\n🔁 Fold {fold+1}')\n",
        "\n",
        "    tuner = kt.BayesianOptimization(\n",
        "        build_model,\n",
        "        objective='val_binary_accuracy',\n",
        "        max_trials=10, #100\n",
        "        directory='bayes_cv',\n",
        "        project_name=f'fold_{fold}',\n",
        "        overwrite=True\n",
        "    )\n",
        "\n",
        "    X_train, X_val = normed_train_data.iloc[train_index], normed_train_data.iloc[val_index]\n",
        "    y_train, y_val = train_labels.iloc[train_index], train_labels.iloc[val_index]\n",
        "\n",
        "    tuner.search(X_train, y_train,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                 epochs=200, # 50 o 500 (uno más bajo y otro más alto, estudair el tiempo de ejecución a grandes rasgos)\n",
        "                 batch_size=ceil(len(train_index) * 0.1),\n",
        "                 verbose=1)\n",
        "\n",
        "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "    print(\"✅ Mejor optimizador:\", best_hp.get('optimizer'))\n",
        "    print(\"✅ Mejor tasa de aprendizaje:\", best_hp.get('learning_rate'))\n",
        "    best_hyperparams.append(best_hp)\n",
        "\n",
        "# Resultados promedio de los folds\n",
        "print(\"\\n📈 Accuracy promedio en validación cruzada:\", np.mean(folds_acc))\n"
      ],
      "metadata": {
        "id": "Lpoe_h8jIJ65",
        "outputId": "b9660e98-4719-4f2b-8756-f2350da1643b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 00s]\n",
            "val_binary_accuracy: 0.8415213823318481\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.8494453430175781\n",
            "Total elapsed time: 00h 09m 23s\n",
            "✅ Mejor optimizador: nadam\n",
            "✅ Mejor tasa de aprendizaje: 0.003939762513244005\n",
            "\n",
            "📈 Accuracy promedio en validación cruzada: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para construir el modelo con hiperparámetros\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1], 1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Hiperparámetros a optimizar\n",
        "    hp_optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
        "\n",
        "    if hp_optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=hp_learning_rate)\n",
        "    elif hp_optimizer == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=hp_learning_rate)\n",
        "    else:\n",
        "        optimizer = Nadam(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', keras.metrics.F1Score()])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Inicializa la búsqueda bayesiana\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=15,  # Número de combinaciones a probar\n",
        "    directory='bayesian_opt',\n",
        "    project_name='cnn_lr_opt'\n",
        ")\n",
        "\n",
        "# Divide entrenamiento en train/validation\n",
        "tuner.search(normed_train_data, train_labels.values,\n",
        "             epochs=100,\n",
        "             validation_split=0.2,\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             verbose=0)\n",
        "\n",
        "# Muestra los mejores resultados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "id": "FeVUuw1YlV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Gemini sugiere:"
      ],
      "metadata": {
        "id": "-pjdu1IsCHBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación simple"
      ],
      "metadata": {
        "id": "57WFLZh_C0k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from keras_tuner import HyperParameters\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "\n",
        "# Función de construcción del modelo (tu arquitectura original)\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Asegúrate de que input_shape es correcto para tus datos después de expand_dims\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(normed_train_data.shape[1], 1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Hiperparámetros a optimizar\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score(name='f1_score')])\n",
        "    return model\n",
        "\n",
        "print(\"\\n==================== 📈 Optimización de Hiperparámetros (Validación Simple) ====================\")\n",
        "\n",
        "# 2. Configurar e iniciar Keras Tuner para la optimización de hiperparámetros\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy', # El objetivo del tuner es la precisión de validación\n",
        "    max_trials=10, # Número de combinaciones de HP a probar\n",
        "    directory='keras_tuner_results',\n",
        "    project_name='simple_split_optimization',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15, # Número de épocas sin mejora\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2, # Keras Tuner usará el 25% de X_train_val para validación interna (20% del total)\n",
        "                                   # Esto resulta en un 60% entrenamiento, 20% validación, 20% prueba\n",
        "             epochs=200, # Max. épocas, early stopping lo detendrá\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# 3. Obtener los mejores hiperparámetros encontrados\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"✅ Mejores Hiperparámetros Encontrados:\")\n",
        "print(f\"  Optimizador: {best_hp.get('optimizer')}\")\n",
        "print(f\"  Tasa de Aprendizaje: {best_hp.get('learning_rate'):.1e}\")\n",
        "\n",
        "# 4. Construir y entrenar el modelo final con los mejores HP en todo el conjunto de entrenamiento+validación\n",
        "print(\"\\nEntrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento+validación...\")\n",
        "final_model = tuner.hypermodel.build(best_hp)\n",
        "final_model.fit(normed_train_data, train_labels,\n",
        "                epochs=200, # Usar las mismas épocas y early stopping\n",
        "                batch_size=ceil(train_size[0]*0.1),\n",
        "                callbacks=[early_stopping_callback],\n",
        "                verbose=1) # Poner en 1 para ver el progreso del entrenamiento final\n",
        "\n",
        "# 5. Evaluar el modelo final en el conjunto de prueba independiente\n",
        "print(\"\\n==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\")\n",
        "y_pred_probs = final_model.predict(normed_test_data).ravel()\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Calcular métricas finales\n",
        "acc = accuracy_score(test_labels, y_pred)\n",
        "prec = precision_score(test_labels, y_pred)\n",
        "rec = recall_score(test_labels, y_pred)\n",
        "f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "print(f\"Accuracy en Conjunto de Prueba: {acc:.4f}\")\n",
        "print(f\"Precision en Conjunto de Prueba: {prec:.4f}\")\n",
        "print(f\"Recall en Conjunto de Prueba: {rec:.4f}\")\n",
        "print(f\"F1-Score en Conjunto de Prueba: {f1:.4f}\")\n",
        "print(\"\\nReporte de Clasificación:\\n\", classification_report(test_labels, y_pred))\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "cm = tf.math.confusion_matrix(labels=test_labels, predictions=y_pred).numpy()\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "71xl8jrVCGGk",
        "outputId": "8c0f3689-c7c5-428a-9ce1-f6c11a25b7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 12s]\n",
            "val_binary_accuracy: 0.45094937086105347\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7990506291389465\n",
            "Total elapsed time: 00h 05m 07s\n",
            "✅ Mejores Hiperparámetros Encontrados:\n",
            "  Optimizador: nadam\n",
            "  Tasa de Aprendizaje: 8.7e-04\n",
            "\n",
            "Entrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento+validación...\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - binary_accuracy: 0.6114 - f1_score: 0.7608 - loss: 0.7352 - precision: 0.6230 - recall: 0.9315\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: binary_accuracy,f1_score,loss,precision,recall\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - binary_accuracy: 0.6359 - f1_score: 0.7657 - loss: 0.6384 - precision: 0.6451 - recall: 0.9188\n",
            "Epoch 3/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6631 - f1_score: 0.7719 - loss: 0.6074 - precision: 0.6718 - recall: 0.9077 \n",
            "Epoch 4/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6681 - f1_score: 0.7554 - loss: 0.6026 - precision: 0.6722 - recall: 0.8856 \n",
            "Epoch 5/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6776 - f1_score: 0.7667 - loss: 0.5893 - precision: 0.6812 - recall: 0.9051 \n",
            "Epoch 6/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6908 - f1_score: 0.7540 - loss: 0.5781 - precision: 0.6938 - recall: 0.8754 \n",
            "Epoch 7/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7223 - f1_score: 0.7635 - loss: 0.5498 - precision: 0.7131 - recall: 0.9205 \n",
            "Epoch 8/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7271 - f1_score: 0.7710 - loss: 0.5411 - precision: 0.7301 - recall: 0.8964 \n",
            "Epoch 9/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7286 - f1_score: 0.7603 - loss: 0.5421 - precision: 0.7465 - recall: 0.8446 \n",
            "Epoch 10/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7418 - f1_score: 0.7622 - loss: 0.5315 - precision: 0.7417 - recall: 0.8911 \n",
            "Epoch 11/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7392 - f1_score: 0.7633 - loss: 0.5252 - precision: 0.7419 - recall: 0.8859 \n",
            "Epoch 12/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7556 - f1_score: 0.7655 - loss: 0.5108 - precision: 0.7665 - recall: 0.8715 \n",
            "Epoch 13/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7719 - f1_score: 0.7694 - loss: 0.4951 - precision: 0.7762 - recall: 0.8923 \n",
            "Epoch 14/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7566 - f1_score: 0.7560 - loss: 0.5016 - precision: 0.7741 - recall: 0.8464 \n",
            "Epoch 15/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7769 - f1_score: 0.7643 - loss: 0.4867 - precision: 0.7826 - recall: 0.8856 \n",
            "Epoch 16/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7813 - f1_score: 0.7616 - loss: 0.4819 - precision: 0.7875 - recall: 0.8827 \n",
            "Epoch 17/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7738 - f1_score: 0.7726 - loss: 0.4771 - precision: 0.7794 - recall: 0.8940 \n",
            "Epoch 18/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7763 - f1_score: 0.7603 - loss: 0.4751 - precision: 0.7986 - recall: 0.8493 \n",
            "Epoch 19/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7786 - f1_score: 0.7682 - loss: 0.4666 - precision: 0.7940 - recall: 0.8713 \n",
            "Epoch 20/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7898 - f1_score: 0.7671 - loss: 0.4577 - precision: 0.8059 - recall: 0.8718 \n",
            "Epoch 21/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7916 - f1_score: 0.7652 - loss: 0.4533 - precision: 0.7874 - recall: 0.9095 \n",
            "Epoch 22/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8000 - f1_score: 0.7649 - loss: 0.4424 - precision: 0.8095 - recall: 0.8857 \n",
            "Epoch 23/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7994 - f1_score: 0.7586 - loss: 0.4379 - precision: 0.8139 - recall: 0.8711 \n",
            "Epoch 24/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7909 - f1_score: 0.7664 - loss: 0.4393 - precision: 0.7948 - recall: 0.8953 \n",
            "Epoch 25/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8093 - f1_score: 0.7722 - loss: 0.4307 - precision: 0.8213 - recall: 0.8904 \n",
            "Epoch 26/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8103 - f1_score: 0.7644 - loss: 0.4236 - precision: 0.8124 - recall: 0.9015 \n",
            "Epoch 27/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8172 - f1_score: 0.7615 - loss: 0.4139 - precision: 0.8242 - recall: 0.8933 \n",
            "Epoch 28/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8127 - f1_score: 0.7614 - loss: 0.4057 - precision: 0.8092 - recall: 0.9098 \n",
            "Epoch 29/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8243 - f1_score: 0.7661 - loss: 0.3968 - precision: 0.8357 - recall: 0.8930 \n",
            "Epoch 30/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8216 - f1_score: 0.7569 - loss: 0.4027 - precision: 0.8350 - recall: 0.8814 \n",
            "Epoch 31/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8216 - f1_score: 0.7527 - loss: 0.4045 - precision: 0.8301 - recall: 0.8860 \n",
            "Epoch 32/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8232 - f1_score: 0.7625 - loss: 0.3902 - precision: 0.8210 - recall: 0.9121 \n",
            "Epoch 33/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8315 - f1_score: 0.7642 - loss: 0.3840 - precision: 0.8424 - recall: 0.8949 \n",
            "Epoch 34/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8303 - f1_score: 0.7590 - loss: 0.3838 - precision: 0.8418 - recall: 0.8899 \n",
            "Epoch 35/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8324 - f1_score: 0.7663 - loss: 0.3753 - precision: 0.8420 - recall: 0.8988 \n",
            "Epoch 36/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8409 - f1_score: 0.7681 - loss: 0.3633 - precision: 0.8517 - recall: 0.9018 \n",
            "Epoch 37/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8457 - f1_score: 0.7599 - loss: 0.3558 - precision: 0.8594 - recall: 0.8948 \n",
            "Epoch 38/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8398 - f1_score: 0.7636 - loss: 0.3573 - precision: 0.8529 - recall: 0.8949 \n",
            "Epoch 39/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8383 - f1_score: 0.7614 - loss: 0.3541 - precision: 0.8420 - recall: 0.9075 \n",
            "Epoch 40/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8437 - f1_score: 0.7568 - loss: 0.3504 - precision: 0.8643 - recall: 0.8813 \n",
            "Epoch 41/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8430 - f1_score: 0.7538 - loss: 0.3555 - precision: 0.8471 - recall: 0.9035 \n",
            "Epoch 42/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8554 - f1_score: 0.7554 - loss: 0.3443 - precision: 0.8655 - recall: 0.9019\n",
            "Epoch 43/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8581 - f1_score: 0.7693 - loss: 0.3355 - precision: 0.8638 - recall: 0.9173 \n",
            "Epoch 44/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8565 - f1_score: 0.7621 - loss: 0.3349 - precision: 0.8729 - recall: 0.8976 \n",
            "Epoch 45/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8569 - f1_score: 0.7588 - loss: 0.3226 - precision: 0.8600 - recall: 0.9148 \n",
            "Epoch 46/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8487 - f1_score: 0.7602 - loss: 0.3433 - precision: 0.8751 - recall: 0.8782\n",
            "Epoch 47/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8656 - f1_score: 0.7648 - loss: 0.3189 - precision: 0.8832 - recall: 0.9022 \n",
            "Epoch 48/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8746 - f1_score: 0.7583 - loss: 0.3124 - precision: 0.8938 - recall: 0.9019 \n",
            "Epoch 49/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8666 - f1_score: 0.7546 - loss: 0.3172 - precision: 0.8682 - recall: 0.9193 \n",
            "Epoch 50/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8589 - f1_score: 0.7609 - loss: 0.3124 - precision: 0.8757 - recall: 0.8977 \n",
            "Epoch 51/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8633 - f1_score: 0.7598 - loss: 0.3062 - precision: 0.8867 - recall: 0.8910 \n",
            "Epoch 52/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8689 - f1_score: 0.7602 - loss: 0.3103 - precision: 0.8794 - recall: 0.9109\n",
            "Epoch 53/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8749 - f1_score: 0.7609 - loss: 0.3027 - precision: 0.8839 - recall: 0.9167 \n",
            "Epoch 54/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8893 - f1_score: 0.7553 - loss: 0.2893 - precision: 0.8995 - recall: 0.9204\n",
            "Epoch 55/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8854 - f1_score: 0.7726 - loss: 0.2870 - precision: 0.8909 - recall: 0.9320 \n",
            "Epoch 56/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8762 - f1_score: 0.7631 - loss: 0.2949 - precision: 0.8949 - recall: 0.9058 \n",
            "Epoch 57/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8823 - f1_score: 0.7631 - loss: 0.2933 - precision: 0.8982 - recall: 0.9131 \n",
            "Epoch 58/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8853 - f1_score: 0.7639 - loss: 0.2829 - precision: 0.9011 - recall: 0.9148 \n",
            "Epoch 59/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8809 - f1_score: 0.7627 - loss: 0.2885 - precision: 0.8911 - recall: 0.9191 \n",
            "Epoch 60/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8813 - f1_score: 0.7611 - loss: 0.2841 - precision: 0.8867 - recall: 0.9252 \n",
            "Epoch 61/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8859 - f1_score: 0.7692 - loss: 0.2841 - precision: 0.8956 - recall: 0.9257 \n",
            "Epoch 62/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8882 - f1_score: 0.7692 - loss: 0.2735 - precision: 0.8923 - recall: 0.9337 \n",
            "Epoch 63/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8925 - f1_score: 0.7649 - loss: 0.2682 - precision: 0.9032 - recall: 0.9253 \n",
            "Epoch 64/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8931 - f1_score: 0.7641 - loss: 0.2659 - precision: 0.8989 - recall: 0.9320 \n",
            "Epoch 65/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9027 - f1_score: 0.7712 - loss: 0.2595 - precision: 0.9098 - recall: 0.9374 \n",
            "Epoch 66/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8945 - f1_score: 0.7635 - loss: 0.2661 - precision: 0.9047 - recall: 0.9268 \n",
            "Epoch 67/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8952 - f1_score: 0.7645 - loss: 0.2631 - precision: 0.9172 - recall: 0.9135 \n",
            "Epoch 68/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8999 - f1_score: 0.7692 - loss: 0.2505 - precision: 0.9100 - recall: 0.9320 \n",
            "Epoch 69/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9008 - f1_score: 0.7528 - loss: 0.2547 - precision: 0.9264 - recall: 0.9085 \n",
            "Epoch 70/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9002 - f1_score: 0.7653 - loss: 0.2534 - precision: 0.9062 - recall: 0.9358 \n",
            "Epoch 71/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8929 - f1_score: 0.7626 - loss: 0.2525 - precision: 0.9175 - recall: 0.9080 \n",
            "Epoch 72/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9049 - f1_score: 0.7607 - loss: 0.2474 - precision: 0.9204 - recall: 0.9252 \n",
            "Epoch 73/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9081 - f1_score: 0.7522 - loss: 0.2468 - precision: 0.9196 - recall: 0.9290 \n",
            "Epoch 74/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9125 - f1_score: 0.7622 - loss: 0.2368 - precision: 0.9254 - recall: 0.9330 \n",
            "Epoch 75/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9116 - f1_score: 0.7624 - loss: 0.2407 - precision: 0.9179 - recall: 0.9406 \n",
            "Epoch 76/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8996 - f1_score: 0.7658 - loss: 0.2462 - precision: 0.9190 - recall: 0.9193 \n",
            "Epoch 77/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8948 - f1_score: 0.7673 - loss: 0.2594 - precision: 0.9134 - recall: 0.9182 \n",
            "Epoch 78/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9130 - f1_score: 0.7602 - loss: 0.2344 - precision: 0.9202 - recall: 0.9398 \n",
            "Epoch 79/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8975 - f1_score: 0.7653 - loss: 0.2452 - precision: 0.9169 - recall: 0.9179 \n",
            "Epoch 80/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9168 - f1_score: 0.7702 - loss: 0.2230 - precision: 0.9304 - recall: 0.9373 \n",
            "Epoch 81/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9027 - f1_score: 0.7646 - loss: 0.2415 - precision: 0.9072 - recall: 0.9387 \n",
            "Epoch 82/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9142 - f1_score: 0.7662 - loss: 0.2310 - precision: 0.9349 - recall: 0.9266 \n",
            "Epoch 83/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9121 - f1_score: 0.7651 - loss: 0.2248 - precision: 0.9206 - recall: 0.9394 \n",
            "Epoch 84/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9025 - f1_score: 0.7671 - loss: 0.2362 - precision: 0.9293 - recall: 0.9132 \n",
            "Epoch 85/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9117 - f1_score: 0.7626 - loss: 0.2305 - precision: 0.9299 - recall: 0.9266 \n",
            "Epoch 86/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9125 - f1_score: 0.7670 - loss: 0.2234 - precision: 0.9302 - recall: 0.9290 \n",
            "Epoch 87/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9156 - f1_score: 0.7627 - loss: 0.2145 - precision: 0.9290 - recall: 0.9346 \n",
            "Epoch 88/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9156 - f1_score: 0.7613 - loss: 0.2232 - precision: 0.9246 - recall: 0.9392 \n",
            "Epoch 89/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9071 - f1_score: 0.7664 - loss: 0.2369 - precision: 0.9293 - recall: 0.9208 \n",
            "Epoch 90/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9164 - f1_score: 0.7627 - loss: 0.2139 - precision: 0.9306 - recall: 0.9341 \n",
            "Epoch 91/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9065 - f1_score: 0.7571 - loss: 0.2265 - precision: 0.9221 - recall: 0.9244 \n",
            "Epoch 92/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9179 - f1_score: 0.7662 - loss: 0.2126 - precision: 0.9324 - recall: 0.9356 \n",
            "Epoch 93/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9134 - f1_score: 0.7591 - loss: 0.2236 - precision: 0.9257 - recall: 0.9333 \n",
            "Epoch 94/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9235 - f1_score: 0.7714 - loss: 0.2021 - precision: 0.9327 - recall: 0.9465 \n",
            "Epoch 95/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9219 - f1_score: 0.7625 - loss: 0.2023 - precision: 0.9241 - recall: 0.9514 \n",
            "Epoch 96/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9216 - f1_score: 0.7705 - loss: 0.2041 - precision: 0.9378 - recall: 0.9370 \n",
            "Epoch 97/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9173 - f1_score: 0.7611 - loss: 0.2103 - precision: 0.9268 - recall: 0.9397 \n",
            "Epoch 98/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9197 - f1_score: 0.7569 - loss: 0.2048 - precision: 0.9303 - recall: 0.9386 \n",
            "Epoch 99/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9311 - f1_score: 0.7638 - loss: 0.1927 - precision: 0.9387 - recall: 0.9506 \n",
            "Epoch 100/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9301 - f1_score: 0.7683 - loss: 0.1934 - precision: 0.9430 - recall: 0.9451 \n",
            "Epoch 101/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9261 - f1_score: 0.7590 - loss: 0.1975 - precision: 0.9297 - recall: 0.9510 \n",
            "Epoch 102/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9229 - f1_score: 0.7587 - loss: 0.2063 - precision: 0.9288 - recall: 0.9463 \n",
            "Epoch 103/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9289 - f1_score: 0.7688 - loss: 0.1920 - precision: 0.9396 - recall: 0.9470 \n",
            "Epoch 104/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9231 - f1_score: 0.7676 - loss: 0.1958 - precision: 0.9296 - recall: 0.9483 \n",
            "Epoch 105/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9197 - f1_score: 0.7582 - loss: 0.2007 - precision: 0.9287 - recall: 0.9408 \n",
            "Epoch 106/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9270 - f1_score: 0.7652 - loss: 0.1920 - precision: 0.9317 - recall: 0.9519 \n",
            "Epoch 107/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9383 - f1_score: 0.7615 - loss: 0.1868 - precision: 0.9550 - recall: 0.9445 \n",
            "Epoch 108/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9109 - f1_score: 0.7603 - loss: 0.2146 - precision: 0.9243 - recall: 0.9307 \n",
            "Epoch 109/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9279 - f1_score: 0.7655 - loss: 0.1796 - precision: 0.9368 - recall: 0.9477 \n",
            "Epoch 110/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9227 - f1_score: 0.7567 - loss: 0.1904 - precision: 0.9278 - recall: 0.9468 \n",
            "Epoch 111/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9318 - f1_score: 0.7719 - loss: 0.1833 - precision: 0.9419 - recall: 0.9500 \n",
            "Epoch 112/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9310 - f1_score: 0.7710 - loss: 0.1888 - precision: 0.9427 - recall: 0.9477 \n",
            "Epoch 113/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9272 - f1_score: 0.7575 - loss: 0.1841 - precision: 0.9351 - recall: 0.9462 \n",
            "Epoch 114/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9402 - f1_score: 0.7708 - loss: 0.1660 - precision: 0.9479 - recall: 0.9570 \n",
            "Epoch 115/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9343 - f1_score: 0.7604 - loss: 0.1805 - precision: 0.9481 - recall: 0.9447 \n",
            "Epoch 116/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9379 - f1_score: 0.7608 - loss: 0.1718 - precision: 0.9459 - recall: 0.9533 \n",
            "Epoch 117/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9322 - f1_score: 0.7512 - loss: 0.1815 - precision: 0.9457 - recall: 0.9413 \n",
            "Epoch 118/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9380 - f1_score: 0.7606 - loss: 0.1714 - precision: 0.9567 - recall: 0.9415 \n",
            "Epoch 119/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9322 - f1_score: 0.7649 - loss: 0.1749 - precision: 0.9331 - recall: 0.9593 \n",
            "Epoch 120/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9333 - f1_score: 0.7586 - loss: 0.1788 - precision: 0.9424 - recall: 0.9489 \n",
            "Epoch 121/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9356 - f1_score: 0.7568 - loss: 0.1669 - precision: 0.9461 - recall: 0.9482 \n",
            "Epoch 122/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9395 - f1_score: 0.7546 - loss: 0.1674 - precision: 0.9432 - recall: 0.9579 \n",
            "Epoch 123/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9316 - f1_score: 0.7628 - loss: 0.1692 - precision: 0.9404 - recall: 0.9493 \n",
            "Epoch 124/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9405 - f1_score: 0.7582 - loss: 0.1696 - precision: 0.9501 - recall: 0.9526 \n",
            "Epoch 125/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9362 - f1_score: 0.7620 - loss: 0.1667 - precision: 0.9438 - recall: 0.9528 \n",
            "Epoch 126/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9369 - f1_score: 0.7565 - loss: 0.1705 - precision: 0.9537 - recall: 0.9420 \n",
            "Epoch 127/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9335 - f1_score: 0.7599 - loss: 0.1785 - precision: 0.9416 - recall: 0.9504 \n",
            "Epoch 128/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9329 - f1_score: 0.7593 - loss: 0.1657 - precision: 0.9421 - recall: 0.9482 \n",
            "Epoch 129/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9280 - f1_score: 0.7549 - loss: 0.1781 - precision: 0.9395 - recall: 0.9415 \n",
            "Epoch 130/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9391 - f1_score: 0.7668 - loss: 0.1591 - precision: 0.9457 - recall: 0.9569 \n",
            "Epoch 131/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9398 - f1_score: 0.7686 - loss: 0.1643 - precision: 0.9495 - recall: 0.9541 \n",
            "Epoch 132/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9337 - f1_score: 0.7652 - loss: 0.1636 - precision: 0.9314 - recall: 0.9639 \n",
            "Epoch 133/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9288 - f1_score: 0.7619 - loss: 0.1786 - precision: 0.9528 - recall: 0.9306 \n",
            "Epoch 134/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9373 - f1_score: 0.7667 - loss: 0.1644 - precision: 0.9517 - recall: 0.9473 \n",
            "Epoch 135/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9460 - f1_score: 0.7635 - loss: 0.1571 - precision: 0.9535 - recall: 0.9592 \n",
            "Epoch 136/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9408 - f1_score: 0.7592 - loss: 0.1622 - precision: 0.9502 - recall: 0.9530 \n",
            "Epoch 137/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9434 - f1_score: 0.7701 - loss: 0.1548 - precision: 0.9596 - recall: 0.9496 \n",
            "Epoch 138/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9336 - f1_score: 0.7674 - loss: 0.1662 - precision: 0.9507 - recall: 0.9423 \n",
            "Epoch 139/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9441 - f1_score: 0.7649 - loss: 0.1497 - precision: 0.9538 - recall: 0.9559 \n",
            "Epoch 140/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9395 - f1_score: 0.7672 - loss: 0.1578 - precision: 0.9490 - recall: 0.9537 \n",
            "Epoch 141/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9409 - f1_score: 0.7623 - loss: 0.1483 - precision: 0.9492 - recall: 0.9550 \n",
            "Epoch 142/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9458 - f1_score: 0.7682 - loss: 0.1501 - precision: 0.9609 - recall: 0.9517 \n",
            "Epoch 143/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9489 - f1_score: 0.7745 - loss: 0.1429 - precision: 0.9604 - recall: 0.9583 \n",
            "Epoch 144/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9432 - f1_score: 0.7566 - loss: 0.1506 - precision: 0.9541 - recall: 0.9525 \n",
            "Epoch 145/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9413 - f1_score: 0.7616 - loss: 0.1566 - precision: 0.9471 - recall: 0.9579 \n",
            "Epoch 146/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9444 - f1_score: 0.7670 - loss: 0.1530 - precision: 0.9462 - recall: 0.9654 \n",
            "Epoch 147/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9461 - f1_score: 0.7645 - loss: 0.1396 - precision: 0.9506 - recall: 0.9628\n",
            "Epoch 148/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9494 - f1_score: 0.7600 - loss: 0.1473 - precision: 0.9509 - recall: 0.9674\n",
            "Epoch 149/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9378 - f1_score: 0.7698 - loss: 0.1503 - precision: 0.9437 - recall: 0.9573\n",
            "Epoch 150/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9421 - f1_score: 0.7619 - loss: 0.1436 - precision: 0.9552 - recall: 0.9501 \n",
            "Epoch 151/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9507 - f1_score: 0.7684 - loss: 0.1450 - precision: 0.9499 - recall: 0.9720 \n",
            "Epoch 152/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9394 - f1_score: 0.7752 - loss: 0.1526 - precision: 0.9443 - recall: 0.9606 \n",
            "Epoch 153/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9501 - f1_score: 0.7662 - loss: 0.1458 - precision: 0.9619 - recall: 0.9572\n",
            "Epoch 154/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9448 - f1_score: 0.7601 - loss: 0.1472 - precision: 0.9515 - recall: 0.9585\n",
            "Epoch 155/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9441 - f1_score: 0.7657 - loss: 0.1553 - precision: 0.9452 - recall: 0.9656\n",
            "Epoch 156/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9481 - f1_score: 0.7650 - loss: 0.1368 - precision: 0.9654 - recall: 0.9499\n",
            "Epoch 157/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9529 - f1_score: 0.7648 - loss: 0.1333 - precision: 0.9534 - recall: 0.9711\n",
            "Epoch 158/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9502 - f1_score: 0.7675 - loss: 0.1359 - precision: 0.9597 - recall: 0.9602\n",
            "Epoch 159/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9510 - f1_score: 0.7621 - loss: 0.1362 - precision: 0.9590 - recall: 0.9613 \n",
            "Epoch 160/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9443 - f1_score: 0.7621 - loss: 0.1461 - precision: 0.9530 - recall: 0.9564 \n",
            "Epoch 161/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9565 - f1_score: 0.7634 - loss: 0.1307 - precision: 0.9633 - recall: 0.9660 \n",
            "Epoch 162/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9516 - f1_score: 0.7589 - loss: 0.1329 - precision: 0.9607 - recall: 0.9598 \n",
            "Epoch 163/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9514 - f1_score: 0.7618 - loss: 0.1375 - precision: 0.9551 - recall: 0.9660 \n",
            "Epoch 164/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9434 - f1_score: 0.7703 - loss: 0.1430 - precision: 0.9495 - recall: 0.9602 \n",
            "Epoch 165/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9442 - f1_score: 0.7607 - loss: 0.1402 - precision: 0.9549 - recall: 0.9538 \n",
            "Epoch 166/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9434 - f1_score: 0.7676 - loss: 0.1326 - precision: 0.9478 - recall: 0.9615 \n",
            "Epoch 167/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9462 - f1_score: 0.7641 - loss: 0.1418 - precision: 0.9633 - recall: 0.9489 \n",
            "Epoch 168/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9527 - f1_score: 0.7612 - loss: 0.1336 - precision: 0.9525 - recall: 0.9713 \n",
            "Epoch 169/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9497 - f1_score: 0.7733 - loss: 0.1355 - precision: 0.9601 - recall: 0.9597 \n",
            "Epoch 170/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9568 - f1_score: 0.7631 - loss: 0.1271 - precision: 0.9649 - recall: 0.9649 \n",
            "Epoch 171/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9514 - f1_score: 0.7709 - loss: 0.1351 - precision: 0.9619 - recall: 0.9602 \n",
            "Epoch 172/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9513 - f1_score: 0.7703 - loss: 0.1285 - precision: 0.9609 - recall: 0.9611 \n",
            "Epoch 173/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9644 - f1_score: 0.7612 - loss: 0.1173 - precision: 0.9732 - recall: 0.9687 \n",
            "Epoch 174/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9494 - f1_score: 0.7649 - loss: 0.1394 - precision: 0.9557 - recall: 0.9625 \n",
            "Epoch 175/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9522 - f1_score: 0.7610 - loss: 0.1301 - precision: 0.9653 - recall: 0.9565 \n",
            "Epoch 176/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9561 - f1_score: 0.7599 - loss: 0.1248 - precision: 0.9620 - recall: 0.9662 \n",
            "Epoch 177/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9535 - f1_score: 0.7743 - loss: 0.1270 - precision: 0.9628 - recall: 0.9633 \n",
            "Epoch 178/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9592 - f1_score: 0.7653 - loss: 0.1219 - precision: 0.9712 - recall: 0.9624\n",
            "Epoch 179/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9510 - f1_score: 0.7633 - loss: 0.1243 - precision: 0.9519 - recall: 0.9692 \n",
            "Epoch 180/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9490 - f1_score: 0.7642 - loss: 0.1292 - precision: 0.9568 - recall: 0.9605 \n",
            "Epoch 181/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9527 - f1_score: 0.7665 - loss: 0.1337 - precision: 0.9643 - recall: 0.9591 \n",
            "Epoch 182/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9439 - f1_score: 0.7719 - loss: 0.1386 - precision: 0.9502 - recall: 0.9607 \n",
            "Epoch 183/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9407 - f1_score: 0.7595 - loss: 0.1424 - precision: 0.9577 - recall: 0.9443 \n",
            "Epoch 184/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9512 - f1_score: 0.7613 - loss: 0.1269 - precision: 0.9517 - recall: 0.9693 \n",
            "Epoch 185/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9540 - f1_score: 0.7719 - loss: 0.1222 - precision: 0.9630 - recall: 0.9636 \n",
            "Epoch 186/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9465 - f1_score: 0.7661 - loss: 0.1361 - precision: 0.9580 - recall: 0.9554 \n",
            "Epoch 187/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9522 - f1_score: 0.7661 - loss: 0.1238 - precision: 0.9566 - recall: 0.9664 \n",
            "Epoch 188/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9560 - f1_score: 0.7664 - loss: 0.1240 - precision: 0.9611 - recall: 0.9680 \n",
            "Epoch 189/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9521 - f1_score: 0.7572 - loss: 0.1292 - precision: 0.9509 - recall: 0.9714 \n",
            "Epoch 190/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9603 - f1_score: 0.7623 - loss: 0.1161 - precision: 0.9685 - recall: 0.9668 \n",
            "Epoch 191/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9581 - f1_score: 0.7590 - loss: 0.1294 - precision: 0.9672 - recall: 0.9638 \n",
            "Epoch 192/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9640 - f1_score: 0.7678 - loss: 0.1079 - precision: 0.9693 - recall: 0.9726 \n",
            "Epoch 193/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9629 - f1_score: 0.7693 - loss: 0.1113 - precision: 0.9713 - recall: 0.9688 \n",
            "Epoch 194/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9613 - f1_score: 0.7607 - loss: 0.1112 - precision: 0.9649 - recall: 0.9720 \n",
            "Epoch 195/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9526 - f1_score: 0.7629 - loss: 0.1256 - precision: 0.9597 - recall: 0.9631 \n",
            "Epoch 196/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9583 - f1_score: 0.7589 - loss: 0.1267 - precision: 0.9707 - recall: 0.9604 \n",
            "Epoch 197/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9637 - f1_score: 0.7695 - loss: 0.1128 - precision: 0.9707 - recall: 0.9707 \n",
            "Epoch 198/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9544 - f1_score: 0.7630 - loss: 0.1212 - precision: 0.9598 - recall: 0.9662 \n",
            "Epoch 199/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9573 - f1_score: 0.7605 - loss: 0.1167 - precision: 0.9644 - recall: 0.9657 \n",
            "Epoch 200/200\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9578 - f1_score: 0.7576 - loss: 0.1169 - precision: 0.9660 - recall: 0.9645 \n",
            "\n",
            "==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Accuracy en Conjunto de Prueba: 0.8291\n",
            "Precision en Conjunto de Prueba: 0.8411\n",
            "Recall en Conjunto de Prueba: 0.8912\n",
            "F1-Score en Conjunto de Prueba: 0.8654\n",
            "\n",
            "Reporte de Clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.73      0.77       303\n",
            "           1       0.84      0.89      0.87       487\n",
            "\n",
            "    accuracy                           0.83       790\n",
            "   macro avg       0.82      0.81      0.82       790\n",
            "weighted avg       0.83      0.83      0.83       790\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfftlXWEG-e"
      },
      "source": [
        "## 5. Entrenamiento del modelo\n",
        "\n",
        "Reservamos el 20% de los datos de entrenamiento para la validación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Opcional) Reentrenar modelo final con todos los datos y mejores hiperparámetros\n",
        "for i in range(5):\n",
        "  best_model = tuner.hypermodel.build(best_hp[i])\n",
        "  history = best_model.fit(X_train, y_train,\n",
        "                          validation_data=(X_val, y_val),\n",
        "                          epochs=1000,\n",
        "                          batch_size=ceil(len(train_index)*0.1),\n",
        "                          verbose=0)\n",
        "\n",
        "  test_loss, test_acc, test_precision, test_recall, test_f1 = model.evaluate(X_val, y_val, verbose=0)\n",
        "  print(f'📊 Fold {fold+1}')\n",
        "  print(f'Test accuracy: {100*test_acc:.2f}%')\n",
        "  print(f'Test loss: {test_loss:.3f}')\n",
        "  folds_acc.append(test_acc)\n",
        "  folds_precission.append(test_precision)\n",
        "  folds_recall.append(test_recall)\n",
        "  folds_f1.append(test_f1)\n"
      ],
      "metadata": {
        "id": "WJq-FrDGEvfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "EPOCHS = 1000\n",
        "#BATCH_SIZE = train_size[0]\n",
        "BATCH_SIZE = ceil(train_size[0]*0.1)\n",
        "history = model.fit(normed_train_data, train_labels, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0)"
      ],
      "metadata": {
        "id": "m0aj2up8xVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w3FgAK4CCSnX",
        "outputId": "73e809a4-162b-4ee8-be99-246e20120c88"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"hist\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006347550950908333,\n        \"min\": 0.8095071911811829,\n        \"max\": 0.8248863816261292,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.817196786403656,\n          0.8217406272888184,\n          0.8248863816261292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00013810814603979643,\n        \"min\": 0.7623376250267029,\n        \"max\": 0.7626677751541138,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7625026702880859,\n          0.7623376250267029,\n          0.7626677751541138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007895688488016887,\n        \"min\": 0.3556634485721588,\n        \"max\": 0.37549519538879395,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3609391152858734,\n          0.3556634485721588,\n          0.3585996925830841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007251117900362078,\n        \"min\": 0.8163371682167053,\n        \"max\": 0.8347502946853638,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8257894515991211,\n          0.8311275839805603,\n          0.8347502946853638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019004011327720016,\n        \"min\": 0.8909710645675659,\n        \"max\": 0.8955138921737671,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8921067714691162,\n          0.8915389180183411,\n          0.8909710645675659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0061989731224158405,\n        \"min\": 0.6494413614273071,\n        \"max\": 0.666201114654541,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6494413614273071,\n          0.666201114654541,\n          0.6578212380409241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00029257633830353846,\n        \"min\": 0.74715656042099,\n        \"max\": 0.7478107810020447,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.74715656042099,\n          0.7478107810020447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014469501568279875,\n        \"min\": 1.1016870737075806,\n        \"max\": 1.136595606803894,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.1320658922195435,\n          1.1292800903320312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0026408697542278014,\n        \"min\": 0.6842105388641357,\n        \"max\": 0.6902287006378174,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6895074844360352,\n          0.6842105388641357\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024471442051881953,\n        \"min\": 0.7523364424705505,\n        \"max\": 0.8200934529304504,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7523364424705505,\n          0.8200934529304504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 695,\n        \"max\": 699,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          696,\n          699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-60e77b78-438e-4ad8-968d-20e4913826e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_score</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>0.809507</td>\n",
              "      <td>0.762503</td>\n",
              "      <td>0.375495</td>\n",
              "      <td>0.816337</td>\n",
              "      <td>0.890971</td>\n",
              "      <td>0.656425</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.136596</td>\n",
              "      <td>0.688017</td>\n",
              "      <td>0.778037</td>\n",
              "      <td>695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>0.817197</td>\n",
              "      <td>0.762338</td>\n",
              "      <td>0.360939</td>\n",
              "      <td>0.825789</td>\n",
              "      <td>0.890971</td>\n",
              "      <td>0.649441</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.132066</td>\n",
              "      <td>0.689507</td>\n",
              "      <td>0.752336</td>\n",
              "      <td>696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>0.824886</td>\n",
              "      <td>0.762338</td>\n",
              "      <td>0.358600</td>\n",
              "      <td>0.834750</td>\n",
              "      <td>0.892107</td>\n",
              "      <td>0.657821</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.135590</td>\n",
              "      <td>0.690229</td>\n",
              "      <td>0.775701</td>\n",
              "      <td>697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>0.824187</td>\n",
              "      <td>0.762503</td>\n",
              "      <td>0.358171</td>\n",
              "      <td>0.831751</td>\n",
              "      <td>0.895514</td>\n",
              "      <td>0.653631</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.101687</td>\n",
              "      <td>0.685185</td>\n",
              "      <td>0.778037</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>0.821741</td>\n",
              "      <td>0.762668</td>\n",
              "      <td>0.355663</td>\n",
              "      <td>0.831128</td>\n",
              "      <td>0.891539</td>\n",
              "      <td>0.666201</td>\n",
              "      <td>0.747157</td>\n",
              "      <td>1.129280</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.820093</td>\n",
              "      <td>699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60e77b78-438e-4ad8-968d-20e4913826e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60e77b78-438e-4ad8-968d-20e4913826e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60e77b78-438e-4ad8-968d-20e4913826e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd7443af-e889-4364-95bb-0df4c538ca25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd7443af-e889-4364-95bb-0df4c538ca25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd7443af-e889-4364-95bb-0df4c538ca25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     accuracy  f1_score      loss  precision    recall  val_accuracy  \\\n",
              "695  0.809507  0.762503  0.375495   0.816337  0.890971      0.656425   \n",
              "696  0.817197  0.762338  0.360939   0.825789  0.890971      0.649441   \n",
              "697  0.824886  0.762338  0.358600   0.834750  0.892107      0.657821   \n",
              "698  0.824187  0.762503  0.358171   0.831751  0.895514      0.653631   \n",
              "699  0.821741  0.762668  0.355663   0.831128  0.891539      0.666201   \n",
              "\n",
              "     val_f1_score  val_loss  val_precision  val_recall  epoch  \n",
              "695      0.747811  1.136596       0.688017    0.778037    695  \n",
              "696      0.747811  1.132066       0.689507    0.752336    696  \n",
              "697      0.747811  1.135590       0.690229    0.775701    697  \n",
              "698      0.747811  1.101687       0.685185    0.778037    698  \n",
              "699      0.747157  1.129280       0.684211    0.820093    699  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "PHxBjzT8Ep82",
        "outputId": "d6a539c6-e7d7-4462-e120-6e33c9e956cd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Binary Crossentropy')\n",
        "  plt.plot(hist['epoch'], hist['binary_accuracy'],'r--',\n",
        "           label='Training Accuracy')\n",
        "  plt.plot(hist['epoch'], hist['val_binary_accuracy'],'b',\n",
        "           label = 'Validation Accuracy')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9M9YKiC-295"
      },
      "source": [
        "## 6. Validación del modelo con los datos de test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS6oqzXxT3AJ",
        "outputId": "e1f55709-b906-46f5-cb3d-db606148ea40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step - accuracy: 0.6644 - f1_score: 0.7639 - loss: 0.9440 - precision: 0.6860 - recall: 0.8382\n",
            "Test accuracy: 66.44%\n",
            "Test loss: 0.944\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, test_f1, test_precision, test_recall = model.evaluate(normed_test_data, test_labels, batch_size=(test_size[0]))\n",
        "print(f'Test accuracy: {100*test_acc:.2f}%')\n",
        "print(f'Test loss: {test_loss:.3f}')\n",
        "# 66,55%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}