{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaEspFon/Scripts-propios/blob/main/TensorFlow/CNN_model_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNAOn5Ia7pG"
      },
      "source": [
        "# OPTIMIZACIÓN DE HIPERPARÁMETROS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhxVlFL7j4N6"
      },
      "source": [
        "## 1. Inicialización de Keras y TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcFrOCQOYU1R",
        "outputId": "38aa2db4-c766-4b4b-8ec0-f43344c3cbde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version:  2.18.0\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "#print(\"Keras version: \", tf.keras.__version__)\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtndO_D__Z2T"
      },
      "source": [
        "## 2. Carga de datos EDA desde Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niPo3Nfh-bVz",
        "outputId": "26a1aa5d-65dc-4495-f92a-5cde57b67e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset: (3949, 21)\n",
            "Recuento de instancias por clase:\n",
            "State\n",
            "1    2435\n",
            "0    1514\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/MariaEspFon/Scripts-propios/main/MATLAB/EDA_D7.2_EMA.csv'\n",
        "column_names = ['Mean','Median', 'Standard Dev', 'Max Value', 'Min Value', 'Standard Dev 1st diff', 'Median 1st diff', 'Standard Dev 2nd diff',\n",
        "                'Total Area', 'Kurtosis', 'SCR', 'Power', '99% Bandwidth', 'Top Bandwidth Frequency',\n",
        "                'Phasic mean', 'Phasic Stdev', 'Phasic AuC', 'Tonic mean', 'Tonic Stdev', 'Tonic AuC',\n",
        "                'State']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names, sep=',', skipinitialspace=True)\n",
        "\n",
        "size = raw_dataset.shape\n",
        "print(f'Formato del dataset: {size}')\n",
        "\n",
        "class_counts = raw_dataset['State'].value_counts()\n",
        "print(\"Recuento de instancias por clase:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WEvgfenf-pEf",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "e677a28f-e000-4bb7-aefe-a863ab215bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Mean    Median  Standard Dev  Max Value  Min Value  \\\n",
              "4466  1.466113  1.566922      1.261131   3.142194  -0.076818   \n",
              "4467  0.540481  0.034924      0.963236   3.007747  -0.231767   \n",
              "4468  2.449819  2.981136      1.047429   3.098601   0.061658   \n",
              "4469  2.944428  2.946765      0.031031   3.030734   2.796635   \n",
              "4470  2.840264  2.868869      0.263836   2.909742   0.000000   \n",
              "\n",
              "      Standard Dev 1st diff  Median 1st diff  Standard Dev 2nd diff  \\\n",
              "4466               0.183625         0.002763               0.093909   \n",
              "4467               0.171018         0.000410               0.068237   \n",
              "4468               0.102151         0.000678               0.043690   \n",
              "4469               0.014701        -0.000828               0.009593   \n",
              "4470               0.257542        -0.000595               0.258572   \n",
              "\n",
              "      Total Area    Kurtosis  ...        Power  99% Bandwidth  \\\n",
              "4466  174.826977    1.231085  ...   447.202123       0.517393   \n",
              "4467   63.761552    3.701841  ...   145.465354       0.969150   \n",
              "4468  292.429905    3.509624  ...   850.749576       0.402680   \n",
              "4469  350.382482   10.605559  ...  1040.473268       0.016502   \n",
              "4470  339.376835  113.812119  ...   976.335639       0.806445   \n",
              "\n",
              "      Top Bandwidth Frequency  Phasic mean  Phasic Stdev  Phasic AuC  \\\n",
              "4466                 0.517538     2.650141      3.726599   78.992107   \n",
              "4467                 0.969496     1.919576      2.938044   54.869583   \n",
              "4468                 0.402778     1.049711      1.670153   31.491325   \n",
              "4469                 0.016585     0.072713      0.296073    2.045646   \n",
              "4470                 0.806529     0.539952      1.058184   16.198553   \n",
              "\n",
              "      Tonic mean  Tonic Stdev   Tonic AuC  State  \n",
              "4466   -3.209107     1.263214  -95.019918      1  \n",
              "4467   -3.763126     1.339107 -111.580315      1  \n",
              "4468   -0.741003     1.967254  -21.775323      1  \n",
              "4469    1.257076     0.145131   37.424606      1  \n",
              "4470    0.802859     0.775748   23.916348      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943dd167-7b22-4994-b1a4-4fdfd511c5c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Standard Dev</th>\n",
              "      <th>Max Value</th>\n",
              "      <th>Min Value</th>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <th>Median 1st diff</th>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <th>Total Area</th>\n",
              "      <th>Kurtosis</th>\n",
              "      <th>...</th>\n",
              "      <th>Power</th>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <th>Phasic mean</th>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <th>Phasic AuC</th>\n",
              "      <th>Tonic mean</th>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <th>Tonic AuC</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>1.466113</td>\n",
              "      <td>1.566922</td>\n",
              "      <td>1.261131</td>\n",
              "      <td>3.142194</td>\n",
              "      <td>-0.076818</td>\n",
              "      <td>0.183625</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.093909</td>\n",
              "      <td>174.826977</td>\n",
              "      <td>1.231085</td>\n",
              "      <td>...</td>\n",
              "      <td>447.202123</td>\n",
              "      <td>0.517393</td>\n",
              "      <td>0.517538</td>\n",
              "      <td>2.650141</td>\n",
              "      <td>3.726599</td>\n",
              "      <td>78.992107</td>\n",
              "      <td>-3.209107</td>\n",
              "      <td>1.263214</td>\n",
              "      <td>-95.019918</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>0.540481</td>\n",
              "      <td>0.034924</td>\n",
              "      <td>0.963236</td>\n",
              "      <td>3.007747</td>\n",
              "      <td>-0.231767</td>\n",
              "      <td>0.171018</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.068237</td>\n",
              "      <td>63.761552</td>\n",
              "      <td>3.701841</td>\n",
              "      <td>...</td>\n",
              "      <td>145.465354</td>\n",
              "      <td>0.969150</td>\n",
              "      <td>0.969496</td>\n",
              "      <td>1.919576</td>\n",
              "      <td>2.938044</td>\n",
              "      <td>54.869583</td>\n",
              "      <td>-3.763126</td>\n",
              "      <td>1.339107</td>\n",
              "      <td>-111.580315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4468</th>\n",
              "      <td>2.449819</td>\n",
              "      <td>2.981136</td>\n",
              "      <td>1.047429</td>\n",
              "      <td>3.098601</td>\n",
              "      <td>0.061658</td>\n",
              "      <td>0.102151</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.043690</td>\n",
              "      <td>292.429905</td>\n",
              "      <td>3.509624</td>\n",
              "      <td>...</td>\n",
              "      <td>850.749576</td>\n",
              "      <td>0.402680</td>\n",
              "      <td>0.402778</td>\n",
              "      <td>1.049711</td>\n",
              "      <td>1.670153</td>\n",
              "      <td>31.491325</td>\n",
              "      <td>-0.741003</td>\n",
              "      <td>1.967254</td>\n",
              "      <td>-21.775323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4469</th>\n",
              "      <td>2.944428</td>\n",
              "      <td>2.946765</td>\n",
              "      <td>0.031031</td>\n",
              "      <td>3.030734</td>\n",
              "      <td>2.796635</td>\n",
              "      <td>0.014701</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>0.009593</td>\n",
              "      <td>350.382482</td>\n",
              "      <td>10.605559</td>\n",
              "      <td>...</td>\n",
              "      <td>1040.473268</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>0.016585</td>\n",
              "      <td>0.072713</td>\n",
              "      <td>0.296073</td>\n",
              "      <td>2.045646</td>\n",
              "      <td>1.257076</td>\n",
              "      <td>0.145131</td>\n",
              "      <td>37.424606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4470</th>\n",
              "      <td>2.840264</td>\n",
              "      <td>2.868869</td>\n",
              "      <td>0.263836</td>\n",
              "      <td>2.909742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257542</td>\n",
              "      <td>-0.000595</td>\n",
              "      <td>0.258572</td>\n",
              "      <td>339.376835</td>\n",
              "      <td>113.812119</td>\n",
              "      <td>...</td>\n",
              "      <td>976.335639</td>\n",
              "      <td>0.806445</td>\n",
              "      <td>0.806529</td>\n",
              "      <td>0.539952</td>\n",
              "      <td>1.058184</td>\n",
              "      <td>16.198553</td>\n",
              "      <td>0.802859</td>\n",
              "      <td>0.775748</td>\n",
              "      <td>23.916348</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943dd167-7b22-4994-b1a4-4fdfd511c5c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "raw_dataset.tail() # muestra las últimas 5 filas por defecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Cqjf_xnwpw"
      },
      "outputs": [],
      "source": [
        "raw_dataset.head() # muestra las primeras 5 filas por defecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9-FGkx3glzZ"
      },
      "source": [
        "## 3. Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBXjhOwa_eFh"
      },
      "source": [
        "### 3.1. Extracción de los conjuntos de entrenamiento, prueba y validación\n",
        "\n",
        "*   Datos de **entrenamiento**: para el aprendizaje de parámetros.\n",
        "*   Datos de **prueba**: para hacer test de predicciones.\n",
        "*   Datos de **validación**: para afinar hiperparámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wtq9cEZV_V-m"
      },
      "outputs": [],
      "source": [
        "# Extracción de subconjuntos: bloque de código para mantener la proporción de clases\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = raw_dataset.drop('State', axis=1)\n",
        "labels = raw_dataset['State']\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "FekCNTKP_WBI",
        "outputId": "f17769d6-c60c-4e30-e9d2-1c2181a3957d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count         mean          std           min  \\\n",
              "Mean                     3159.0     1.461257     2.688161  2.881417e-04   \n",
              "Median                   3159.0     1.466649     2.710469  0.000000e+00   \n",
              "Standard Dev             3159.0     0.144952     0.381106  4.706701e-04   \n",
              "Max Value                3159.0     1.704078     2.942718  4.779257e-03   \n",
              "Min Value                3159.0     1.193842     2.469216  0.000000e+00   \n",
              "Standard Dev 1st diff    3159.0     0.022006     0.039530  3.494808e-04   \n",
              "Median 1st diff          3159.0    -0.000315     0.003921 -1.093078e-01   \n",
              "Standard Dev 2nd diff    3159.0     0.018383     0.029861  4.191872e-04   \n",
              "Total Area               3159.0   173.890366   319.923866  3.457700e-02   \n",
              "Kurtosis                 3159.0     5.549862     7.382169  1.057126e+00   \n",
              "SCR                      3159.0     1.063944     2.344673  0.000000e+00   \n",
              "Power                    3159.0  1142.881747  3839.609331  1.060477e-04   \n",
              "99% Bandwidth            3159.0     0.182056     0.350587  1.650002e-02   \n",
              "Top Bandwidth Frequency  3159.0     0.182157     0.350636  1.658335e-02   \n",
              "Phasic mean              3159.0     0.606996     1.303538  4.475971e-08   \n",
              "Phasic Stdev             3159.0     0.966032     1.883792  1.652074e-08   \n",
              "Phasic AuC               3159.0    18.063914    38.840793  1.331816e-06   \n",
              "Tonic mean               3159.0    -0.782682     1.836786 -2.952807e+01   \n",
              "Tonic Stdev              3159.0     0.433241     0.832538  1.055206e-04   \n",
              "Tonic AuC                3159.0   -23.288679    54.738380 -8.829021e+02   \n",
              "\n",
              "                               25%        50%         75%           max  \n",
              "Mean                      0.249013   0.433919    1.120415     16.873588  \n",
              "Median                    0.241514   0.431638    1.125672     17.060042  \n",
              "Standard Dev              0.005087   0.024107    0.121097      6.510492  \n",
              "Max Value                 0.293813   0.496918    1.504204     17.572616  \n",
              "Min Value                 0.140055   0.314706    0.660940     16.098618  \n",
              "Standard Dev 1st diff     0.001248   0.005013    0.023161      0.471897  \n",
              "Median 1st diff          -0.000351  -0.000024    0.000155      0.048991  \n",
              "Standard Dev 2nd diff     0.001694   0.004379    0.020992      0.258629  \n",
              "Total Area               29.601951  51.637832  133.571556   2013.300593  \n",
              "Kurtosis                  2.075404   2.857487    5.505709    113.896441  \n",
              "SCR                       0.000000   0.000000    1.000000     24.000000  \n",
              "Power                     7.913682  23.449923  171.273761  34363.988284  \n",
              "99% Bandwidth             0.016504   0.016529    0.167778      1.982856  \n",
              "Top Bandwidth Frequency   0.016587   0.016612    0.167895      1.983451  \n",
              "Phasic mean               0.018716   0.101285    0.523234     21.397006  \n",
              "Phasic Stdev              0.053579   0.223113    0.967546     35.095213  \n",
              "Phasic AuC                0.551897   2.997145   15.523808    638.941089  \n",
              "Tonic mean               -1.153674  -0.500970    0.136751      3.422684  \n",
              "Tonic Stdev               0.027316   0.098597    0.515756     16.795811  \n",
              "Tonic AuC               -34.324767 -14.913256    4.080784    101.863348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac4cdf56-a950-4812-a962-70320ee528bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.461257</td>\n",
              "      <td>2.688161</td>\n",
              "      <td>2.881417e-04</td>\n",
              "      <td>0.249013</td>\n",
              "      <td>0.433919</td>\n",
              "      <td>1.120415</td>\n",
              "      <td>16.873588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.466649</td>\n",
              "      <td>2.710469</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.241514</td>\n",
              "      <td>0.431638</td>\n",
              "      <td>1.125672</td>\n",
              "      <td>17.060042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.144952</td>\n",
              "      <td>0.381106</td>\n",
              "      <td>4.706701e-04</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.024107</td>\n",
              "      <td>0.121097</td>\n",
              "      <td>6.510492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.704078</td>\n",
              "      <td>2.942718</td>\n",
              "      <td>4.779257e-03</td>\n",
              "      <td>0.293813</td>\n",
              "      <td>0.496918</td>\n",
              "      <td>1.504204</td>\n",
              "      <td>17.572616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.193842</td>\n",
              "      <td>2.469216</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.314706</td>\n",
              "      <td>0.660940</td>\n",
              "      <td>16.098618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.022006</td>\n",
              "      <td>0.039530</td>\n",
              "      <td>3.494808e-04</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0.023161</td>\n",
              "      <td>0.471897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>-1.093078e-01</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.048991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>0.029861</td>\n",
              "      <td>4.191872e-04</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.258629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>173.890366</td>\n",
              "      <td>319.923866</td>\n",
              "      <td>3.457700e-02</td>\n",
              "      <td>29.601951</td>\n",
              "      <td>51.637832</td>\n",
              "      <td>133.571556</td>\n",
              "      <td>2013.300593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.549862</td>\n",
              "      <td>7.382169</td>\n",
              "      <td>1.057126e+00</td>\n",
              "      <td>2.075404</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>5.505709</td>\n",
              "      <td>113.896441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.063944</td>\n",
              "      <td>2.344673</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1142.881747</td>\n",
              "      <td>3839.609331</td>\n",
              "      <td>1.060477e-04</td>\n",
              "      <td>7.913682</td>\n",
              "      <td>23.449923</td>\n",
              "      <td>171.273761</td>\n",
              "      <td>34363.988284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182056</td>\n",
              "      <td>0.350587</td>\n",
              "      <td>1.650002e-02</td>\n",
              "      <td>0.016504</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.167778</td>\n",
              "      <td>1.982856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182157</td>\n",
              "      <td>0.350636</td>\n",
              "      <td>1.658335e-02</td>\n",
              "      <td>0.016587</td>\n",
              "      <td>0.016612</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>1.983451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.606996</td>\n",
              "      <td>1.303538</td>\n",
              "      <td>4.475971e-08</td>\n",
              "      <td>0.018716</td>\n",
              "      <td>0.101285</td>\n",
              "      <td>0.523234</td>\n",
              "      <td>21.397006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.966032</td>\n",
              "      <td>1.883792</td>\n",
              "      <td>1.652074e-08</td>\n",
              "      <td>0.053579</td>\n",
              "      <td>0.223113</td>\n",
              "      <td>0.967546</td>\n",
              "      <td>35.095213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>18.063914</td>\n",
              "      <td>38.840793</td>\n",
              "      <td>1.331816e-06</td>\n",
              "      <td>0.551897</td>\n",
              "      <td>2.997145</td>\n",
              "      <td>15.523808</td>\n",
              "      <td>638.941089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.782682</td>\n",
              "      <td>1.836786</td>\n",
              "      <td>-2.952807e+01</td>\n",
              "      <td>-1.153674</td>\n",
              "      <td>-0.500970</td>\n",
              "      <td>0.136751</td>\n",
              "      <td>3.422684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.832538</td>\n",
              "      <td>1.055206e-04</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.098597</td>\n",
              "      <td>0.515756</td>\n",
              "      <td>16.795811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-23.288679</td>\n",
              "      <td>54.738380</td>\n",
              "      <td>-8.829021e+02</td>\n",
              "      <td>-34.324767</td>\n",
              "      <td>-14.913256</td>\n",
              "      <td>4.080784</td>\n",
              "      <td>101.863348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac4cdf56-a950-4812-a962-70320ee528bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac4cdf56-a950-4812-a962-70320ee528bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac4cdf56-a950-4812-a962-70320ee528bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ad7100a5-fad3-40fa-92a9-0a495ad97fe3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad7100a5-fad3-40fa-92a9-0a495ad97fe3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ad7100a5-fad3-40fa-92a9-0a495ad97fe3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fc7215f9-9d04-41b5-97d4-74944e364a0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc7215f9-9d04-41b5-97d4-74944e364a0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_stats",
              "summary": "{\n  \"name\": \"train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.43774243066844,\n        \"min\": -23.288679302492756,\n        \"max\": 1142.8817465910665,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.4612569864023432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856.3494010607636,\n        \"min\": 0.003920865966528552,\n        \"max\": 3839.6093312957755,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.688160769255659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.1982611498348,\n        \"min\": -882.902109713819,\n        \"max\": 1.05712563449178,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0002881416666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.567138491113965,\n        \"min\": -34.3247668007665,\n        \"max\": 29.601950522781898,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.24901303990454848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.034024453837553,\n        \"min\": -14.9132560124876,\n        \"max\": 51.6378323985219,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.43391925352509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.88127532395101,\n        \"min\": 0.000155043576272,\n        \"max\": 171.27376076324,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.120414963183705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7661.905667264518,\n        \"min\": 0.0489910736836237,\n        \"max\": 34363.988283576,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          16.873587916458\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_size = train_dataset.shape\n",
        "test_size = test_dataset.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syU3bAgjhaZb"
      },
      "source": [
        "### 3.2. Normalización y estandarización de todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "V6-D516VCSUe",
        "outputId": "2e2a3475-cc51-4682-b52f-d4ec360f2e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count          mean  std        min       25%  \\\n",
              "Mean                     3159.0  8.997059e-18  1.0  -0.543483 -0.450957   \n",
              "Median                   3159.0 -1.462022e-17  1.0  -0.541105 -0.452001   \n",
              "Standard Dev             3159.0  6.410405e-17  1.0  -0.379110 -0.366997   \n",
              "Max Value                3159.0 -3.261434e-17  1.0  -0.577459 -0.479239   \n",
              "Min Value                3159.0  1.349559e-17  1.0  -0.483490 -0.426770   \n",
              "Standard Dev 1st diff    3159.0  8.997059e-17  1.0  -0.547850 -0.525124   \n",
              "Median 1st diff          3159.0  8.997059e-18  1.0 -27.798013 -0.008976   \n",
              "Standard Dev 2nd diff    3159.0  1.012169e-16  1.0  -0.601592 -0.558901   \n",
              "Total Area               3159.0 -1.135879e-16  1.0  -0.543429 -0.451009   \n",
              "Kurtosis                 3159.0 -5.848088e-17  1.0  -0.608593 -0.470655   \n",
              "SCR                      3159.0 -3.036507e-17  1.0  -0.453771 -0.453771   \n",
              "Power                    3159.0 -2.249265e-17  1.0  -0.297656 -0.295595   \n",
              "99% Bandwidth            3159.0 -2.474191e-17  1.0  -0.472226 -0.472214   \n",
              "Top Bandwidth Frequency  3159.0 -6.185478e-18  1.0  -0.472211 -0.472199   \n",
              "Phasic mean              3159.0 -2.305496e-17  1.0  -0.465652 -0.451294   \n",
              "Phasic Stdev             3159.0  5.623162e-19  1.0  -0.512813 -0.484370   \n",
              "Phasic AuC               3159.0 -1.433906e-17  1.0  -0.465076 -0.450867   \n",
              "Tonic mean               3159.0 -5.117077e-17  1.0 -15.649830 -0.201979   \n",
              "Tonic Stdev              3159.0  2.924044e-17  1.0  -0.520259 -0.487576   \n",
              "Tonic AuC                3159.0 -6.579099e-17  1.0 -15.704035 -0.201615   \n",
              "\n",
              "                              50%       75%        max  \n",
              "Mean                    -0.382171 -0.126794   5.733411  \n",
              "Median                  -0.381857 -0.125800   5.753023  \n",
              "Standard Dev            -0.317089 -0.062595  16.702809  \n",
              "Max Value               -0.410220 -0.067921   5.392477  \n",
              "Min Value               -0.356038 -0.215818   6.036239  \n",
              "Standard Dev 1st diff   -0.429885  0.029211  11.380875  \n",
              "Median 1st diff          0.074262  0.120010  12.575429  \n",
              "Standard Dev 2nd diff   -0.468976  0.087356   8.045450  \n",
              "Total Area              -0.382130 -0.126026   5.749525  \n",
              "Kurtosis                -0.364713 -0.005981  14.676795  \n",
              "SCR                     -0.453771 -0.027272   9.782197  \n",
              "Power                   -0.291548 -0.253049   8.652210  \n",
              "99% Bandwidth           -0.472143 -0.040728   5.136521  \n",
              "Top Bandwidth Frequency -0.472128 -0.040677   5.137217  \n",
              "Phasic mean             -0.387952 -0.064257  15.948907  \n",
              "Phasic Stdev            -0.394374  0.000804  18.117274  \n",
              "Phasic AuC              -0.387911 -0.065398  15.985183  \n",
              "Tonic mean               0.153372  0.500566   2.289524  \n",
              "Tonic Stdev             -0.401957  0.099112  19.653834  \n",
              "Tonic AuC                0.153008  0.500005   2.286367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e712dd7-f605-41eb-892c-405be22e2c76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543483</td>\n",
              "      <td>-0.450957</td>\n",
              "      <td>-0.382171</td>\n",
              "      <td>-0.126794</td>\n",
              "      <td>5.733411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.462022e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.541105</td>\n",
              "      <td>-0.452001</td>\n",
              "      <td>-0.381857</td>\n",
              "      <td>-0.125800</td>\n",
              "      <td>5.753023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>6.410405e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.379110</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-0.317089</td>\n",
              "      <td>-0.062595</td>\n",
              "      <td>16.702809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.261434e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.577459</td>\n",
              "      <td>-0.479239</td>\n",
              "      <td>-0.410220</td>\n",
              "      <td>-0.067921</td>\n",
              "      <td>5.392477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.349559e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.483490</td>\n",
              "      <td>-0.426770</td>\n",
              "      <td>-0.356038</td>\n",
              "      <td>-0.215818</td>\n",
              "      <td>6.036239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.547850</td>\n",
              "      <td>-0.525124</td>\n",
              "      <td>-0.429885</td>\n",
              "      <td>0.029211</td>\n",
              "      <td>11.380875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-27.798013</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.074262</td>\n",
              "      <td>0.120010</td>\n",
              "      <td>12.575429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.012169e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.601592</td>\n",
              "      <td>-0.558901</td>\n",
              "      <td>-0.468976</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>8.045450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.135879e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543429</td>\n",
              "      <td>-0.451009</td>\n",
              "      <td>-0.382130</td>\n",
              "      <td>-0.126026</td>\n",
              "      <td>5.749525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.848088e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.608593</td>\n",
              "      <td>-0.470655</td>\n",
              "      <td>-0.364713</td>\n",
              "      <td>-0.005981</td>\n",
              "      <td>14.676795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.036507e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.027272</td>\n",
              "      <td>9.782197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.249265e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.297656</td>\n",
              "      <td>-0.295595</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.253049</td>\n",
              "      <td>8.652210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.474191e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472226</td>\n",
              "      <td>-0.472214</td>\n",
              "      <td>-0.472143</td>\n",
              "      <td>-0.040728</td>\n",
              "      <td>5.136521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.185478e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472211</td>\n",
              "      <td>-0.472199</td>\n",
              "      <td>-0.472128</td>\n",
              "      <td>-0.040677</td>\n",
              "      <td>5.137217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.305496e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465652</td>\n",
              "      <td>-0.451294</td>\n",
              "      <td>-0.387952</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>15.948907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.623162e-19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.512813</td>\n",
              "      <td>-0.484370</td>\n",
              "      <td>-0.394374</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>18.117274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.433906e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465076</td>\n",
              "      <td>-0.450867</td>\n",
              "      <td>-0.387911</td>\n",
              "      <td>-0.065398</td>\n",
              "      <td>15.985183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.117077e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.649830</td>\n",
              "      <td>-0.201979</td>\n",
              "      <td>0.153372</td>\n",
              "      <td>0.500566</td>\n",
              "      <td>2.289524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>2.924044e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.520259</td>\n",
              "      <td>-0.487576</td>\n",
              "      <td>-0.401957</td>\n",
              "      <td>0.099112</td>\n",
              "      <td>19.653834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.579099e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.704035</td>\n",
              "      <td>-0.201615</td>\n",
              "      <td>0.153008</td>\n",
              "      <td>0.500005</td>\n",
              "      <td>2.286367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e712dd7-f605-41eb-892c-405be22e2c76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e712dd7-f605-41eb-892c-405be22e2c76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e712dd7-f605-41eb-892c-405be22e2c76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-02dcbd1a-455c-4e14-b42b-dc14754c90cf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02dcbd1a-455c-4e14-b42b-dc14754c90cf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-02dcbd1a-455c-4e14-b42b-dc14754c90cf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6aaf6551-55ae-4f5c-8973-2dc4e362a4e4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('normed_train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6aaf6551-55ae-4f5c-8973-2dc4e362a4e4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('normed_train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "normed_train_stats",
              "summary": "{\n  \"name\": \"normed_train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.130827903032307e-17,\n        \"min\": -1.13587870072444e-16,\n        \"max\": 1.012169139259402e-16,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          8.997059015639129e-18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1848847376991577e-14,\n        \"min\": 0.9999999999999469,\n        \"max\": 1.000000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9999999999999469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.397919147016072,\n        \"min\": -27.798013059723413,\n        \"max\": -0.2976557097171227,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.5434826895194267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13303447554408515,\n        \"min\": -0.5589012867384386,\n        \"max\": -0.008976423627184933,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.4509566393357717\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1982775721363611,\n        \"min\": -0.47214325593943735,\n        \"max\": 0.15337222439091985,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.3821712393941821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19358796580988194,\n        \"min\": -0.2530486572965829,\n        \"max\": 0.500566267762931,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.12679376438970055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4656321224551565,\n        \"min\": 2.2863670387300563,\n        \"max\": 19.653834404298966,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          5.733411150971922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "train_size = normed_train_data.shape\n",
        "test_size = normed_test_data.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "normed_train_stats = normed_train_data.describe()\n",
        "normed_train_stats = normed_train_stats.transpose()\n",
        "normed_train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmNpCfOqCwqv"
      },
      "source": [
        "## 4.1. Optimización masiva de parámetros\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_conv_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(hp.Int('hidden_blocks', min_value=1, max_value=4)):\n",
        "        filters = hp.Int(f'n_filters{i}', min_value=4, max_value=32, step=4)\n",
        "        kernel_size = hp.Choice(f'size{i}', values=[2, 3, 4, 5])\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))  # Valor fijo para la etapa 1\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_conv_model(HyperParameters())\n",
        "\n",
        "tuner_1 = kt.BayesianOptimization(\n",
        "    build_conv_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage1',\n",
        "    project_name='cnn1d_conv_structure'\n",
        ")\n",
        "\n",
        "#28min 30s sin GPU"
      ],
      "metadata": {
        "id": "U_quo4A8uaj8",
        "outputId": "df9965c0-4e89-4852-8767-634bc8de1dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_1.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=200,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp1 = tuner_1.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp1.values"
      ],
      "metadata": {
        "id": "xgJLDUbVGQrN",
        "outputId": "9eaebfe1-0361-4b5f-c5c1-741f19534d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.760284811258316\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7610759437084198\n",
            "Total elapsed time: 00h 02m 14s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "4                 |1                 |hidden_blocks\n",
            "32                |16                |n_filters0\n",
            "5                 |3                 |size0\n",
            "20                |None              |n_filters1\n",
            "2                 |None              |size1\n",
            "\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 267ms/step - binary_accuracy: 0.5885 - f1_score: 0.7603 - loss: 0.6984 - precision: 0.6322 - recall: 0.7855 - val_binary_accuracy: 0.5807 - val_f1_score: 0.7799 - val_loss: 0.6874 - val_precision: 0.6257 - val_recall: 0.8564\n",
            "Epoch 2/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - binary_accuracy: 0.6316 - f1_score: 0.7573 - loss: 0.6325 - precision: 0.6417 - recall: 0.8960 - val_binary_accuracy: 0.5997 - val_f1_score: 0.7799 - val_loss: 0.6814 - val_precision: 0.6396 - val_recall: 0.8564\n",
            "Epoch 3/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.6683 - f1_score: 0.7607 - loss: 0.6148 - precision: 0.6688 - recall: 0.9096 - val_binary_accuracy: 0.6076 - val_f1_score: 0.7799 - val_loss: 0.6771 - val_precision: 0.6444 - val_recall: 0.8614\n",
            "Epoch 4/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.6955 - f1_score: 0.7524 - loss: 0.6009 - precision: 0.6886 - recall: 0.9048 - val_binary_accuracy: 0.6092 - val_f1_score: 0.7799 - val_loss: 0.6748 - val_precision: 0.6495 - val_recall: 0.8441\n",
            "Epoch 5/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.6730 - f1_score: 0.7577 - loss: 0.5969 - precision: 0.6744 - recall: 0.8980 - val_binary_accuracy: 0.6123 - val_f1_score: 0.7799 - val_loss: 0.6730 - val_precision: 0.6532 - val_recall: 0.8391\n",
            "Epoch 6/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6712 - f1_score: 0.7532 - loss: 0.5944 - precision: 0.6648 - recall: 0.9212 - val_binary_accuracy: 0.6028 - val_f1_score: 0.7799 - val_loss: 0.6723 - val_precision: 0.6515 - val_recall: 0.8144\n",
            "Epoch 7/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.6813 - f1_score: 0.7468 - loss: 0.5855 - precision: 0.6995 - recall: 0.8154 - val_binary_accuracy: 0.6108 - val_f1_score: 0.7799 - val_loss: 0.6698 - val_precision: 0.6599 - val_recall: 0.8069\n",
            "Epoch 8/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7102 - f1_score: 0.7567 - loss: 0.5747 - precision: 0.7212 - recall: 0.8550 - val_binary_accuracy: 0.6139 - val_f1_score: 0.7799 - val_loss: 0.6667 - val_precision: 0.6587 - val_recall: 0.8218\n",
            "Epoch 9/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7127 - f1_score: 0.7577 - loss: 0.5616 - precision: 0.7141 - recall: 0.8823 - val_binary_accuracy: 0.6218 - val_f1_score: 0.7799 - val_loss: 0.6652 - val_precision: 0.6730 - val_recall: 0.7946\n",
            "Epoch 10/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7154 - f1_score: 0.7603 - loss: 0.5485 - precision: 0.7330 - recall: 0.8439 - val_binary_accuracy: 0.6187 - val_f1_score: 0.7799 - val_loss: 0.6618 - val_precision: 0.6694 - val_recall: 0.7970\n",
            "Epoch 11/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7182 - f1_score: 0.7569 - loss: 0.5438 - precision: 0.7370 - recall: 0.8366 - val_binary_accuracy: 0.6187 - val_f1_score: 0.7799 - val_loss: 0.6586 - val_precision: 0.6730 - val_recall: 0.7847\n",
            "Epoch 12/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7147 - f1_score: 0.7559 - loss: 0.5507 - precision: 0.7243 - recall: 0.8589 - val_binary_accuracy: 0.6297 - val_f1_score: 0.7799 - val_loss: 0.6523 - val_precision: 0.6742 - val_recall: 0.8144\n",
            "Epoch 13/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7262 - f1_score: 0.7568 - loss: 0.5488 - precision: 0.7301 - recall: 0.8739 - val_binary_accuracy: 0.6313 - val_f1_score: 0.7799 - val_loss: 0.6517 - val_precision: 0.6831 - val_recall: 0.7896\n",
            "Epoch 14/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7137 - f1_score: 0.7562 - loss: 0.5460 - precision: 0.7267 - recall: 0.8480 - val_binary_accuracy: 0.6250 - val_f1_score: 0.7799 - val_loss: 0.6524 - val_precision: 0.6819 - val_recall: 0.7748\n",
            "Epoch 15/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7367 - f1_score: 0.7566 - loss: 0.5229 - precision: 0.7390 - recall: 0.8773 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6461 - val_precision: 0.6947 - val_recall: 0.8168\n",
            "Epoch 16/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7393 - f1_score: 0.7515 - loss: 0.5199 - precision: 0.7490 - recall: 0.8533 - val_binary_accuracy: 0.6487 - val_f1_score: 0.7799 - val_loss: 0.6412 - val_precision: 0.6953 - val_recall: 0.8020\n",
            "Epoch 17/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7583 - f1_score: 0.7640 - loss: 0.5208 - precision: 0.7583 - recall: 0.8949 - val_binary_accuracy: 0.6582 - val_f1_score: 0.7799 - val_loss: 0.6260 - val_precision: 0.6950 - val_recall: 0.8292\n",
            "Epoch 18/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7444 - f1_score: 0.7664 - loss: 0.5124 - precision: 0.7682 - recall: 0.8436 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6246 - val_precision: 0.7051 - val_recall: 0.7871\n",
            "Epoch 19/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7437 - f1_score: 0.7638 - loss: 0.5133 - precision: 0.7563 - recall: 0.8640 - val_binary_accuracy: 0.6535 - val_f1_score: 0.7799 - val_loss: 0.6194 - val_precision: 0.6956 - val_recall: 0.8144\n",
            "Epoch 20/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7458 - f1_score: 0.7694 - loss: 0.5139 - precision: 0.7656 - recall: 0.8552 - val_binary_accuracy: 0.6677 - val_f1_score: 0.7799 - val_loss: 0.6105 - val_precision: 0.7100 - val_recall: 0.8119\n",
            "Epoch 21/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7623 - f1_score: 0.7602 - loss: 0.4887 - precision: 0.7801 - recall: 0.8523 - val_binary_accuracy: 0.6693 - val_f1_score: 0.7799 - val_loss: 0.6012 - val_precision: 0.7327 - val_recall: 0.7599\n",
            "Epoch 22/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7523 - f1_score: 0.7738 - loss: 0.4950 - precision: 0.7808 - recall: 0.8443 - val_binary_accuracy: 0.6772 - val_f1_score: 0.7799 - val_loss: 0.6010 - val_precision: 0.7101 - val_recall: 0.8366\n",
            "Epoch 23/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7757 - f1_score: 0.7708 - loss: 0.4912 - precision: 0.7875 - recall: 0.8785 - val_binary_accuracy: 0.7009 - val_f1_score: 0.7799 - val_loss: 0.5762 - val_precision: 0.7483 - val_recall: 0.8020\n",
            "Epoch 24/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7716 - f1_score: 0.7626 - loss: 0.4691 - precision: 0.7760 - recall: 0.8849 - val_binary_accuracy: 0.7041 - val_f1_score: 0.7799 - val_loss: 0.5647 - val_precision: 0.7416 - val_recall: 0.8243\n",
            "Epoch 25/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7659 - f1_score: 0.7628 - loss: 0.4830 - precision: 0.7859 - recall: 0.8523 - val_binary_accuracy: 0.7247 - val_f1_score: 0.7799 - val_loss: 0.5578 - val_precision: 0.7457 - val_recall: 0.8639\n",
            "Epoch 26/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7707 - f1_score: 0.7608 - loss: 0.4669 - precision: 0.7920 - recall: 0.8505 - val_binary_accuracy: 0.6725 - val_f1_score: 0.7799 - val_loss: 0.5858 - val_precision: 0.7074 - val_recall: 0.8317\n",
            "Epoch 27/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7807 - f1_score: 0.7610 - loss: 0.4652 - precision: 0.7975 - recall: 0.8626 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5485 - val_precision: 0.7540 - val_recall: 0.8267\n",
            "Epoch 28/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7823 - f1_score: 0.7527 - loss: 0.4737 - precision: 0.7780 - recall: 0.8961 - val_binary_accuracy: 0.7104 - val_f1_score: 0.7799 - val_loss: 0.5650 - val_precision: 0.7600 - val_recall: 0.7995\n",
            "Epoch 29/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7577 - f1_score: 0.7527 - loss: 0.4841 - precision: 0.7834 - recall: 0.8263 - val_binary_accuracy: 0.7199 - val_f1_score: 0.7799 - val_loss: 0.5585 - val_precision: 0.7918 - val_recall: 0.7624\n",
            "Epoch 30/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7686 - f1_score: 0.7670 - loss: 0.4801 - precision: 0.7859 - recall: 0.8630 - val_binary_accuracy: 0.7009 - val_f1_score: 0.7799 - val_loss: 0.5589 - val_precision: 0.7822 - val_recall: 0.7376\n",
            "Epoch 31/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.7783 - f1_score: 0.7547 - loss: 0.4536 - precision: 0.7944 - recall: 0.8561 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5448 - val_precision: 0.7563 - val_recall: 0.8218\n",
            "Epoch 32/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7783 - f1_score: 0.7607 - loss: 0.4490 - precision: 0.7857 - recall: 0.8781 - val_binary_accuracy: 0.7215 - val_f1_score: 0.7799 - val_loss: 0.5496 - val_precision: 0.7780 - val_recall: 0.7896\n",
            "Epoch 33/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7850 - f1_score: 0.7548 - loss: 0.4568 - precision: 0.8022 - recall: 0.8568 - val_binary_accuracy: 0.7247 - val_f1_score: 0.7799 - val_loss: 0.5423 - val_precision: 0.7964 - val_recall: 0.7649\n",
            "Epoch 34/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.7748 - f1_score: 0.7478 - loss: 0.4663 - precision: 0.8118 - recall: 0.8130 - val_binary_accuracy: 0.7073 - val_f1_score: 0.7799 - val_loss: 0.5510 - val_precision: 0.7844 - val_recall: 0.7475\n",
            "Epoch 35/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.7964 - f1_score: 0.7626 - loss: 0.4465 - precision: 0.8251 - recall: 0.8500 - val_binary_accuracy: 0.7263 - val_f1_score: 0.7799 - val_loss: 0.5435 - val_precision: 0.7954 - val_recall: 0.7698\n",
            "Epoch 36/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7924 - f1_score: 0.7669 - loss: 0.4471 - precision: 0.8158 - recall: 0.8605 - val_binary_accuracy: 0.7152 - val_f1_score: 0.7799 - val_loss: 0.5460 - val_precision: 0.7732 - val_recall: 0.7847\n",
            "Epoch 37/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.7928 - f1_score: 0.7644 - loss: 0.4332 - precision: 0.8098 - recall: 0.8697 - val_binary_accuracy: 0.7326 - val_f1_score: 0.7799 - val_loss: 0.5414 - val_precision: 0.7752 - val_recall: 0.8193\n",
            "Epoch 38/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.7944 - f1_score: 0.7558 - loss: 0.4339 - precision: 0.8164 - recall: 0.8535 - val_binary_accuracy: 0.7500 - val_f1_score: 0.7799 - val_loss: 0.5383 - val_precision: 0.7733 - val_recall: 0.8614\n",
            "Epoch 39/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8069 - f1_score: 0.7547 - loss: 0.4140 - precision: 0.8198 - recall: 0.8732 - val_binary_accuracy: 0.7294 - val_f1_score: 0.7799 - val_loss: 0.5457 - val_precision: 0.7920 - val_recall: 0.7822\n",
            "Epoch 40/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7920 - f1_score: 0.7565 - loss: 0.4280 - precision: 0.8230 - recall: 0.8389 - val_binary_accuracy: 0.7342 - val_f1_score: 0.7799 - val_loss: 0.5381 - val_precision: 0.7757 - val_recall: 0.8218\n",
            "Epoch 41/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8051 - f1_score: 0.7547 - loss: 0.4166 - precision: 0.8163 - recall: 0.8759 - val_binary_accuracy: 0.7089 - val_f1_score: 0.7799 - val_loss: 0.5454 - val_precision: 0.7989 - val_recall: 0.7277\n",
            "Epoch 42/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8112 - f1_score: 0.7703 - loss: 0.4176 - precision: 0.8292 - recall: 0.8800 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5407 - val_precision: 0.7650 - val_recall: 0.8540\n",
            "Epoch 43/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8087 - f1_score: 0.7490 - loss: 0.4158 - precision: 0.8188 - recall: 0.8758 - val_binary_accuracy: 0.7405 - val_f1_score: 0.7799 - val_loss: 0.5417 - val_precision: 0.7575 - val_recall: 0.8738\n",
            "Epoch 44/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7978 - f1_score: 0.7500 - loss: 0.4220 - precision: 0.8006 - recall: 0.8838 - val_binary_accuracy: 0.7453 - val_f1_score: 0.7799 - val_loss: 0.5332 - val_precision: 0.7670 - val_recall: 0.8639\n",
            "Epoch 45/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8198 - f1_score: 0.7574 - loss: 0.3960 - precision: 0.8395 - recall: 0.8710 - val_binary_accuracy: 0.7310 - val_f1_score: 0.7799 - val_loss: 0.5651 - val_precision: 0.7623 - val_recall: 0.8416\n",
            "Epoch 46/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7999 - f1_score: 0.7527 - loss: 0.4060 - precision: 0.8179 - recall: 0.8600 - val_binary_accuracy: 0.7405 - val_f1_score: 0.7799 - val_loss: 0.5390 - val_precision: 0.7857 - val_recall: 0.8168\n",
            "Epoch 47/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8089 - f1_score: 0.7556 - loss: 0.4028 - precision: 0.8226 - recall: 0.8733 - val_binary_accuracy: 0.7073 - val_f1_score: 0.7799 - val_loss: 0.5689 - val_precision: 0.7844 - val_recall: 0.7475\n",
            "Epoch 48/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7974 - f1_score: 0.7556 - loss: 0.4179 - precision: 0.8347 - recall: 0.8310 - val_binary_accuracy: 0.7468 - val_f1_score: 0.7799 - val_loss: 0.5491 - val_precision: 0.7748 - val_recall: 0.8515\n",
            "Epoch 49/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8032 - f1_score: 0.7464 - loss: 0.4165 - precision: 0.8181 - recall: 0.8612 - val_binary_accuracy: 0.7278 - val_f1_score: 0.7799 - val_loss: 0.5537 - val_precision: 0.7886 - val_recall: 0.7847\n",
            "Epoch 50/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8158 - f1_score: 0.7638 - loss: 0.3847 - precision: 0.8301 - recall: 0.8825 - val_binary_accuracy: 0.7263 - val_f1_score: 0.7799 - val_loss: 0.5547 - val_precision: 0.8016 - val_recall: 0.7599\n",
            "Epoch 51/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8194 - f1_score: 0.7592 - loss: 0.3883 - precision: 0.8299 - recall: 0.8868 - val_binary_accuracy: 0.7342 - val_f1_score: 0.7799 - val_loss: 0.5448 - val_precision: 0.7744 - val_recall: 0.8243\n",
            "Epoch 52/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8194 - f1_score: 0.7480 - loss: 0.3904 - precision: 0.8291 - recall: 0.8794 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5858 - val_precision: 0.7922 - val_recall: 0.8020\n",
            "Epoch 53/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8271 - f1_score: 0.7634 - loss: 0.3725 - precision: 0.8348 - recall: 0.8972 - val_binary_accuracy: 0.7389 - val_f1_score: 0.7799 - val_loss: 0.5579 - val_precision: 0.7852 - val_recall: 0.8144\n",
            "Epoch 54/200\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8251 - f1_score: 0.7633 - loss: 0.3718 - precision: 0.8248 - recall: 0.9096 - val_binary_accuracy: 0.7168 - val_f1_score: 0.7799 - val_loss: 0.5951 - val_precision: 0.7792 - val_recall: 0.7772\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1127897549>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tuner_1.search(normed_train_data, train_labels,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    115\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The model does not have any trainable weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;31m# Run update step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3005\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m       return self._replica_ctx_update(\n\u001b[0m\u001b[1;32m   3008\u001b[0m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[1;32m   3009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2884\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3476\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   3477\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 3478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3483\u001b[0m         _CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   3484\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ):\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             ops.divide(\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             ),\n\u001b[1;32m    150\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\u001b[0m in \u001b[0;36msparse_wrapper\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;31m# x2 is an IndexedSlices, densify.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msparse_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   3938\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    491\u001b[0m         \"AddV2\", x=x, y=y, name=name)\n\u001b[1;32m    492\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     return super()._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m       ret = Operation.from_node_def(\n\u001b[0m\u001b[1;32m   2702\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mfrom_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       if not all(\n\u001b[0m\u001b[1;32m   1175\u001b[0m           x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):\n\u001b[1;32m   1176\u001b[0m         raise TypeError(\"In op '%s', input types (%s) are not compatible \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m       if not all(\n\u001b[0m\u001b[1;32m   1175\u001b[0m           x.is_compatible_with(i.dtype) for i, x in zip(inputs, input_types)):\n\u001b[1;32m   1176\u001b[0m         raise TypeError(\"In op '%s', input types (%s) are not compatible \"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(best_hp1.get('hidden_blocks')):\n",
        "        filters = best_hp1.get(f'n_filters{i}')\n",
        "        kernel_size = best_hp1.get(f'size{i}')\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Aquí ajustamos solo los parámetros nuevos\n",
        "    dense_units = hp.Int('dense_units', min_value=16, max_value=128, step=8)\n",
        "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_final_model(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner_2 = kt.BayesianOptimization(\n",
        "    build_final_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage2',\n",
        "    project_name='cnn1d_dense_lr_batch'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "6DnGkCSIvH_h",
        "outputId": "0763117c-93aa-4313-ec4e-78ae6573516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │         \u001b[38;5;34m1,372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │           \u001b[38;5;34m112\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m5,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,101\u001b[0m (35.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,101</span> (35.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,981\u001b[0m (35.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,981</span> (35.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage2/cnn1d_dense_lr_batch/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_2.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
        "                    batch_size=kt.HyperParameters().Choice('batch_size', [128, 358, 537]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okut5Zt2GmPF",
        "outputId": "b6224996-120f-40e7-8d9a-2c09ada59879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.7332402169704437\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7618715167045593\n",
            "Total elapsed time: 01h 42m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp2 = tuner_2.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp2.values"
      ],
      "metadata": {
        "id": "w1IQLia14ibr",
        "outputId": "ee370ad5-4952-4a00-b0e0-2451b05df689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_units': 40, 'learning_rate': 0.0004578995948758916}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNb7pcumf33T"
      },
      "source": [
        "## 4.2. Optimización de hiperparámetros del mejor modelo conseguido"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_model_C1(hp):\n",
        "  model = Sequential()\n",
        "  filters1 = hp.Int('nfilters1', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters1, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters2 = hp.Int('nfilters2', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters2, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters3 = hp.Int('nfilters3', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters3, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Flatten())\n",
        "  dense_units = hp.Int('dense_units', min_value=16, max_value=64, step=4)\n",
        "  model.add(layers.Dense(dense_units, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "   # compilación del modelo\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "  return model\n",
        "\n",
        "model = build_model_C1(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model_C1,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning_stage',\n",
        "    project_name='TFG'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "KHuAnr0MfWC7",
        "outputId": "059a5330-06b0-449b-c789-7868f4b36636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,477\u001b[0m (5.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,477</span> (5.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,453\u001b[0m (5.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,453</span> (5.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage/TFG/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1T1WwGjonc",
        "outputId": "e77238f5-1c17-4c36-82ce-f681bd90a235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 27s]\n",
            "val_binary_accuracy: 0.7667597532272339\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7891061305999756\n",
            "Total elapsed time: 01h 01m 48s\n",
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nfilters1': 64, 'nfilters2': 52, 'nfilters3': 56, 'dense_units': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Optimización bayesiana de learning rate y optimizador\n",
        "\n",
        "Mercedes no utilizó validación cruzada; realmente no parece que haga falta porque el dataset no es tan pequeño (supera las 1000 muestras)"
      ],
      "metadata": {
        "id": "rjQqaNgvECTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Asegúrate de tener normed_train_data, train_labels definidos antes de esto\n",
        "\n",
        "# Añadir dimensión para Conv1D\n",
        "#X = np.expand_dims(normed_train_data.values, axis=2)\n",
        "#y = train_labels.values\n",
        "\n",
        "# Función de construcción del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,  # Número de combinaciones a probar\n",
        "    directory='bayesian_opt',\n",
        "    project_name='cnn_lr_opt'\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy',\n",
        "    patience=10, # Número de épocas sin mejora\n",
        "    restore_best_weights=True # Restaurar los pesos del modelo con la mejor val_loss\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500,\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# Muestra los mejores resultados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")"
      ],
      "metadata": {
        "id": "BD55-165EBGL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Optimización bayesiana más completa"
      ],
      "metadata": {
        "id": "-pjdu1IsCHBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación simple"
      ],
      "metadata": {
        "id": "57WFLZh_C0k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations # activations is not strictly needed but was in original imports\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from keras_tuner import HyperParameters\n",
        "from sklearn.model_selection import train_test_split # Not used for the final explicit split, but kept from original\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "\n",
        "# Función de construcción del modelo con hiperparámetros extendidos\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Hiperparámetro: Regularización L2 para todas las capas convolucionales y densas\n",
        "    #hp_l2_reg = hp.Float('l2_reg', min_value=1e-6, max_value=1e-2, sampling='log')\n",
        "\n",
        "    # Capa Conv1D 1\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv1_filters', min_value=16, max_value=64, step=8), 2,\n",
        "        strides=1, padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg),\n",
        "        input_shape=(normed_train_data.shape[1], 1)\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv1', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    # Capa Conv1D 2\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv2_filters', min_value=16, max_value=64, step=8), 3,\n",
        "        padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg)\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv2', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    # Capa Conv1D 3\n",
        "    model.add(layers.Conv1D(\n",
        "        hp.Int('conv3_filters', min_value=16, max_value=64, step=8),\n",
        "        hp.Int('size_conv3_kernel', min_value=2, max_value=5, step=1),\n",
        "        padding='same', activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg) # L2 Regularization\n",
        "    ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_conv3', min_value=0.1, max_value=0.4, step=0.05)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(\n",
        "        hp.Int('dense_units', min_value=16, max_value=128, step=8),\n",
        "        activation='relu',\n",
        "        #kernel_regularizer=keras.regularizers.l2(hp_l2_reg) # L2 Regularization\n",
        "    ))\n",
        "    model.add(layers.Dropout(hp.Float('dropout_rate_dense', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    #hp_batch = hp.Choice('batch_size', [32, 64, 128, 256, ceil(train_size[0]*0.1)])\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score(name='f1_score')])\n",
        "    return model\n",
        "\n",
        "print(\"\\n==================== 📈 Optimización de Hiperparámetros (Validación Simple Mejorada) ====================\")\n",
        "\n",
        "# Re-modelar los datos de entrada para Conv1D (muestras, pasos, canales)\n",
        "# Los datos originales son (muestras, características)\n",
        "X_train_reshaped = np.expand_dims(normed_train_data.values, axis=2)\n",
        "X_test_reshaped = np.expand_dims(normed_test_data.values, axis=2)\n",
        "\n",
        "# 2. Configurar e iniciar Keras Tuner para la optimización de hiperparámetros\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    directory='keras_tuner_results_improved',\n",
        "    project_name='simple_split_optimization_improved',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_binary_accuracy',\n",
        "    patience=15, # Número de épocas sin mejora\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500, # Max. épocas, early stopping lo detendrá antes si converge\n",
        "             # Ahora, el batch_size es un hiperparámetro. tuner.search lo gestionará internamente.\n",
        "             # Si se quisiera establecer un batch_size fijo aquí, se haría así:\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# 3. Obtener los mejores hiperparámetros encontrados\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"✅ Mejores Hiperparámetros Encontrados:\")\n",
        "print(f\"  Optimizador: {best_hp.get('optimizer')}\")\n",
        "print(f\"  Tasa de Aprendizaje: {best_hp.get('learning_rate'):.1e}\")\n",
        "print(f\"  Filtros Conv1: {best_hp.get('conv1_filters')}\")\n",
        "print(f\"  Filtros Conv2: {best_hp.get('conv2_filters')}\")\n",
        "print(f\"  Filtros Conv3: {best_hp.get('conv3_filters')}\")\n",
        "print(f\"  Unidades Dense: {best_hp.get('dense_units')}\")\n",
        "print(f\"  Dropout Conv: {best_hp.get('dropout_rate_conv1'):.2f} (ejemplo)\") # Se asume una tasa común para las tres capas Conv\n",
        "print(f\"  Dropout Dense: {best_hp.get('dropout_rate_dense'):.2f}\")\n",
        "print(f\"  L2 Reg: {best_hp.get('l2_reg'):.1e}\")\n",
        "print(f\"  Batch Size: {best_hp.get('batch_size')}\")"
      ],
      "metadata": {
        "id": "zhUc_U9qeD4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfftlXWEG-e"
      },
      "source": [
        "## 5. Entrenamiento y validación del modelo\n",
        "\n",
        "Reservamos el 20% de los datos de entrenamiento para la validación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Construir y entrenar el modelo final con los mejores HP en todo el conjunto de entrenamiento\n",
        "# (X_train_reshaped y train_labels)\n",
        "print(\"\\nEntrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento completo...\")\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "final_model = tuner.hypermodel.build(best_hp)\n",
        "final_model.fit(normed_train_data, train_labels,\n",
        "                epochs=1000, # Max. épocas, early stopping lo detendrá\n",
        "                #batch_size=best_hp.get('batch_size'), # Usar el batch_size óptimo\n",
        "                batch_size=ceil(train_size[0]*0.1),\n",
        "                callbacks=[early_stopping_callback],\n",
        "                verbose=1) # Poner en 1 para ver el progreso del entrenamiento final\n",
        "\n",
        "# 5. Evaluar el modelo final en el conjunto de prueba independiente (normed_test_data)\n",
        "print(\"\\n==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\")\n",
        "#y_pred_probs = final_model.predict(normed_test_data)\n",
        "#y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "# Calcular métricas finales\n",
        "#acc = accuracy_score(test_labels, y_pred)\n",
        "#prec = precision_score(test_labels, y_pred)\n",
        "#rec = recall_score(test_labels, y_pred)\n",
        "#f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = final_model.evaluate(normed_test_data, test_labels, batch_size=(test_size[0]))\n",
        "\n",
        "print(f\"Accuracy en Conjunto de Prueba: {test_acc:.4f}\")\n",
        "print(f\"Precision en Conjunto de Prueba: {test_prec:.4f}\")\n",
        "print(f\"Recall en Conjunto de Prueba: {test_rec:.4f}\")\n",
        "print(f\"F1-Score en Conjunto de Prueba: {test_f1:.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "predictions = final_model.predict(normed_test_data)\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "# Muestra la matriz de confusión\n",
        "def plot_confusion_matrix(cm):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.title('Matriz de Confusión')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(cm)\n",
        "# Muestra métricas adicionales\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=['Clase 0', 'Clase 1']))"
      ],
      "metadata": {
        "id": "TpUm-PkTCZaX",
        "outputId": "141202b2-b00f-4f69-d459-b5ff89998676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento completo...\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - binary_accuracy: 0.5944 - f1_score: 0.7715 - loss: 0.7729 - precision: 0.6391 - recall: 0.8131\n",
            "Epoch 2/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6678 - f1_score: 0.7732 - loss: 0.6075 - precision: 0.6979 - recall: 0.8413 \n",
            "Epoch 3/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6577 - f1_score: 0.7616 - loss: 0.6141 - precision: 0.6958 - recall: 0.7913 \n",
            "Epoch 4/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_binary_accuracy` which is not available. Available metrics are: binary_accuracy,f1_score,loss,precision,recall\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6823 - f1_score: 0.7616 - loss: 0.5807 - precision: 0.6962 - recall: 0.8581 \n",
            "Epoch 5/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6962 - f1_score: 0.7663 - loss: 0.5652 - precision: 0.7084 - recall: 0.8693 \n",
            "Epoch 6/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7226 - f1_score: 0.7724 - loss: 0.5441 - precision: 0.7389 - recall: 0.8643 \n",
            "Epoch 7/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7211 - f1_score: 0.7537 - loss: 0.5447 - precision: 0.7305 - recall: 0.8541 \n",
            "Epoch 8/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7131 - f1_score: 0.7529 - loss: 0.5494 - precision: 0.7283 - recall: 0.8366 \n",
            "Epoch 9/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7440 - f1_score: 0.7701 - loss: 0.4997 - precision: 0.7607 - recall: 0.8625 \n",
            "Epoch 10/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7486 - f1_score: 0.7635 - loss: 0.5035 - precision: 0.7639 - recall: 0.8572 \n",
            "Epoch 11/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7338 - f1_score: 0.7654 - loss: 0.5072 - precision: 0.7601 - recall: 0.8344 \n",
            "Epoch 12/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7482 - f1_score: 0.7609 - loss: 0.4925 - precision: 0.7661 - recall: 0.8492 \n",
            "Epoch 13/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7709 - f1_score: 0.7609 - loss: 0.4741 - precision: 0.7810 - recall: 0.8712 \n",
            "Epoch 14/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7710 - f1_score: 0.7629 - loss: 0.4698 - precision: 0.7816 - recall: 0.8728\n",
            "Epoch 15/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7832 - f1_score: 0.7621 - loss: 0.4524 - precision: 0.7855 - recall: 0.8912 \n",
            "Epoch 16/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7573 - f1_score: 0.7565 - loss: 0.4697 - precision: 0.7719 - recall: 0.8552 \n",
            "Epoch 17/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7921 - f1_score: 0.7696 - loss: 0.4411 - precision: 0.8011 - recall: 0.8877 \n",
            "Epoch 18/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8059 - f1_score: 0.7701 - loss: 0.4179 - precision: 0.8199 - recall: 0.8842 \n",
            "Epoch 19/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7966 - f1_score: 0.7588 - loss: 0.4327 - precision: 0.8136 - recall: 0.8650 \n",
            "Epoch 20/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.7863 - f1_score: 0.7624 - loss: 0.4413 - precision: 0.7931 - recall: 0.8840 \n",
            "Epoch 21/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8044 - f1_score: 0.7665 - loss: 0.4181 - precision: 0.8112 - recall: 0.8935 \n",
            "Epoch 22/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8069 - f1_score: 0.7702 - loss: 0.4122 - precision: 0.8101 - recall: 0.9045\n",
            "Epoch 23/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.7893 - f1_score: 0.7700 - loss: 0.4370 - precision: 0.8139 - recall: 0.8605\n",
            "Epoch 24/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8070 - f1_score: 0.7601 - loss: 0.3914 - precision: 0.8247 - recall: 0.8701 \n",
            "Epoch 25/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8237 - f1_score: 0.7597 - loss: 0.3813 - precision: 0.8263 - recall: 0.9017 \n",
            "Epoch 26/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8098 - f1_score: 0.7618 - loss: 0.4005 - precision: 0.8319 - recall: 0.8657 \n",
            "Epoch 27/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8092 - f1_score: 0.7521 - loss: 0.3967 - precision: 0.8154 - recall: 0.8838\n",
            "Epoch 28/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8463 - f1_score: 0.7563 - loss: 0.3510 - precision: 0.8582 - recall: 0.8954 \n",
            "Epoch 29/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8159 - f1_score: 0.7659 - loss: 0.3815 - precision: 0.8340 - recall: 0.8783\n",
            "Epoch 30/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8292 - f1_score: 0.7595 - loss: 0.3748 - precision: 0.8400 - recall: 0.8910\n",
            "Epoch 31/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8358 - f1_score: 0.7667 - loss: 0.3673 - precision: 0.8426 - recall: 0.9048\n",
            "Epoch 32/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8511 - f1_score: 0.7597 - loss: 0.3427 - precision: 0.8640 - recall: 0.8985 \n",
            "Epoch 33/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8378 - f1_score: 0.7547 - loss: 0.3457 - precision: 0.8474 - recall: 0.8931 \n",
            "Epoch 34/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8230 - f1_score: 0.7616 - loss: 0.3626 - precision: 0.8279 - recall: 0.9001 \n",
            "Epoch 35/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8468 - f1_score: 0.7652 - loss: 0.3388 - precision: 0.8671 - recall: 0.8894 \n",
            "Epoch 36/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8373 - f1_score: 0.7597 - loss: 0.3432 - precision: 0.8552 - recall: 0.8841 \n",
            "Epoch 37/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8512 - f1_score: 0.7649 - loss: 0.3351 - precision: 0.8595 - recall: 0.9081 \n",
            "Epoch 38/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8464 - f1_score: 0.7664 - loss: 0.3347 - precision: 0.8684 - recall: 0.8879 \n",
            "Epoch 39/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8485 - f1_score: 0.7608 - loss: 0.3308 - precision: 0.8525 - recall: 0.9111 \n",
            "Epoch 40/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8561 - f1_score: 0.7584 - loss: 0.3182 - precision: 0.8735 - recall: 0.8941 \n",
            "Epoch 41/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8479 - f1_score: 0.7645 - loss: 0.3116 - precision: 0.8600 - recall: 0.9010 \n",
            "Epoch 42/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8560 - f1_score: 0.7545 - loss: 0.3094 - precision: 0.8886 - recall: 0.8717 \n",
            "Epoch 43/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8491 - f1_score: 0.7664 - loss: 0.3092 - precision: 0.8745 - recall: 0.8844 \n",
            "Epoch 44/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8657 - f1_score: 0.7713 - loss: 0.3025 - precision: 0.8949 - recall: 0.8917 \n",
            "Epoch 45/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8552 - f1_score: 0.7576 - loss: 0.3130 - precision: 0.8642 - recall: 0.9050 \n",
            "Epoch 46/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8576 - f1_score: 0.7578 - loss: 0.3116 - precision: 0.8889 - recall: 0.8761 \n",
            "Epoch 47/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8699 - f1_score: 0.7548 - loss: 0.2986 - precision: 0.8844 - recall: 0.9035 \n",
            "Epoch 48/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8464 - f1_score: 0.7660 - loss: 0.3166 - precision: 0.8866 - recall: 0.8646 \n",
            "Epoch 49/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8871 - f1_score: 0.7671 - loss: 0.2757 - precision: 0.8991 - recall: 0.9220 \n",
            "Epoch 50/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8654 - f1_score: 0.7610 - loss: 0.2939 - precision: 0.8864 - recall: 0.8962 \n",
            "Epoch 51/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8799 - f1_score: 0.7646 - loss: 0.2741 - precision: 0.8921 - recall: 0.9170 \n",
            "Epoch 52/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8901 - f1_score: 0.7561 - loss: 0.2623 - precision: 0.9036 - recall: 0.9172 \n",
            "Epoch 53/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8726 - f1_score: 0.7697 - loss: 0.2753 - precision: 0.8874 - recall: 0.9114 \n",
            "Epoch 54/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8783 - f1_score: 0.7626 - loss: 0.2768 - precision: 0.8999 - recall: 0.9030 \n",
            "Epoch 55/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8933 - f1_score: 0.7675 - loss: 0.2517 - precision: 0.8967 - recall: 0.9366 \n",
            "Epoch 56/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8859 - f1_score: 0.7557 - loss: 0.2640 - precision: 0.9070 - recall: 0.9054 \n",
            "Epoch 57/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8920 - f1_score: 0.7666 - loss: 0.2589 - precision: 0.8989 - recall: 0.9308 \n",
            "Epoch 58/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8797 - f1_score: 0.7563 - loss: 0.2785 - precision: 0.9050 - recall: 0.8963 \n",
            "Epoch 59/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8839 - f1_score: 0.7619 - loss: 0.2637 - precision: 0.8953 - recall: 0.9188 \n",
            "Epoch 60/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8829 - f1_score: 0.7574 - loss: 0.2591 - precision: 0.8925 - recall: 0.9185 \n",
            "Epoch 61/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8854 - f1_score: 0.7597 - loss: 0.2550 - precision: 0.8867 - recall: 0.9333 \n",
            "Epoch 62/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8893 - f1_score: 0.7591 - loss: 0.2481 - precision: 0.8971 - recall: 0.9252 \n",
            "Epoch 63/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8890 - f1_score: 0.7591 - loss: 0.2574 - precision: 0.9102 - recall: 0.9084 \n",
            "Epoch 64/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8836 - f1_score: 0.7533 - loss: 0.2610 - precision: 0.8853 - recall: 0.9280 \n",
            "Epoch 65/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8934 - f1_score: 0.7636 - loss: 0.2548 - precision: 0.9006 - recall: 0.9302 \n",
            "Epoch 66/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9046 - f1_score: 0.7614 - loss: 0.2330 - precision: 0.9131 - recall: 0.9337 \n",
            "Epoch 67/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8888 - f1_score: 0.7652 - loss: 0.2423 - precision: 0.8947 - recall: 0.9297 \n",
            "Epoch 68/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8933 - f1_score: 0.7616 - loss: 0.2394 - precision: 0.9164 - recall: 0.9095 \n",
            "Epoch 69/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8912 - f1_score: 0.7676 - loss: 0.2491 - precision: 0.9032 - recall: 0.9243 \n",
            "Epoch 70/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8916 - f1_score: 0.7671 - loss: 0.2415 - precision: 0.9083 - recall: 0.9183 \n",
            "Epoch 71/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9029 - f1_score: 0.7580 - loss: 0.2254 - precision: 0.9128 - recall: 0.9298 \n",
            "Epoch 72/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8968 - f1_score: 0.7583 - loss: 0.2338 - precision: 0.9121 - recall: 0.9202 \n",
            "Epoch 73/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9029 - f1_score: 0.7571 - loss: 0.2205 - precision: 0.9123 - recall: 0.9302 \n",
            "Epoch 74/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9021 - f1_score: 0.7644 - loss: 0.2296 - precision: 0.9196 - recall: 0.9225 \n",
            "Epoch 75/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9079 - f1_score: 0.7515 - loss: 0.2260 - precision: 0.9226 - recall: 0.9241 \n",
            "Epoch 76/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9003 - f1_score: 0.7647 - loss: 0.2268 - precision: 0.9160 - recall: 0.9238 \n",
            "Epoch 77/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8905 - f1_score: 0.7667 - loss: 0.2477 - precision: 0.9046 - recall: 0.9208 \n",
            "Epoch 78/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9068 - f1_score: 0.7571 - loss: 0.2166 - precision: 0.9212 - recall: 0.9263 \n",
            "Epoch 79/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9205 - f1_score: 0.7706 - loss: 0.1988 - precision: 0.9350 - recall: 0.9383 \n",
            "Epoch 80/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9091 - f1_score: 0.7650 - loss: 0.2132 - precision: 0.9166 - recall: 0.9385 \n",
            "Epoch 81/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9131 - f1_score: 0.7668 - loss: 0.2010 - precision: 0.9258 - recall: 0.9352 \n",
            "Epoch 82/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9034 - f1_score: 0.7618 - loss: 0.2253 - precision: 0.9154 - recall: 0.9288 \n",
            "Epoch 83/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9117 - f1_score: 0.7641 - loss: 0.2021 - precision: 0.9229 - recall: 0.9350 \n",
            "Epoch 84/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8919 - f1_score: 0.7603 - loss: 0.2360 - precision: 0.8982 - recall: 0.9298 \n",
            "Epoch 85/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9258 - f1_score: 0.7612 - loss: 0.1897 - precision: 0.9364 - recall: 0.9435 \n",
            "Epoch 86/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9217 - f1_score: 0.7695 - loss: 0.1927 - precision: 0.9344 - recall: 0.9403 \n",
            "Epoch 87/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9230 - f1_score: 0.7697 - loss: 0.1912 - precision: 0.9277 - recall: 0.9511 \n",
            "Epoch 88/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9200 - f1_score: 0.7706 - loss: 0.1861 - precision: 0.9331 - recall: 0.9396 \n",
            "Epoch 89/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9307 - f1_score: 0.7712 - loss: 0.1805 - precision: 0.9371 - recall: 0.9532 \n",
            "Epoch 90/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9151 - f1_score: 0.7561 - loss: 0.1970 - precision: 0.9238 - recall: 0.9378 \n",
            "Epoch 91/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9119 - f1_score: 0.7650 - loss: 0.2006 - precision: 0.9257 - recall: 0.9325 \n",
            "Epoch 92/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9180 - f1_score: 0.7613 - loss: 0.1929 - precision: 0.9357 - recall: 0.9305 \n",
            "Epoch 93/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9130 - f1_score: 0.7701 - loss: 0.2033 - precision: 0.9186 - recall: 0.9445 \n",
            "Epoch 94/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9172 - f1_score: 0.7612 - loss: 0.1953 - precision: 0.9282 - recall: 0.9373 \n",
            "Epoch 95/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9090 - f1_score: 0.7635 - loss: 0.2085 - precision: 0.9190 - recall: 0.9348 \n",
            "Epoch 96/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9199 - f1_score: 0.7597 - loss: 0.1802 - precision: 0.9245 - recall: 0.9466 \n",
            "Epoch 97/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9202 - f1_score: 0.7678 - loss: 0.1843 - precision: 0.9216 - recall: 0.9527 \n",
            "Epoch 98/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9295 - f1_score: 0.7642 - loss: 0.1782 - precision: 0.9429 - recall: 0.9430 \n",
            "Epoch 99/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9236 - f1_score: 0.7553 - loss: 0.1891 - precision: 0.9317 - recall: 0.9429 \n",
            "Epoch 100/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9176 - f1_score: 0.7605 - loss: 0.1840 - precision: 0.9309 - recall: 0.9347 \n",
            "Epoch 101/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9213 - f1_score: 0.7537 - loss: 0.1828 - precision: 0.9294 - recall: 0.9408 \n",
            "Epoch 102/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9218 - f1_score: 0.7539 - loss: 0.1790 - precision: 0.9372 - recall: 0.9327 \n",
            "Epoch 103/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9191 - f1_score: 0.7682 - loss: 0.1931 - precision: 0.9384 - recall: 0.9315 \n",
            "Epoch 104/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9291 - f1_score: 0.7657 - loss: 0.1682 - precision: 0.9443 - recall: 0.9411 \n",
            "Epoch 105/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9209 - f1_score: 0.7715 - loss: 0.1804 - precision: 0.9355 - recall: 0.9386 \n",
            "Epoch 106/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9218 - f1_score: 0.7583 - loss: 0.1709 - precision: 0.9276 - recall: 0.9458 \n",
            "Epoch 107/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9289 - f1_score: 0.7655 - loss: 0.1779 - precision: 0.9324 - recall: 0.9542 \n",
            "Epoch 108/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9304 - f1_score: 0.7636 - loss: 0.1705 - precision: 0.9444 - recall: 0.9425 \n",
            "Epoch 109/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9273 - f1_score: 0.7651 - loss: 0.1710 - precision: 0.9451 - recall: 0.9367 \n",
            "Epoch 110/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9369 - f1_score: 0.7602 - loss: 0.1670 - precision: 0.9490 - recall: 0.9478 \n",
            "Epoch 111/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9315 - f1_score: 0.7611 - loss: 0.1656 - precision: 0.9418 - recall: 0.9469 \n",
            "Epoch 112/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9376 - f1_score: 0.7706 - loss: 0.1630 - precision: 0.9536 - recall: 0.9461 \n",
            "Epoch 113/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9290 - f1_score: 0.7786 - loss: 0.1622 - precision: 0.9469 - recall: 0.9410 \n",
            "Epoch 114/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9200 - f1_score: 0.7690 - loss: 0.1929 - precision: 0.9369 - recall: 0.9342 \n",
            "Epoch 115/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9264 - f1_score: 0.7595 - loss: 0.1623 - precision: 0.9325 - recall: 0.9478 \n",
            "Epoch 116/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9428 - f1_score: 0.7661 - loss: 0.1469 - precision: 0.9518 - recall: 0.9560 \n",
            "Epoch 117/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9156 - f1_score: 0.7595 - loss: 0.1925 - precision: 0.9182 - recall: 0.9468 \n",
            "Epoch 118/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9250 - f1_score: 0.7710 - loss: 0.1657 - precision: 0.9388 - recall: 0.9412 \n",
            "Epoch 119/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9250 - f1_score: 0.7725 - loss: 0.1704 - precision: 0.9406 - recall: 0.9393 \n",
            "Epoch 120/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9311 - f1_score: 0.7542 - loss: 0.1560 - precision: 0.9368 - recall: 0.9496\n",
            "Epoch 121/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9349 - f1_score: 0.7544 - loss: 0.1599 - precision: 0.9505 - recall: 0.9414 \n",
            "Epoch 122/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9130 - f1_score: 0.7646 - loss: 0.2051 - precision: 0.9355 - recall: 0.9222 \n",
            "Epoch 123/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9137 - f1_score: 0.7650 - loss: 0.1857 - precision: 0.9265 - recall: 0.9341 \n",
            "Epoch 124/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9374 - f1_score: 0.7733 - loss: 0.1415 - precision: 0.9493 - recall: 0.9508\n",
            "Epoch 125/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9488 - f1_score: 0.7743 - loss: 0.1373 - precision: 0.9612 - recall: 0.9572 \n",
            "Epoch 126/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9354 - f1_score: 0.7690 - loss: 0.1579 - precision: 0.9482 - recall: 0.9475 \n",
            "Epoch 127/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9406 - f1_score: 0.7705 - loss: 0.1460 - precision: 0.9439 - recall: 0.9615\n",
            "Epoch 128/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9221 - f1_score: 0.7699 - loss: 0.1800 - precision: 0.9437 - recall: 0.9304 \n",
            "Epoch 129/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9327 - f1_score: 0.7769 - loss: 0.1616 - precision: 0.9425 - recall: 0.9513 \n",
            "Epoch 130/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9402 - f1_score: 0.7637 - loss: 0.1494 - precision: 0.9468 - recall: 0.9564\n",
            "Epoch 131/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9397 - f1_score: 0.7682 - loss: 0.1431 - precision: 0.9476 - recall: 0.9554\n",
            "Epoch 132/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9205 - f1_score: 0.7602 - loss: 0.1941 - precision: 0.9355 - recall: 0.9343 \n",
            "Epoch 133/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9457 - f1_score: 0.7582 - loss: 0.1362 - precision: 0.9599 - recall: 0.9500\n",
            "Epoch 134/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9277 - f1_score: 0.7693 - loss: 0.1661 - precision: 0.9389 - recall: 0.9450\n",
            "Epoch 135/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9414 - f1_score: 0.7687 - loss: 0.1460 - precision: 0.9500 - recall: 0.9556 \n",
            "Epoch 136/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9304 - f1_score: 0.7752 - loss: 0.1606 - precision: 0.9385 - recall: 0.9508 \n",
            "Epoch 137/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9341 - f1_score: 0.7780 - loss: 0.1483 - precision: 0.9456 - recall: 0.9496 \n",
            "Epoch 138/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9307 - f1_score: 0.7652 - loss: 0.1608 - precision: 0.9441 - recall: 0.9432 \n",
            "Epoch 139/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9391 - f1_score: 0.7598 - loss: 0.1422 - precision: 0.9419 - recall: 0.9590 \n",
            "Epoch 140/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9336 - f1_score: 0.7666 - loss: 0.1569 - precision: 0.9442 - recall: 0.9482 \n",
            "Epoch 141/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9446 - f1_score: 0.7702 - loss: 0.1370 - precision: 0.9484 - recall: 0.9632 \n",
            "Epoch 142/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9389 - f1_score: 0.7818 - loss: 0.1492 - precision: 0.9507 - recall: 0.9534 \n",
            "Epoch 143/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9361 - f1_score: 0.7658 - loss: 0.1562 - precision: 0.9373 - recall: 0.9605 \n",
            "Epoch 144/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9415 - f1_score: 0.7690 - loss: 0.1440 - precision: 0.9497 - recall: 0.9560 \n",
            "Epoch 145/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9532 - f1_score: 0.7731 - loss: 0.1272 - precision: 0.9613 - recall: 0.9636 \n",
            "Epoch 146/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9204 - f1_score: 0.7562 - loss: 0.1666 - precision: 0.9344 - recall: 0.9333 \n",
            "Epoch 147/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9551 - f1_score: 0.7758 - loss: 0.1186 - precision: 0.9596 - recall: 0.9694 \n",
            "Epoch 148/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9432 - f1_score: 0.7546 - loss: 0.1403 - precision: 0.9532 - recall: 0.9527 \n",
            "Epoch 149/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9434 - f1_score: 0.7684 - loss: 0.1399 - precision: 0.9481 - recall: 0.9614 \n",
            "Epoch 150/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9565 - f1_score: 0.7677 - loss: 0.1212 - precision: 0.9630 - recall: 0.9666 \n",
            "Epoch 151/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9287 - f1_score: 0.7695 - loss: 0.1604 - precision: 0.9369 - recall: 0.9495 \n",
            "Epoch 152/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9409 - f1_score: 0.7747 - loss: 0.1414 - precision: 0.9546 - recall: 0.9508 \n",
            "Epoch 153/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9439 - f1_score: 0.7707 - loss: 0.1347 - precision: 0.9501 - recall: 0.9601 \n",
            "Epoch 154/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9346 - f1_score: 0.7646 - loss: 0.1486 - precision: 0.9479 - recall: 0.9453 \n",
            "Epoch 155/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9516 - f1_score: 0.7734 - loss: 0.1261 - precision: 0.9574 - recall: 0.9650 \n",
            "Epoch 156/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9394 - f1_score: 0.7702 - loss: 0.1349 - precision: 0.9402 - recall: 0.9639 \n",
            "Epoch 157/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9443 - f1_score: 0.7656 - loss: 0.1337 - precision: 0.9585 - recall: 0.9505 \n",
            "Epoch 158/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9482 - f1_score: 0.7735 - loss: 0.1184 - precision: 0.9605 - recall: 0.9567 \n",
            "Epoch 159/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9313 - f1_score: 0.7614 - loss: 0.1512 - precision: 0.9319 - recall: 0.9573 \n",
            "Epoch 160/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9335 - f1_score: 0.7672 - loss: 0.1479 - precision: 0.9433 - recall: 0.9492 \n",
            "Epoch 161/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9526 - f1_score: 0.7696 - loss: 0.1165 - precision: 0.9613 - recall: 0.9618 \n",
            "Epoch 162/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9299 - f1_score: 0.7737 - loss: 0.1609 - precision: 0.9445 - recall: 0.9430 \n",
            "Epoch 163/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9497 - f1_score: 0.7686 - loss: 0.1357 - precision: 0.9588 - recall: 0.9599 \n",
            "Epoch 164/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9478 - f1_score: 0.7630 - loss: 0.1285 - precision: 0.9539 - recall: 0.9609 \n",
            "Epoch 165/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9421 - f1_score: 0.7737 - loss: 0.1370 - precision: 0.9534 - recall: 0.9539 \n",
            "Epoch 166/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9505 - f1_score: 0.7647 - loss: 0.1164 - precision: 0.9522 - recall: 0.9680 \n",
            "Epoch 167/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9423 - f1_score: 0.7683 - loss: 0.1303 - precision: 0.9529 - recall: 0.9537 \n",
            "Epoch 168/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9302 - f1_score: 0.7692 - loss: 0.1695 - precision: 0.9339 - recall: 0.9550 \n",
            "Epoch 169/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9548 - f1_score: 0.7610 - loss: 0.1077 - precision: 0.9687 - recall: 0.9566 \n",
            "Epoch 170/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9376 - f1_score: 0.7682 - loss: 0.1525 - precision: 0.9412 - recall: 0.9597 \n",
            "Epoch 171/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9530 - f1_score: 0.7646 - loss: 0.1123 - precision: 0.9538 - recall: 0.9705 \n",
            "Epoch 172/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9422 - f1_score: 0.7752 - loss: 0.1348 - precision: 0.9579 - recall: 0.9496 \n",
            "Epoch 173/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9415 - f1_score: 0.7688 - loss: 0.1318 - precision: 0.9504 - recall: 0.9548 \n",
            "Epoch 174/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9348 - f1_score: 0.7661 - loss: 0.1423 - precision: 0.9484 - recall: 0.9449 \n",
            "Epoch 175/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9582 - f1_score: 0.7667 - loss: 0.1110 - precision: 0.9637 - recall: 0.9686 \n",
            "Epoch 176/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9424 - f1_score: 0.7700 - loss: 0.1344 - precision: 0.9535 - recall: 0.9533 \n",
            "Epoch 177/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9403 - f1_score: 0.7696 - loss: 0.1448 - precision: 0.9554 - recall: 0.9479 \n",
            "Epoch 178/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9373 - f1_score: 0.7763 - loss: 0.1422 - precision: 0.9554 - recall: 0.9443 \n",
            "Epoch 179/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9514 - f1_score: 0.7704 - loss: 0.1161 - precision: 0.9605 - recall: 0.9611 \n",
            "Epoch 180/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9478 - f1_score: 0.7713 - loss: 0.1269 - precision: 0.9513 - recall: 0.9650 \n",
            "Epoch 181/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9508 - f1_score: 0.7656 - loss: 0.1167 - precision: 0.9584 - recall: 0.9616 \n",
            "Epoch 182/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9506 - f1_score: 0.7710 - loss: 0.1175 - precision: 0.9596 - recall: 0.9607 \n",
            "Epoch 183/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9493 - f1_score: 0.7709 - loss: 0.1225 - precision: 0.9560 - recall: 0.9624 \n",
            "Epoch 184/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9490 - f1_score: 0.7615 - loss: 0.1169 - precision: 0.9566 - recall: 0.9592 \n",
            "Epoch 185/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9575 - f1_score: 0.7681 - loss: 0.1078 - precision: 0.9590 - recall: 0.9724 \n",
            "Epoch 186/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9503 - f1_score: 0.7753 - loss: 0.1237 - precision: 0.9576 - recall: 0.9630 \n",
            "Epoch 187/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9489 - f1_score: 0.7745 - loss: 0.1232 - precision: 0.9534 - recall: 0.9648 \n",
            "Epoch 188/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9571 - f1_score: 0.7811 - loss: 0.1093 - precision: 0.9709 - recall: 0.9610 \n",
            "Epoch 189/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9413 - f1_score: 0.7660 - loss: 0.1329 - precision: 0.9528 - recall: 0.9514 \n",
            "Epoch 190/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9498 - f1_score: 0.7759 - loss: 0.1215 - precision: 0.9550 - recall: 0.9649 \n",
            "Epoch 191/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9352 - f1_score: 0.7757 - loss: 0.1637 - precision: 0.9528 - recall: 0.9433 \n",
            "Epoch 192/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9538 - f1_score: 0.7696 - loss: 0.1101 - precision: 0.9602 - recall: 0.9651 \n",
            "Epoch 193/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9647 - f1_score: 0.7643 - loss: 0.0953 - precision: 0.9718 - recall: 0.9703 \n",
            "Epoch 194/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9472 - f1_score: 0.7661 - loss: 0.1268 - precision: 0.9603 - recall: 0.9532 \n",
            "Epoch 195/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9609 - f1_score: 0.7774 - loss: 0.1056 - precision: 0.9666 - recall: 0.9711 \n",
            "Epoch 196/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9552 - f1_score: 0.7640 - loss: 0.1076 - precision: 0.9602 - recall: 0.9665 \n",
            "Epoch 197/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9598 - f1_score: 0.7654 - loss: 0.1026 - precision: 0.9646 - recall: 0.9696 \n",
            "Epoch 198/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9505 - f1_score: 0.7625 - loss: 0.1147 - precision: 0.9553 - recall: 0.9636 \n",
            "Epoch 199/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9642 - f1_score: 0.7683 - loss: 0.0921 - precision: 0.9749 - recall: 0.9667 \n",
            "Epoch 200/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9547 - f1_score: 0.7644 - loss: 0.1163 - precision: 0.9635 - recall: 0.9623 \n",
            "Epoch 201/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9510 - f1_score: 0.7794 - loss: 0.1271 - precision: 0.9680 - recall: 0.9539 \n",
            "Epoch 202/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9529 - f1_score: 0.7752 - loss: 0.1133 - precision: 0.9601 - recall: 0.9645 \n",
            "Epoch 203/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9654 - f1_score: 0.7681 - loss: 0.0958 - precision: 0.9707 - recall: 0.9730 \n",
            "Epoch 204/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9455 - f1_score: 0.7656 - loss: 0.1347 - precision: 0.9612 - recall: 0.9489 \n",
            "Epoch 205/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9605 - f1_score: 0.7640 - loss: 0.0985 - precision: 0.9660 - recall: 0.9693 \n",
            "Epoch 206/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9378 - f1_score: 0.7602 - loss: 0.1500 - precision: 0.9543 - recall: 0.9415 \n",
            "Epoch 207/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9558 - f1_score: 0.7711 - loss: 0.1156 - precision: 0.9638 - recall: 0.9645 \n",
            "Epoch 208/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9706 - f1_score: 0.7785 - loss: 0.0849 - precision: 0.9757 - recall: 0.9772 \n",
            "Epoch 209/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9430 - f1_score: 0.7698 - loss: 0.1411 - precision: 0.9447 - recall: 0.9638 \n",
            "Epoch 210/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9653 - f1_score: 0.7748 - loss: 0.0938 - precision: 0.9750 - recall: 0.9690 \n",
            "Epoch 211/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9560 - f1_score: 0.7656 - loss: 0.1076 - precision: 0.9613 - recall: 0.9669 \n",
            "Epoch 212/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9514 - f1_score: 0.7688 - loss: 0.1143 - precision: 0.9544 - recall: 0.9674 \n",
            "Epoch 213/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9581 - f1_score: 0.7723 - loss: 0.0938 - precision: 0.9656 - recall: 0.9668 \n",
            "Epoch 214/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9441 - f1_score: 0.7681 - loss: 0.1283 - precision: 0.9567 - recall: 0.9517 \n",
            "Epoch 215/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9550 - f1_score: 0.7740 - loss: 0.1029 - precision: 0.9574 - recall: 0.9706 \n",
            "Epoch 216/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9631 - f1_score: 0.7784 - loss: 0.0886 - precision: 0.9689 - recall: 0.9724 \n",
            "Epoch 217/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9301 - f1_score: 0.7779 - loss: 0.1576 - precision: 0.9412 - recall: 0.9478 \n",
            "Epoch 218/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9613 - f1_score: 0.7762 - loss: 0.0978 - precision: 0.9667 - recall: 0.9711\n",
            "Epoch 219/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9597 - f1_score: 0.7727 - loss: 0.1002 - precision: 0.9729 - recall: 0.9616\n",
            "Epoch 220/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9466 - f1_score: 0.7789 - loss: 0.1200 - precision: 0.9550 - recall: 0.9601\n",
            "Epoch 221/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9546 - f1_score: 0.7620 - loss: 0.1113 - precision: 0.9627 - recall: 0.9619 \n",
            "Epoch 222/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9643 - f1_score: 0.7691 - loss: 0.0923 - precision: 0.9723 - recall: 0.9694\n",
            "Epoch 223/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9681 - f1_score: 0.7791 - loss: 0.0899 - precision: 0.9724 - recall: 0.9768\n",
            "Epoch 224/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9646 - f1_score: 0.7686 - loss: 0.0862 - precision: 0.9737 - recall: 0.9686\n",
            "Epoch 225/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9441 - f1_score: 0.7724 - loss: 0.1182 - precision: 0.9483 - recall: 0.9625\n",
            "Epoch 226/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9473 - f1_score: 0.7763 - loss: 0.1296 - precision: 0.9633 - recall: 0.9513\n",
            "Epoch 227/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9619 - f1_score: 0.7733 - loss: 0.0995 - precision: 0.9703 - recall: 0.9682\n",
            "Epoch 228/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9630 - f1_score: 0.7768 - loss: 0.0955 - precision: 0.9647 - recall: 0.9762\n",
            "Epoch 229/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9467 - f1_score: 0.7613 - loss: 0.1300 - precision: 0.9577 - recall: 0.9538  \n",
            "Epoch 230/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9563 - f1_score: 0.7639 - loss: 0.1064 - precision: 0.9648 - recall: 0.9635\n",
            "Epoch 231/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9632 - f1_score: 0.7748 - loss: 0.1032 - precision: 0.9694 - recall: 0.9712\n",
            "Epoch 232/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9622 - f1_score: 0.7740 - loss: 0.0898 - precision: 0.9691 - recall: 0.9699 \n",
            "Epoch 233/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9540 - f1_score: 0.7707 - loss: 0.1024 - precision: 0.9661 - recall: 0.9591 \n",
            "Epoch 234/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9510 - f1_score: 0.7674 - loss: 0.1076 - precision: 0.9520 - recall: 0.9688 \n",
            "Epoch 235/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9589 - f1_score: 0.7811 - loss: 0.0965 - precision: 0.9690 - recall: 0.9655 \n",
            "Epoch 236/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9510 - f1_score: 0.7716 - loss: 0.1101 - precision: 0.9565 - recall: 0.9641 \n",
            "Epoch 237/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9531 - f1_score: 0.7796 - loss: 0.1277 - precision: 0.9653 - recall: 0.9595 \n",
            "Epoch 238/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9661 - f1_score: 0.7838 - loss: 0.0787 - precision: 0.9756 - recall: 0.9706 \n",
            "Epoch 239/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9678 - f1_score: 0.7759 - loss: 0.0887 - precision: 0.9760 - recall: 0.9722 \n",
            "Epoch 240/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9539 - f1_score: 0.7699 - loss: 0.1089 - precision: 0.9648 - recall: 0.9595 \n",
            "Epoch 241/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9638 - f1_score: 0.7681 - loss: 0.1003 - precision: 0.9715 - recall: 0.9692 \n",
            "Epoch 242/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9572 - f1_score: 0.7727 - loss: 0.0983 - precision: 0.9677 - recall: 0.9628 \n",
            "Epoch 243/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9638 - f1_score: 0.7685 - loss: 0.0858 - precision: 0.9677 - recall: 0.9735 \n",
            "Epoch 244/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9567 - f1_score: 0.7702 - loss: 0.1018 - precision: 0.9734 - recall: 0.9557 \n",
            "Epoch 245/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9596 - f1_score: 0.7793 - loss: 0.0998 - precision: 0.9675 - recall: 0.9679 \n",
            "Epoch 246/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9559 - f1_score: 0.7775 - loss: 0.1062 - precision: 0.9647 - recall: 0.9642 \n",
            "Epoch 247/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9585 - f1_score: 0.7673 - loss: 0.1005 - precision: 0.9707 - recall: 0.9607 \n",
            "Epoch 248/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9533 - f1_score: 0.7733 - loss: 0.1109 - precision: 0.9601 - recall: 0.9649 \n",
            "Epoch 249/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9564 - f1_score: 0.7739 - loss: 0.1027 - precision: 0.9638 - recall: 0.9653 \n",
            "Epoch 250/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9567 - f1_score: 0.7761 - loss: 0.0946 - precision: 0.9637 - recall: 0.9664 \n",
            "Epoch 251/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9587 - f1_score: 0.7641 - loss: 0.0939 - precision: 0.9630 - recall: 0.9690 \n",
            "Epoch 252/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7670 - loss: 0.0861 - precision: 0.9687 - recall: 0.9712 \n",
            "Epoch 253/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9618 - f1_score: 0.7729 - loss: 0.0871 - precision: 0.9657 - recall: 0.9728 \n",
            "Epoch 254/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9589 - f1_score: 0.7688 - loss: 0.1108 - precision: 0.9718 - recall: 0.9606 \n",
            "Epoch 255/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9612 - f1_score: 0.7720 - loss: 0.0998 - precision: 0.9672 - recall: 0.9698 \n",
            "Epoch 256/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9654 - f1_score: 0.7819 - loss: 0.0916 - precision: 0.9736 - recall: 0.9712 \n",
            "Epoch 257/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9721 - f1_score: 0.7754 - loss: 0.0834 - precision: 0.9798 - recall: 0.9751 \n",
            "Epoch 258/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9565 - f1_score: 0.7728 - loss: 0.1055 - precision: 0.9707 - recall: 0.9583 \n",
            "Epoch 259/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9553 - f1_score: 0.7836 - loss: 0.1051 - precision: 0.9562 - recall: 0.9735 \n",
            "Epoch 260/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9683 - f1_score: 0.7752 - loss: 0.0826 - precision: 0.9763 - recall: 0.9725 \n",
            "Epoch 261/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9594 - f1_score: 0.7736 - loss: 0.0847 - precision: 0.9676 - recall: 0.9667 \n",
            "Epoch 262/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9632 - f1_score: 0.7787 - loss: 0.0950 - precision: 0.9701 - recall: 0.9710 \n",
            "Epoch 263/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9571 - f1_score: 0.7791 - loss: 0.1068 - precision: 0.9680 - recall: 0.9626 \n",
            "Epoch 264/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9598 - f1_score: 0.7776 - loss: 0.0898 - precision: 0.9700 - recall: 0.9652 \n",
            "Epoch 265/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9598 - f1_score: 0.7692 - loss: 0.1043 - precision: 0.9591 - recall: 0.9761 \n",
            "Epoch 266/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9619 - f1_score: 0.7760 - loss: 0.0854 - precision: 0.9655 - recall: 0.9730 \n",
            "Epoch 267/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9581 - f1_score: 0.7742 - loss: 0.1048 - precision: 0.9693 - recall: 0.9627 \n",
            "Epoch 268/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9711 - f1_score: 0.7796 - loss: 0.0792 - precision: 0.9811 - recall: 0.9722 \n",
            "Epoch 269/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9591 - f1_score: 0.7680 - loss: 0.0977 - precision: 0.9658 - recall: 0.9671 \n",
            "Epoch 270/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9674 - f1_score: 0.7658 - loss: 0.0834 - precision: 0.9716 - recall: 0.9748 \n",
            "Epoch 271/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9686 - f1_score: 0.7777 - loss: 0.0823 - precision: 0.9741 - recall: 0.9755 \n",
            "Epoch 272/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9745 - f1_score: 0.7739 - loss: 0.0753 - precision: 0.9823 - recall: 0.9762 \n",
            "Epoch 273/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9613 - f1_score: 0.7722 - loss: 0.0966 - precision: 0.9666 - recall: 0.9705 \n",
            "Epoch 274/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9682 - f1_score: 0.7860 - loss: 0.0904 - precision: 0.9750 - recall: 0.9747 \n",
            "Epoch 275/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9660 - f1_score: 0.7698 - loss: 0.0881 - precision: 0.9742 - recall: 0.9696 \n",
            "Epoch 276/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7674 - loss: 0.0727 - precision: 0.9773 - recall: 0.9762 \n",
            "Epoch 277/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9598 - f1_score: 0.7830 - loss: 0.0993 - precision: 0.9662 - recall: 0.9702 \n",
            "Epoch 278/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7814 - loss: 0.0907 - precision: 0.9724 - recall: 0.9688 \n",
            "Epoch 279/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9602 - f1_score: 0.7751 - loss: 0.0914 - precision: 0.9669 - recall: 0.9686 \n",
            "Epoch 280/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9605 - f1_score: 0.7733 - loss: 0.0902 - precision: 0.9770 - recall: 0.9582 \n",
            "Epoch 281/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9710 - f1_score: 0.7766 - loss: 0.0821 - precision: 0.9793 - recall: 0.9737 \n",
            "Epoch 282/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9557 - f1_score: 0.7734 - loss: 0.1122 - precision: 0.9690 - recall: 0.9584 \n",
            "Epoch 283/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9759 - f1_score: 0.7666 - loss: 0.0633 - precision: 0.9780 - recall: 0.9823 \n",
            "Epoch 284/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9717 - f1_score: 0.7690 - loss: 0.0789 - precision: 0.9795 - recall: 0.9739 \n",
            "Epoch 285/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9632 - f1_score: 0.7783 - loss: 0.0922 - precision: 0.9625 - recall: 0.9788 \n",
            "Epoch 286/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9703 - f1_score: 0.7832 - loss: 0.0867 - precision: 0.9781 - recall: 0.9744 \n",
            "Epoch 287/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9668 - f1_score: 0.7706 - loss: 0.0794 - precision: 0.9768 - recall: 0.9689 \n",
            "Epoch 288/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9751 - f1_score: 0.7657 - loss: 0.0680 - precision: 0.9813 - recall: 0.9773 \n",
            "Epoch 289/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9624 - f1_score: 0.7720 - loss: 0.0865 - precision: 0.9756 - recall: 0.9629 \n",
            "Epoch 290/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9654 - f1_score: 0.7674 - loss: 0.0829 - precision: 0.9705 - recall: 0.9728 \n",
            "Epoch 291/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9711 - f1_score: 0.7725 - loss: 0.0796 - precision: 0.9787 - recall: 0.9741 \n",
            "Epoch 292/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9588 - f1_score: 0.7785 - loss: 0.1085 - precision: 0.9614 - recall: 0.9727 \n",
            "Epoch 293/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9684 - f1_score: 0.7775 - loss: 0.0733 - precision: 0.9774 - recall: 0.9714 \n",
            "Epoch 294/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9776 - f1_score: 0.7774 - loss: 0.0601 - precision: 0.9850 - recall: 0.9788 \n",
            "Epoch 295/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9525 - f1_score: 0.7770 - loss: 0.1160 - precision: 0.9619 - recall: 0.9616 \n",
            "Epoch 296/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9618 - f1_score: 0.7785 - loss: 0.0884 - precision: 0.9713 - recall: 0.9668 \n",
            "Epoch 297/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9699 - f1_score: 0.7732 - loss: 0.0662 - precision: 0.9693 - recall: 0.9820 \n",
            "Epoch 298/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9680 - f1_score: 0.7776 - loss: 0.0836 - precision: 0.9716 - recall: 0.9766 \n",
            "Epoch 299/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9574 - f1_score: 0.7786 - loss: 0.0992 - precision: 0.9588 - recall: 0.9728 \n",
            "Epoch 300/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9627 - f1_score: 0.7757 - loss: 0.0879 - precision: 0.9707 - recall: 0.9682 \n",
            "Epoch 301/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9671 - f1_score: 0.7714 - loss: 0.0778 - precision: 0.9713 - recall: 0.9748 \n",
            "Epoch 302/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9622 - f1_score: 0.7733 - loss: 0.0936 - precision: 0.9764 - recall: 0.9615 \n",
            "Epoch 303/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9716 - f1_score: 0.7804 - loss: 0.0769 - precision: 0.9742 - recall: 0.9803 \n",
            "Epoch 304/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9581 - f1_score: 0.7829 - loss: 0.1011 - precision: 0.9638 - recall: 0.9696 \n",
            "Epoch 305/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9635 - f1_score: 0.7714 - loss: 0.0901 - precision: 0.9705 - recall: 0.9695 \n",
            "Epoch 306/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.7765 - loss: 0.0699 - precision: 0.9791 - recall: 0.9777 \n",
            "Epoch 307/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9707 - f1_score: 0.7776 - loss: 0.0699 - precision: 0.9788 - recall: 0.9735 \n",
            "Epoch 308/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9604 - f1_score: 0.7756 - loss: 0.0953 - precision: 0.9706 - recall: 0.9649 \n",
            "Epoch 309/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9725 - f1_score: 0.7807 - loss: 0.0738 - precision: 0.9786 - recall: 0.9772 \n",
            "Epoch 310/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9706 - f1_score: 0.7825 - loss: 0.0759 - precision: 0.9786 - recall: 0.9741 \n",
            "Epoch 311/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9761 - f1_score: 0.7860 - loss: 0.0676 - precision: 0.9821 - recall: 0.9799 \n",
            "Epoch 312/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9570 - f1_score: 0.7846 - loss: 0.0955 - precision: 0.9678 - recall: 0.9633 \n",
            "Epoch 313/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9731 - f1_score: 0.7770 - loss: 0.0780 - precision: 0.9739 - recall: 0.9830 \n",
            "Epoch 314/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9746 - f1_score: 0.7764 - loss: 0.0700 - precision: 0.9800 - recall: 0.9787 \n",
            "Epoch 315/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9677 - f1_score: 0.7762 - loss: 0.0708 - precision: 0.9738 - recall: 0.9736 \n",
            "Epoch 316/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9691 - f1_score: 0.7706 - loss: 0.0760 - precision: 0.9682 - recall: 0.9816 \n",
            "Epoch 317/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9710 - f1_score: 0.7754 - loss: 0.0729 - precision: 0.9775 - recall: 0.9750 \n",
            "Epoch 318/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9702 - f1_score: 0.7786 - loss: 0.0770 - precision: 0.9792 - recall: 0.9724 \n",
            "Epoch 319/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9694 - f1_score: 0.7880 - loss: 0.0732 - precision: 0.9757 - recall: 0.9758\n",
            "Epoch 320/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9624 - f1_score: 0.7766 - loss: 0.0971 - precision: 0.9668 - recall: 0.9720\n",
            "Epoch 321/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9742 - f1_score: 0.7770 - loss: 0.0671 - precision: 0.9774 - recall: 0.9807\n",
            "Epoch 322/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9708 - f1_score: 0.7773 - loss: 0.0796 - precision: 0.9747 - recall: 0.9779\n",
            "Epoch 323/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9744 - f1_score: 0.7748 - loss: 0.0644 - precision: 0.9773 - recall: 0.9809\n",
            "Epoch 324/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9722 - f1_score: 0.7752 - loss: 0.0683 - precision: 0.9777 - recall: 0.9771\n",
            "Epoch 325/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9592 - f1_score: 0.7833 - loss: 0.0975 - precision: 0.9600 - recall: 0.9758\n",
            "Epoch 326/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9717 - f1_score: 0.7769 - loss: 0.0710 - precision: 0.9760 - recall: 0.9780\n",
            "Epoch 327/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9711 - f1_score: 0.7773 - loss: 0.0722 - precision: 0.9735 - recall: 0.9798\n",
            "Epoch 328/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9675 - f1_score: 0.7853 - loss: 0.0747 - precision: 0.9706 - recall: 0.9776 \n",
            "Epoch 329/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9802 - f1_score: 0.7714 - loss: 0.0550 - precision: 0.9837 - recall: 0.9839\n",
            "Epoch 330/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9645 - f1_score: 0.7826 - loss: 0.0953 - precision: 0.9760 - recall: 0.9666  \n",
            "Epoch 331/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9694 - f1_score: 0.7824 - loss: 0.0762 - precision: 0.9718 - recall: 0.9789 \n",
            "Epoch 332/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9740 - f1_score: 0.7794 - loss: 0.0694 - precision: 0.9795 - recall: 0.9784 \n",
            "Epoch 333/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9673 - f1_score: 0.7837 - loss: 0.0811 - precision: 0.9731 - recall: 0.9743 \n",
            "Epoch 334/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9660 - f1_score: 0.7880 - loss: 0.0775 - precision: 0.9717 - recall: 0.9742 \n",
            "Epoch 335/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9741 - f1_score: 0.7773 - loss: 0.0672 - precision: 0.9804 - recall: 0.9773 \n",
            "Epoch 336/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9504 - f1_score: 0.7858 - loss: 0.1160 - precision: 0.9553 - recall: 0.9663 \n",
            "Epoch 337/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.7799 - loss: 0.0529 - precision: 0.9875 - recall: 0.9802 \n",
            "Epoch 338/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9595 - f1_score: 0.7749 - loss: 0.0881 - precision: 0.9673 - recall: 0.9659 \n",
            "Epoch 339/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7743 - loss: 0.0691 - precision: 0.9841 - recall: 0.9692 \n",
            "Epoch 340/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9718 - f1_score: 0.7805 - loss: 0.0690 - precision: 0.9747 - recall: 0.9799 \n",
            "Epoch 341/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9719 - f1_score: 0.7845 - loss: 0.0714 - precision: 0.9768 - recall: 0.9781 \n",
            "Epoch 342/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9705 - f1_score: 0.7866 - loss: 0.0742 - precision: 0.9770 - recall: 0.9756 \n",
            "Epoch 343/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9769 - f1_score: 0.7883 - loss: 0.0582 - precision: 0.9875 - recall: 0.9756 \n",
            "Epoch 344/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9608 - f1_score: 0.7850 - loss: 0.1027 - precision: 0.9721 - recall: 0.9646\n",
            "Epoch 345/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9768 - f1_score: 0.7841 - loss: 0.0590 - precision: 0.9841 - recall: 0.9785 \n",
            "Epoch 346/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9703 - f1_score: 0.7812 - loss: 0.0685 - precision: 0.9777 - recall: 0.9738 \n",
            "Epoch 347/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9696 - f1_score: 0.7803 - loss: 0.0761 - precision: 0.9749 - recall: 0.9755 \n",
            "Epoch 348/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9722 - f1_score: 0.7836 - loss: 0.0692 - precision: 0.9811 - recall: 0.9741 \n",
            "Epoch 349/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.7743 - loss: 0.0742 - precision: 0.9814 - recall: 0.9691 \n",
            "Epoch 350/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.7883 - loss: 0.0845 - precision: 0.9772 - recall: 0.9734 \n",
            "Epoch 351/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9708 - f1_score: 0.7950 - loss: 0.0795 - precision: 0.9783 - recall: 0.9756 \n",
            "Epoch 352/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9726 - f1_score: 0.7683 - loss: 0.0617 - precision: 0.9736 - recall: 0.9812 \n",
            "Epoch 353/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7864 - loss: 0.0575 - precision: 0.9835 - recall: 0.9834 \n",
            "Epoch 354/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9781 - f1_score: 0.7811 - loss: 0.0659 - precision: 0.9868 - recall: 0.9777 \n",
            "Epoch 355/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9673 - f1_score: 0.7837 - loss: 0.0754 - precision: 0.9717 - recall: 0.9759 \n",
            "Epoch 356/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9722 - f1_score: 0.7881 - loss: 0.0745 - precision: 0.9809 - recall: 0.9745 \n",
            "Epoch 357/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9759 - f1_score: 0.7848 - loss: 0.0623 - precision: 0.9801 - recall: 0.9812 \n",
            "Epoch 358/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9708 - f1_score: 0.7872 - loss: 0.0771 - precision: 0.9799 - recall: 0.9731 \n",
            "Epoch 359/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9681 - f1_score: 0.7888 - loss: 0.0738 - precision: 0.9751 - recall: 0.9739 \n",
            "Epoch 360/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9700 - f1_score: 0.7802 - loss: 0.0652 - precision: 0.9771 - recall: 0.9740 \n",
            "Epoch 361/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9635 - f1_score: 0.7824 - loss: 0.0839 - precision: 0.9645 - recall: 0.9767 \n",
            "Epoch 362/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9754 - f1_score: 0.7842 - loss: 0.0667 - precision: 0.9790 - recall: 0.9814 \n",
            "Epoch 363/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9759 - f1_score: 0.7747 - loss: 0.0706 - precision: 0.9831 - recall: 0.9775 \n",
            "Epoch 364/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9740 - f1_score: 0.7885 - loss: 0.0638 - precision: 0.9773 - recall: 0.9817 \n",
            "Epoch 365/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9697 - f1_score: 0.7838 - loss: 0.0791 - precision: 0.9701 - recall: 0.9813 \n",
            "Epoch 366/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9636 - f1_score: 0.7855 - loss: 0.0910 - precision: 0.9616 - recall: 0.9813 \n",
            "Epoch 367/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9757 - f1_score: 0.7841 - loss: 0.0714 - precision: 0.9811 - recall: 0.9792 \n",
            "Epoch 368/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9764 - f1_score: 0.7788 - loss: 0.0621 - precision: 0.9798 - recall: 0.9819\n",
            "Epoch 369/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9799 - f1_score: 0.7751 - loss: 0.0547 - precision: 0.9829 - recall: 0.9839 \n",
            "Epoch 370/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9730 - f1_score: 0.7750 - loss: 0.0729 - precision: 0.9780 - recall: 0.9777 \n",
            "Epoch 371/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9608 - f1_score: 0.7857 - loss: 0.0969 - precision: 0.9650 - recall: 0.9722 \n",
            "Epoch 372/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9611 - f1_score: 0.7944 - loss: 0.0791 - precision: 0.9713 - recall: 0.9669 \n",
            "Epoch 373/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9692 - f1_score: 0.7841 - loss: 0.0695 - precision: 0.9782 - recall: 0.9724 \n",
            "Epoch 374/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9780 - f1_score: 0.7719 - loss: 0.0613 - precision: 0.9806 - recall: 0.9832 \n",
            "Epoch 375/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9717 - f1_score: 0.7755 - loss: 0.0669 - precision: 0.9803 - recall: 0.9729 \n",
            "Epoch 376/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9725 - f1_score: 0.7859 - loss: 0.0776 - precision: 0.9752 - recall: 0.9808 \n",
            "Epoch 377/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9696 - f1_score: 0.7766 - loss: 0.0752 - precision: 0.9704 - recall: 0.9800 \n",
            "Epoch 378/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9719 - f1_score: 0.7793 - loss: 0.0725 - precision: 0.9785 - recall: 0.9756 \n",
            "Epoch 379/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9722 - f1_score: 0.7896 - loss: 0.0676 - precision: 0.9854 - recall: 0.9700 \n",
            "Epoch 380/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9592 - f1_score: 0.7759 - loss: 0.0924 - precision: 0.9684 - recall: 0.9643 \n",
            "Epoch 381/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9650 - f1_score: 0.7750 - loss: 0.0751 - precision: 0.9679 - recall: 0.9746 \n",
            "Epoch 382/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9657 - f1_score: 0.7767 - loss: 0.0833 - precision: 0.9624 - recall: 0.9818 \n",
            "Epoch 383/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9772 - f1_score: 0.7891 - loss: 0.0577 - precision: 0.9833 - recall: 0.9798 \n",
            "Epoch 384/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9775 - f1_score: 0.7837 - loss: 0.0626 - precision: 0.9806 - recall: 0.9832 \n",
            "Epoch 385/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9762 - f1_score: 0.7779 - loss: 0.0635 - precision: 0.9814 - recall: 0.9793 \n",
            "Epoch 386/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9776 - f1_score: 0.7803 - loss: 0.0580 - precision: 0.9807 - recall: 0.9827 \n",
            "Epoch 387/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9732 - f1_score: 0.7765 - loss: 0.0632 - precision: 0.9813 - recall: 0.9744 \n",
            "Epoch 388/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9730 - f1_score: 0.7836 - loss: 0.0703 - precision: 0.9780 - recall: 0.9786 \n",
            "Epoch 389/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9694 - f1_score: 0.7810 - loss: 0.0826 - precision: 0.9714 - recall: 0.9788 \n",
            "Epoch 390/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9786 - f1_score: 0.7850 - loss: 0.0519 - precision: 0.9781 - recall: 0.9876 \n",
            "Epoch 391/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9797 - f1_score: 0.7868 - loss: 0.0548 - precision: 0.9811 - recall: 0.9865 \n",
            "Epoch 392/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9635 - f1_score: 0.7834 - loss: 0.0880 - precision: 0.9749 - recall: 0.9663 \n",
            "Epoch 393/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9710 - f1_score: 0.7762 - loss: 0.0622 - precision: 0.9746 - recall: 0.9778 \n",
            "Epoch 394/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9748 - f1_score: 0.7812 - loss: 0.0599 - precision: 0.9827 - recall: 0.9763 \n",
            "Epoch 395/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9766 - f1_score: 0.7756 - loss: 0.0600 - precision: 0.9832 - recall: 0.9781 \n",
            "Epoch 396/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9775 - f1_score: 0.7834 - loss: 0.0590 - precision: 0.9839 - recall: 0.9795 \n",
            "Epoch 397/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9628 - f1_score: 0.7848 - loss: 0.0874 - precision: 0.9768 - recall: 0.9630 \n",
            "Epoch 398/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9807 - f1_score: 0.7899 - loss: 0.0598 - precision: 0.9827 - recall: 0.9866 \n",
            "Epoch 399/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.7775 - loss: 0.0492 - precision: 0.9886 - recall: 0.9836 \n",
            "Epoch 400/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9763 - f1_score: 0.7835 - loss: 0.0614 - precision: 0.9815 - recall: 0.9799 \n",
            "Epoch 401/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9718 - f1_score: 0.7904 - loss: 0.0681 - precision: 0.9724 - recall: 0.9830 \n",
            "Epoch 402/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9776 - f1_score: 0.7760 - loss: 0.0545 - precision: 0.9794 - recall: 0.9835 \n",
            "Epoch 403/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.7800 - loss: 0.0537 - precision: 0.9811 - recall: 0.9858 \n",
            "Epoch 404/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9627 - f1_score: 0.7791 - loss: 0.0913 - precision: 0.9703 - recall: 0.9684 \n",
            "Epoch 405/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9791 - f1_score: 0.7968 - loss: 0.0546 - precision: 0.9837 - recall: 0.9828 \n",
            "Epoch 406/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9698 - f1_score: 0.7804 - loss: 0.0769 - precision: 0.9744 - recall: 0.9763 \n",
            "Epoch 407/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.7820 - loss: 0.0506 - precision: 0.9838 - recall: 0.9807 \n",
            "Epoch 408/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9844 - f1_score: 0.7827 - loss: 0.0435 - precision: 0.9864 - recall: 0.9884 \n",
            "Epoch 409/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9627 - f1_score: 0.7895 - loss: 0.1008 - precision: 0.9677 - recall: 0.9722 \n",
            "Epoch 410/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9786 - f1_score: 0.7817 - loss: 0.0568 - precision: 0.9836 - recall: 0.9815 \n",
            "Epoch 411/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9767 - f1_score: 0.7777 - loss: 0.0591 - precision: 0.9825 - recall: 0.9791\n",
            "Epoch 412/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9800 - f1_score: 0.7759 - loss: 0.0675 - precision: 0.9843 - recall: 0.9825\n",
            "Epoch 413/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9761 - f1_score: 0.7815 - loss: 0.0598 - precision: 0.9757 - recall: 0.9854\n",
            "Epoch 414/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9784 - f1_score: 0.7597 - loss: 0.0513 - precision: 0.9795 - recall: 0.9838\n",
            "Epoch 415/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9819 - f1_score: 0.7929 - loss: 0.0480 - precision: 0.9843 - recall: 0.9867\n",
            "Epoch 416/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9782 - f1_score: 0.7871 - loss: 0.0579 - precision: 0.9844 - recall: 0.9804\n",
            "Epoch 417/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9717 - f1_score: 0.7863 - loss: 0.0653 - precision: 0.9815 - recall: 0.9723\n",
            "Epoch 418/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9725 - f1_score: 0.7825 - loss: 0.0702 - precision: 0.9777 - recall: 0.9775\n",
            "Epoch 419/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9742 - f1_score: 0.7845 - loss: 0.0675 - precision: 0.9774 - recall: 0.9803\n",
            "Epoch 420/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9867 - f1_score: 0.7862 - loss: 0.0411 - precision: 0.9901 - recall: 0.9882\n",
            "Epoch 421/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9759 - f1_score: 0.7834 - loss: 0.0686 - precision: 0.9825 - recall: 0.9782\n",
            "Epoch 422/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9744 - f1_score: 0.7775 - loss: 0.0590 - precision: 0.9830 - recall: 0.9743\n",
            "Epoch 423/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9711 - f1_score: 0.7792 - loss: 0.0713 - precision: 0.9778 - recall: 0.9745  \n",
            "Epoch 424/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9836 - f1_score: 0.7836 - loss: 0.0506 - precision: 0.9872 - recall: 0.9860 \n",
            "Epoch 425/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9778 - f1_score: 0.7844 - loss: 0.0584 - precision: 0.9830 - recall: 0.9808 \n",
            "Epoch 426/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9748 - f1_score: 0.7848 - loss: 0.0632 - precision: 0.9790 - recall: 0.9799 \n",
            "Epoch 427/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.7824 - loss: 0.0435 - precision: 0.9902 - recall: 0.9872 \n",
            "Epoch 428/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9749 - f1_score: 0.7859 - loss: 0.0609 - precision: 0.9834 - recall: 0.9757 \n",
            "Epoch 429/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9808 - f1_score: 0.7801 - loss: 0.0525 - precision: 0.9844 - recall: 0.9839 \n",
            "Epoch 430/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.7998 - loss: 0.0401 - precision: 0.9926 - recall: 0.9836 \n",
            "Epoch 431/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9658 - f1_score: 0.7801 - loss: 0.0832 - precision: 0.9707 - recall: 0.9733 \n",
            "Epoch 432/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9837 - f1_score: 0.7727 - loss: 0.0427 - precision: 0.9854 - recall: 0.9874 \n",
            "Epoch 433/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9704 - f1_score: 0.7886 - loss: 0.0691 - precision: 0.9754 - recall: 0.9767 \n",
            "Epoch 434/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9697 - f1_score: 0.7864 - loss: 0.0733 - precision: 0.9713 - recall: 0.9800 \n",
            "Epoch 435/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9781 - f1_score: 0.7786 - loss: 0.0589 - precision: 0.9825 - recall: 0.9814 \n",
            "Epoch 436/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9799 - f1_score: 0.7944 - loss: 0.0507 - precision: 0.9831 - recall: 0.9849 \n",
            "Epoch 437/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9760 - f1_score: 0.7816 - loss: 0.0569 - precision: 0.9795 - recall: 0.9809 \n",
            "Epoch 438/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9656 - f1_score: 0.7848 - loss: 0.0822 - precision: 0.9783 - recall: 0.9645 \n",
            "Epoch 439/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.7886 - loss: 0.0492 - precision: 0.9908 - recall: 0.9827 \n",
            "Epoch 440/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9716 - f1_score: 0.7938 - loss: 0.0601 - precision: 0.9728 - recall: 0.9825 \n",
            "Epoch 441/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9799 - f1_score: 0.7896 - loss: 0.0454 - precision: 0.9819 - recall: 0.9854 \n",
            "Epoch 442/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.7802 - loss: 0.0624 - precision: 0.9744 - recall: 0.9764 \n",
            "Epoch 443/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.7904 - loss: 0.0494 - precision: 0.9848 - recall: 0.9882 \n",
            "Epoch 444/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9701 - f1_score: 0.7861 - loss: 0.0724 - precision: 0.9758 - recall: 0.9754 \n",
            "Epoch 445/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9865 - f1_score: 0.7956 - loss: 0.0379 - precision: 0.9864 - recall: 0.9920 \n",
            "Epoch 446/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9739 - f1_score: 0.7920 - loss: 0.0596 - precision: 0.9801 - recall: 0.9777 \n",
            "Epoch 447/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9750 - f1_score: 0.7944 - loss: 0.0750 - precision: 0.9823 - recall: 0.9769 \n",
            "Epoch 448/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9791 - f1_score: 0.7853 - loss: 0.0542 - precision: 0.9779 - recall: 0.9879 \n",
            "Epoch 449/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7917 - loss: 0.0491 - precision: 0.9806 - recall: 0.9863 \n",
            "Epoch 450/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9743 - f1_score: 0.7929 - loss: 0.0651 - precision: 0.9796 - recall: 0.9793 \n",
            "Epoch 451/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9761 - f1_score: 0.7932 - loss: 0.0572 - precision: 0.9854 - recall: 0.9759 \n",
            "Epoch 452/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9745 - f1_score: 0.7911 - loss: 0.0692 - precision: 0.9799 - recall: 0.9790 \n",
            "Epoch 453/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9839 - f1_score: 0.7929 - loss: 0.0437 - precision: 0.9889 - recall: 0.9851 \n",
            "Epoch 454/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9807 - f1_score: 0.7956 - loss: 0.0492 - precision: 0.9835 - recall: 0.9855 \n",
            "Epoch 455/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9682 - f1_score: 0.7851 - loss: 0.0790 - precision: 0.9745 - recall: 0.9736 \n",
            "Epoch 456/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9861 - f1_score: 0.7898 - loss: 0.0418 - precision: 0.9909 - recall: 0.9864 \n",
            "Epoch 457/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9652 - f1_score: 0.7861 - loss: 0.0946 - precision: 0.9750 - recall: 0.9670 \n",
            "Epoch 458/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9823 - f1_score: 0.8027 - loss: 0.0435 - precision: 0.9821 - recall: 0.9900 \n",
            "Epoch 459/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9689 - f1_score: 0.7866 - loss: 0.0776 - precision: 0.9767 - recall: 0.9725 \n",
            "Epoch 460/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9730 - f1_score: 0.7860 - loss: 0.0749 - precision: 0.9830 - recall: 0.9729 \n",
            "Epoch 461/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9721 - f1_score: 0.8051 - loss: 0.0661 - precision: 0.9791 - recall: 0.9767 \n",
            "Epoch 462/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9826 - f1_score: 0.7914 - loss: 0.0459 - precision: 0.9885 - recall: 0.9836 \n",
            "Epoch 463/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.7957 - loss: 0.0381 - precision: 0.9871 - recall: 0.9883 \n",
            "Epoch 464/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9727 - f1_score: 0.7963 - loss: 0.0709 - precision: 0.9779 - recall: 0.9786 \n",
            "Epoch 465/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9793 - f1_score: 0.7915 - loss: 0.0562 - precision: 0.9813 - recall: 0.9851 \n",
            "Epoch 466/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9781 - f1_score: 0.7903 - loss: 0.0573 - precision: 0.9816 - recall: 0.9827 \n",
            "Epoch 467/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.7977 - loss: 0.0399 - precision: 0.9903 - recall: 0.9864 \n",
            "Epoch 468/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9715 - f1_score: 0.7812 - loss: 0.0708 - precision: 0.9779 - recall: 0.9752 \n",
            "Epoch 469/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.7924 - loss: 0.0707 - precision: 0.9844 - recall: 0.9794 \n",
            "Epoch 470/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9873 - f1_score: 0.7972 - loss: 0.0388 - precision: 0.9887 - recall: 0.9910 \n",
            "Epoch 471/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9841 - f1_score: 0.7861 - loss: 0.0447 - precision: 0.9837 - recall: 0.9904 \n",
            "Epoch 472/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.7972 - loss: 0.0436 - precision: 0.9860 - recall: 0.9872 \n",
            "Epoch 473/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7792 - loss: 0.0483 - precision: 0.9814 - recall: 0.9848 \n",
            "Epoch 474/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9713 - f1_score: 0.7934 - loss: 0.0723 - precision: 0.9777 - recall: 0.9759 \n",
            "Epoch 475/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.7993 - loss: 0.0578 - precision: 0.9916 - recall: 0.9795 \n",
            "Epoch 476/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9817 - f1_score: 0.7898 - loss: 0.0508 - precision: 0.9877 - recall: 0.9822 \n",
            "Epoch 477/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9824 - f1_score: 0.7920 - loss: 0.0467 - precision: 0.9855 - recall: 0.9861 \n",
            "Epoch 478/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9771 - f1_score: 0.7933 - loss: 0.0509 - precision: 0.9836 - recall: 0.9796 \n",
            "Epoch 479/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9751 - f1_score: 0.7891 - loss: 0.0554 - precision: 0.9783 - recall: 0.9816 \n",
            "Epoch 480/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9682 - f1_score: 0.7866 - loss: 0.0906 - precision: 0.9748 - recall: 0.9730 \n",
            "Epoch 481/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9880 - f1_score: 0.7872 - loss: 0.0369 - precision: 0.9932 - recall: 0.9872 \n",
            "Epoch 482/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9798 - f1_score: 0.8007 - loss: 0.0481 - precision: 0.9822 - recall: 0.9857 \n",
            "Epoch 483/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9719 - f1_score: 0.7973 - loss: 0.0615 - precision: 0.9812 - recall: 0.9736 \n",
            "Epoch 484/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9784 - f1_score: 0.7908 - loss: 0.0522 - precision: 0.9850 - recall: 0.9799 \n",
            "Epoch 485/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9732 - f1_score: 0.7922 - loss: 0.0630 - precision: 0.9832 - recall: 0.9733 \n",
            "Epoch 486/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7883 - loss: 0.0572 - precision: 0.9844 - recall: 0.9823 \n",
            "Epoch 487/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9800 - f1_score: 0.7880 - loss: 0.0492 - precision: 0.9797 - recall: 0.9881 \n",
            "Epoch 488/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9768 - f1_score: 0.7924 - loss: 0.0588 - precision: 0.9822 - recall: 0.9799 \n",
            "Epoch 489/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7978 - loss: 0.0496 - precision: 0.9844 - recall: 0.9827 \n",
            "Epoch 490/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.7940 - loss: 0.0557 - precision: 0.9854 - recall: 0.9788 \n",
            "Epoch 491/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9688 - f1_score: 0.7911 - loss: 0.0983 - precision: 0.9747 - recall: 0.9743 \n",
            "Epoch 492/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8021 - loss: 0.0338 - precision: 0.9916 - recall: 0.9897 \n",
            "Epoch 493/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9724 - f1_score: 0.7936 - loss: 0.0621 - precision: 0.9793 - recall: 0.9761 \n",
            "Epoch 494/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.7856 - loss: 0.0395 - precision: 0.9873 - recall: 0.9894 \n",
            "Epoch 495/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9728 - f1_score: 0.7907 - loss: 0.0685 - precision: 0.9791 - recall: 0.9763 \n",
            "Epoch 496/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.7956 - loss: 0.0421 - precision: 0.9885 - recall: 0.9878 \n",
            "Epoch 497/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9854 - f1_score: 0.7995 - loss: 0.0454 - precision: 0.9879 - recall: 0.9886 \n",
            "Epoch 498/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.7953 - loss: 0.0439 - precision: 0.9897 - recall: 0.9879 \n",
            "Epoch 499/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9724 - f1_score: 0.7964 - loss: 0.1016 - precision: 0.9771 - recall: 0.9782 \n",
            "Epoch 500/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9767 - f1_score: 0.8048 - loss: 0.0568 - precision: 0.9916 - recall: 0.9714 \n",
            "Epoch 501/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.7954 - loss: 0.0425 - precision: 0.9907 - recall: 0.9864 \n",
            "Epoch 502/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.7875 - loss: 0.0552 - precision: 0.9812 - recall: 0.9835 \n",
            "Epoch 503/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9808 - f1_score: 0.7956 - loss: 0.0466 - precision: 0.9826 - recall: 0.9867 \n",
            "Epoch 504/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9812 - f1_score: 0.7845 - loss: 0.0502 - precision: 0.9837 - recall: 0.9854 \n",
            "Epoch 505/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9755 - f1_score: 0.7938 - loss: 0.0586 - precision: 0.9791 - recall: 0.9811 \n",
            "Epoch 506/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9801 - f1_score: 0.7931 - loss: 0.0536 - precision: 0.9836 - recall: 0.9841 \n",
            "Epoch 507/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9800 - f1_score: 0.7950 - loss: 0.0419 - precision: 0.9890 - recall: 0.9788 \n",
            "Epoch 508/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9912 - f1_score: 0.7954 - loss: 0.0311 - precision: 0.9945 - recall: 0.9913\n",
            "Epoch 509/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9834 - f1_score: 0.7878 - loss: 0.0480 - precision: 0.9867 - recall: 0.9861\n",
            "Epoch 510/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9736 - f1_score: 0.7971 - loss: 0.0660 - precision: 0.9825 - recall: 0.9749\n",
            "Epoch 511/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9748 - f1_score: 0.7860 - loss: 0.0576 - precision: 0.9798 - recall: 0.9785\n",
            "Epoch 512/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9819 - f1_score: 0.7893 - loss: 0.0416 - precision: 0.9823 - recall: 0.9882\n",
            "Epoch 513/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9806 - f1_score: 0.7919 - loss: 0.0493 - precision: 0.9833 - recall: 0.9850\n",
            "Epoch 514/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9859 - f1_score: 0.7918 - loss: 0.0396 - precision: 0.9900 - recall: 0.9871\n",
            "Epoch 515/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9724 - f1_score: 0.7852 - loss: 0.0711 - precision: 0.9800 - recall: 0.9746\n",
            "Epoch 516/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9731 - f1_score: 0.7779 - loss: 0.0871 - precision: 0.9797 - recall: 0.9750\n",
            "Epoch 517/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.7852 - loss: 0.0361 - precision: 0.9870 - recall: 0.9906 \n",
            "Epoch 518/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.7874 - loss: 0.0393 - precision: 0.9887 - recall: 0.9864 \n",
            "Epoch 519/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9789 - f1_score: 0.7928 - loss: 0.0563 - precision: 0.9892 - recall: 0.9764 \n",
            "Epoch 520/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9802 - f1_score: 0.8031 - loss: 0.0477 - precision: 0.9821 - recall: 0.9866 \n",
            "Epoch 521/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9829 - f1_score: 0.8003 - loss: 0.0518 - precision: 0.9847 - recall: 0.9878 \n",
            "Epoch 522/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8024 - loss: 0.0362 - precision: 0.9906 - recall: 0.9895 \n",
            "Epoch 523/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9751 - f1_score: 0.8012 - loss: 0.0561 - precision: 0.9805 - recall: 0.9797 \n",
            "Epoch 524/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7948 - loss: 0.0556 - precision: 0.9838 - recall: 0.9831 \n",
            "Epoch 525/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9842 - f1_score: 0.8025 - loss: 0.0459 - precision: 0.9898 - recall: 0.9851 \n",
            "Epoch 526/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.7866 - loss: 0.0377 - precision: 0.9875 - recall: 0.9877 \n",
            "Epoch 527/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9732 - f1_score: 0.7940 - loss: 0.0724 - precision: 0.9758 - recall: 0.9808 \n",
            "Epoch 528/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9822 - f1_score: 0.7966 - loss: 0.0546 - precision: 0.9878 - recall: 0.9833 \n",
            "Epoch 529/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9813 - f1_score: 0.8011 - loss: 0.0437 - precision: 0.9842 - recall: 0.9858 \n",
            "Epoch 530/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.8007 - loss: 0.0411 - precision: 0.9884 - recall: 0.9869 \n",
            "Epoch 531/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9833 - f1_score: 0.7949 - loss: 0.0435 - precision: 0.9846 - recall: 0.9886 \n",
            "Epoch 532/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9735 - f1_score: 0.7871 - loss: 0.0734 - precision: 0.9759 - recall: 0.9803 \n",
            "Epoch 533/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8010 - loss: 0.0414 - precision: 0.9887 - recall: 0.9882 \n",
            "Epoch 534/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9651 - f1_score: 0.7925 - loss: 0.0802 - precision: 0.9712 - recall: 0.9725 \n",
            "Epoch 535/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9867 - f1_score: 0.7933 - loss: 0.0336 - precision: 0.9892 - recall: 0.9891 \n",
            "Epoch 536/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9770 - f1_score: 0.7966 - loss: 0.0599 - precision: 0.9790 - recall: 0.9840 \n",
            "Epoch 537/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8007 - loss: 0.0421 - precision: 0.9852 - recall: 0.9839 \n",
            "Epoch 538/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9869 - f1_score: 0.8002 - loss: 0.0361 - precision: 0.9889 - recall: 0.9898 \n",
            "Epoch 539/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9833 - f1_score: 0.8000 - loss: 0.0450 - precision: 0.9866 - recall: 0.9866 \n",
            "Epoch 540/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.7929 - loss: 0.0475 - precision: 0.9818 - recall: 0.9818 \n",
            "Epoch 541/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9739 - f1_score: 0.7949 - loss: 0.0582 - precision: 0.9819 - recall: 0.9755 \n",
            "Epoch 542/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9806 - f1_score: 0.7960 - loss: 0.0496 - precision: 0.9841 - recall: 0.9846 \n",
            "Epoch 543/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9722 - f1_score: 0.7987 - loss: 0.0820 - precision: 0.9785 - recall: 0.9767 \n",
            "Epoch 544/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9883 - f1_score: 0.7951 - loss: 0.0340 - precision: 0.9901 - recall: 0.9909 \n",
            "Epoch 545/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9856 - f1_score: 0.8017 - loss: 0.0393 - precision: 0.9900 - recall: 0.9869 \n",
            "Epoch 546/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9631 - f1_score: 0.7982 - loss: 0.0785 - precision: 0.9701 - recall: 0.9700 \n",
            "Epoch 547/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9720 - f1_score: 0.7983 - loss: 0.0677 - precision: 0.9753 - recall: 0.9792 \n",
            "Epoch 548/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8042 - loss: 0.0295 - precision: 0.9935 - recall: 0.9918 \n",
            "Epoch 549/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9784 - f1_score: 0.7996 - loss: 0.0613 - precision: 0.9830 - recall: 0.9823 \n",
            "Epoch 550/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9888 - f1_score: 0.7965 - loss: 0.0348 - precision: 0.9884 - recall: 0.9933 \n",
            "Epoch 551/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9865 - f1_score: 0.8061 - loss: 0.0367 - precision: 0.9846 - recall: 0.9939 \n",
            "Epoch 552/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9729 - f1_score: 0.8011 - loss: 0.0548 - precision: 0.9767 - recall: 0.9794 \n",
            "Epoch 553/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.7922 - loss: 0.0573 - precision: 0.9846 - recall: 0.9814 \n",
            "Epoch 554/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9859 - f1_score: 0.7946 - loss: 0.0347 - precision: 0.9868 - recall: 0.9905 \n",
            "Epoch 555/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.7983 - loss: 0.0608 - precision: 0.9811 - recall: 0.9796 \n",
            "Epoch 556/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.8034 - loss: 0.0427 - precision: 0.9879 - recall: 0.9853 \n",
            "Epoch 557/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9809 - f1_score: 0.7993 - loss: 0.0510 - precision: 0.9824 - recall: 0.9868 \n",
            "Epoch 558/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.7909 - loss: 0.0398 - precision: 0.9884 - recall: 0.9850 \n",
            "Epoch 559/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9784 - f1_score: 0.8003 - loss: 0.0513 - precision: 0.9836 - recall: 0.9816 \n",
            "Epoch 560/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9713 - f1_score: 0.8013 - loss: 0.0842 - precision: 0.9772 - recall: 0.9761 \n",
            "Epoch 561/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.7980 - loss: 0.0437 - precision: 0.9837 - recall: 0.9895 \n",
            "Epoch 562/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8010 - loss: 0.0438 - precision: 0.9906 - recall: 0.9855 \n",
            "Epoch 563/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9850 - f1_score: 0.7888 - loss: 0.0428 - precision: 0.9882 - recall: 0.9873 \n",
            "Epoch 564/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9830 - f1_score: 0.7870 - loss: 0.0447 - precision: 0.9871 - recall: 0.9852 \n",
            "Epoch 565/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8034 - loss: 0.0328 - precision: 0.9885 - recall: 0.9889 \n",
            "Epoch 566/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8023 - loss: 0.0364 - precision: 0.9869 - recall: 0.9903 \n",
            "Epoch 567/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9842 - f1_score: 0.7954 - loss: 0.0453 - precision: 0.9887 - recall: 0.9856 \n",
            "Epoch 568/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9851 - f1_score: 0.7986 - loss: 0.0385 - precision: 0.9876 - recall: 0.9884 \n",
            "Epoch 569/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9760 - f1_score: 0.8007 - loss: 0.0594 - precision: 0.9758 - recall: 0.9857 \n",
            "Epoch 570/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9868 - f1_score: 0.7977 - loss: 0.0331 - precision: 0.9920 - recall: 0.9866 \n",
            "Epoch 571/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.8029 - loss: 0.0557 - precision: 0.9819 - recall: 0.9859 \n",
            "Epoch 572/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8008 - loss: 0.0374 - precision: 0.9882 - recall: 0.9905 \n",
            "Epoch 573/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9789 - f1_score: 0.7934 - loss: 0.0483 - precision: 0.9841 - recall: 0.9811 \n",
            "Epoch 574/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9844 - f1_score: 0.8017 - loss: 0.0348 - precision: 0.9868 - recall: 0.9879 \n",
            "Epoch 575/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9772 - f1_score: 0.7887 - loss: 0.0612 - precision: 0.9812 - recall: 0.9806 \n",
            "Epoch 576/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9825 - f1_score: 0.8015 - loss: 0.0504 - precision: 0.9838 - recall: 0.9879 \n",
            "Epoch 577/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9875 - f1_score: 0.8033 - loss: 0.0311 - precision: 0.9920 - recall: 0.9879 \n",
            "Epoch 578/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9869 - f1_score: 0.8066 - loss: 0.0359 - precision: 0.9909 - recall: 0.9879 \n",
            "Epoch 579/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.7955 - loss: 0.0381 - precision: 0.9940 - recall: 0.9826 \n",
            "Epoch 580/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9887 - f1_score: 0.8049 - loss: 0.0354 - precision: 0.9917 - recall: 0.9901 \n",
            "Epoch 581/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.7983 - loss: 0.0551 - precision: 0.9863 - recall: 0.9845 \n",
            "Epoch 582/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9754 - f1_score: 0.8032 - loss: 0.0558 - precision: 0.9764 - recall: 0.9842 \n",
            "Epoch 583/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9884 - f1_score: 0.7952 - loss: 0.0340 - precision: 0.9892 - recall: 0.9917 \n",
            "Epoch 584/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9892 - f1_score: 0.7967 - loss: 0.0312 - precision: 0.9911 - recall: 0.9914\n",
            "Epoch 585/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.7999 - loss: 0.0364 - precision: 0.9881 - recall: 0.9884 \n",
            "Epoch 586/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9744 - f1_score: 0.8013 - loss: 0.0598 - precision: 0.9768 - recall: 0.9822 \n",
            "Epoch 587/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9915 - f1_score: 0.7999 - loss: 0.0270 - precision: 0.9947 - recall: 0.9915 \n",
            "Epoch 588/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9798 - f1_score: 0.7980 - loss: 0.0601 - precision: 0.9798 - recall: 0.9877 \n",
            "Epoch 589/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9833 - f1_score: 0.7945 - loss: 0.0452 - precision: 0.9856 - recall: 0.9873 \n",
            "Epoch 590/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9798 - f1_score: 0.8030 - loss: 0.0746 - precision: 0.9878 - recall: 0.9797 \n",
            "Epoch 591/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9903 - f1_score: 0.7959 - loss: 0.0270 - precision: 0.9915 - recall: 0.9928 \n",
            "Epoch 592/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9803 - f1_score: 0.8023 - loss: 0.0475 - precision: 0.9794 - recall: 0.9891 \n",
            "Epoch 593/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9759 - f1_score: 0.8016 - loss: 0.0568 - precision: 0.9779 - recall: 0.9836 \n",
            "Epoch 594/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9747 - f1_score: 0.7993 - loss: 0.0617 - precision: 0.9776 - recall: 0.9818 \n",
            "Epoch 595/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9890 - f1_score: 0.8028 - loss: 0.0330 - precision: 0.9892 - recall: 0.9929 \n",
            "Epoch 596/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9765 - f1_score: 0.7951 - loss: 0.0559 - precision: 0.9805 - recall: 0.9809 \n",
            "Epoch 597/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8001 - loss: 0.0298 - precision: 0.9892 - recall: 0.9911 \n",
            "Epoch 598/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9836 - f1_score: 0.8045 - loss: 0.0395 - precision: 0.9874 - recall: 0.9861\n",
            "Epoch 599/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9774 - f1_score: 0.8029 - loss: 0.0798 - precision: 0.9798 - recall: 0.9841 \n",
            "Epoch 600/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9782 - f1_score: 0.7979 - loss: 0.0528 - precision: 0.9867 - recall: 0.9773 \n",
            "Epoch 601/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9856 - f1_score: 0.7894 - loss: 0.0368 - precision: 0.9869 - recall: 0.9894 \n",
            "Epoch 602/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9807 - f1_score: 0.7903 - loss: 0.0507 - precision: 0.9831 - recall: 0.9854\n",
            "Epoch 603/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9807 - f1_score: 0.7874 - loss: 0.0520 - precision: 0.9836 - recall: 0.9844\n",
            "Epoch 604/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9872 - f1_score: 0.8080 - loss: 0.0326 - precision: 0.9899 - recall: 0.9895\n",
            "Epoch 605/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9808 - f1_score: 0.8002 - loss: 0.0471 - precision: 0.9823 - recall: 0.9864\n",
            "Epoch 606/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9859 - f1_score: 0.8058 - loss: 0.0358 - precision: 0.9940 - recall: 0.9832\n",
            "Epoch 607/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9862 - f1_score: 0.8020 - loss: 0.0445 - precision: 0.9876 - recall: 0.9903\n",
            "Epoch 608/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9831 - f1_score: 0.8095 - loss: 0.0396 - precision: 0.9851 - recall: 0.9879\n",
            "Epoch 609/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9848 - f1_score: 0.8109 - loss: 0.0369 - precision: 0.9876 - recall: 0.9881\n",
            "Epoch 610/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9763 - f1_score: 0.7919 - loss: 0.0649 - precision: 0.9842 - recall: 0.9768\n",
            "Epoch 611/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9837 - f1_score: 0.8023 - loss: 0.0449 - precision: 0.9879 - recall: 0.9858\n",
            "Epoch 612/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9790 - f1_score: 0.8032 - loss: 0.0429 - precision: 0.9780 - recall: 0.9883  \n",
            "Epoch 613/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.7983 - loss: 0.0386 - precision: 0.9873 - recall: 0.9878 \n",
            "Epoch 614/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9883 - f1_score: 0.8042 - loss: 0.0295 - precision: 0.9916 - recall: 0.9895 \n",
            "Epoch 615/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9785 - f1_score: 0.8002 - loss: 0.0550 - precision: 0.9819 - recall: 0.9832 \n",
            "Epoch 616/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8096 - loss: 0.0411 - precision: 0.9895 - recall: 0.9821 \n",
            "Epoch 617/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9844 - f1_score: 0.7955 - loss: 0.0347 - precision: 0.9881 - recall: 0.9862 \n",
            "Epoch 618/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.8022 - loss: 0.0501 - precision: 0.9889 - recall: 0.9861 \n",
            "Epoch 619/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.7990 - loss: 0.0631 - precision: 0.9848 - recall: 0.9834 \n",
            "Epoch 620/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.7996 - loss: 0.0337 - precision: 0.9896 - recall: 0.9917 \n",
            "Epoch 621/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9941 - f1_score: 0.8000 - loss: 0.0221 - precision: 0.9962 - recall: 0.9943 \n",
            "Epoch 622/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8100 - loss: 0.0358 - precision: 0.9896 - recall: 0.9879 \n",
            "Epoch 623/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9834 - f1_score: 0.8015 - loss: 0.0493 - precision: 0.9869 - recall: 0.9861 \n",
            "Epoch 624/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.7998 - loss: 0.0470 - precision: 0.9854 - recall: 0.9846 \n",
            "Epoch 625/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9893 - f1_score: 0.8072 - loss: 0.0267 - precision: 0.9929 - recall: 0.9898 \n",
            "Epoch 626/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8121 - loss: 0.0312 - precision: 0.9932 - recall: 0.9890 \n",
            "Epoch 627/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9723 - f1_score: 0.8013 - loss: 0.0612 - precision: 0.9752 - recall: 0.9802 \n",
            "Epoch 628/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8012 - loss: 0.0411 - precision: 0.9863 - recall: 0.9918 \n",
            "Epoch 629/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9821 - f1_score: 0.7996 - loss: 0.0460 - precision: 0.9840 - recall: 0.9869 \n",
            "Epoch 630/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9749 - f1_score: 0.7987 - loss: 0.0627 - precision: 0.9824 - recall: 0.9758 \n",
            "Epoch 631/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9889 - f1_score: 0.7954 - loss: 0.0315 - precision: 0.9905 - recall: 0.9912 \n",
            "Epoch 632/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9805 - f1_score: 0.8018 - loss: 0.0472 - precision: 0.9826 - recall: 0.9859 \n",
            "Epoch 633/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9870 - f1_score: 0.8072 - loss: 0.0353 - precision: 0.9896 - recall: 0.9893 \n",
            "Epoch 634/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.7994 - loss: 0.0372 - precision: 0.9904 - recall: 0.9884 \n",
            "Epoch 635/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9822 - f1_score: 0.8031 - loss: 0.0480 - precision: 0.9901 - recall: 0.9811 \n",
            "Epoch 636/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9875 - f1_score: 0.8079 - loss: 0.0354 - precision: 0.9883 - recall: 0.9915 \n",
            "Epoch 637/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9853 - f1_score: 0.8081 - loss: 0.0347 - precision: 0.9861 - recall: 0.9899 \n",
            "Epoch 638/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.7951 - loss: 0.0248 - precision: 0.9908 - recall: 0.9926 \n",
            "Epoch 639/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8088 - loss: 0.0413 - precision: 0.9887 - recall: 0.9862 \n",
            "Epoch 640/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9903 - f1_score: 0.8123 - loss: 0.0273 - precision: 0.9917 - recall: 0.9928 \n",
            "Epoch 641/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9747 - f1_score: 0.8094 - loss: 0.0636 - precision: 0.9829 - recall: 0.9753 \n",
            "Epoch 642/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9852 - f1_score: 0.7999 - loss: 0.0466 - precision: 0.9868 - recall: 0.9894 \n",
            "Epoch 643/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9866 - f1_score: 0.8005 - loss: 0.0323 - precision: 0.9923 - recall: 0.9857 \n",
            "Epoch 644/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8033 - loss: 0.0326 - precision: 0.9891 - recall: 0.9893 \n",
            "Epoch 645/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9884 - f1_score: 0.7936 - loss: 0.0296 - precision: 0.9882 - recall: 0.9927 \n",
            "Epoch 646/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9754 - f1_score: 0.8073 - loss: 0.0606 - precision: 0.9793 - recall: 0.9808 \n",
            "Epoch 647/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9809 - f1_score: 0.8080 - loss: 0.0473 - precision: 0.9816 - recall: 0.9882 \n",
            "Epoch 648/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9816 - f1_score: 0.7877 - loss: 0.0408 - precision: 0.9852 - recall: 0.9840 \n",
            "Epoch 649/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8071 - loss: 0.0379 - precision: 0.9898 - recall: 0.9855 \n",
            "Epoch 650/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8069 - loss: 0.0338 - precision: 0.9950 - recall: 0.9855 \n",
            "Epoch 651/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9895 - f1_score: 0.8048 - loss: 0.0289 - precision: 0.9923 - recall: 0.9908 \n",
            "Epoch 652/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.8006 - loss: 0.0520 - precision: 0.9841 - recall: 0.9868 \n",
            "Epoch 653/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8104 - loss: 0.0289 - precision: 0.9896 - recall: 0.9927 \n",
            "Epoch 654/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9868 - f1_score: 0.7984 - loss: 0.0389 - precision: 0.9878 - recall: 0.9907 \n",
            "Epoch 655/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.7974 - loss: 0.0321 - precision: 0.9902 - recall: 0.9943 \n",
            "Epoch 656/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9831 - f1_score: 0.8045 - loss: 0.0452 - precision: 0.9869 - recall: 0.9859 \n",
            "Epoch 657/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9851 - f1_score: 0.8079 - loss: 0.0400 - precision: 0.9856 - recall: 0.9903 \n",
            "Epoch 658/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9884 - f1_score: 0.8044 - loss: 0.0310 - precision: 0.9910 - recall: 0.9901 \n",
            "Epoch 659/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9797 - f1_score: 0.8050 - loss: 0.0517 - precision: 0.9823 - recall: 0.9844 \n",
            "Epoch 660/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9865 - f1_score: 0.8070 - loss: 0.0338 - precision: 0.9874 - recall: 0.9905 \n",
            "Epoch 661/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9769 - f1_score: 0.8024 - loss: 0.0578 - precision: 0.9810 - recall: 0.9816 \n",
            "Epoch 662/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9817 - f1_score: 0.8116 - loss: 0.0477 - precision: 0.9836 - recall: 0.9870 \n",
            "Epoch 663/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8025 - loss: 0.0318 - precision: 0.9889 - recall: 0.9902 \n",
            "Epoch 664/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9842 - f1_score: 0.7948 - loss: 0.0369 - precision: 0.9903 - recall: 0.9836 \n",
            "Epoch 665/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8119 - loss: 0.0353 - precision: 0.9888 - recall: 0.9871 \n",
            "Epoch 666/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8077 - loss: 0.0490 - precision: 0.9860 - recall: 0.9875 \n",
            "Epoch 667/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8102 - loss: 0.0235 - precision: 0.9956 - recall: 0.9928 \n",
            "Epoch 668/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9737 - f1_score: 0.8055 - loss: 0.0721 - precision: 0.9781 - recall: 0.9791 \n",
            "Epoch 669/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9873 - f1_score: 0.7946 - loss: 0.0330 - precision: 0.9910 - recall: 0.9882\n",
            "Epoch 670/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8129 - loss: 0.0350 - precision: 0.9907 - recall: 0.9928 \n",
            "Epoch 671/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9869 - f1_score: 0.8073 - loss: 0.0332 - precision: 0.9887 - recall: 0.9902 \n",
            "Epoch 672/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8072 - loss: 0.0293 - precision: 0.9917 - recall: 0.9882 \n",
            "Epoch 673/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9733 - f1_score: 0.8007 - loss: 0.0663 - precision: 0.9772 - recall: 0.9786 \n",
            "Epoch 674/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8071 - loss: 0.0290 - precision: 0.9904 - recall: 0.9911 \n",
            "Epoch 675/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8071 - loss: 0.0384 - precision: 0.9875 - recall: 0.9877 \n",
            "Epoch 676/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9859 - f1_score: 0.8001 - loss: 0.0437 - precision: 0.9878 - recall: 0.9894 \n",
            "Epoch 677/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9888 - f1_score: 0.8133 - loss: 0.0350 - precision: 0.9903 - recall: 0.9916\n",
            "Epoch 678/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9837 - f1_score: 0.8122 - loss: 0.0446 - precision: 0.9871 - recall: 0.9868 \n",
            "Epoch 679/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8024 - loss: 0.0395 - precision: 0.9871 - recall: 0.9896 \n",
            "Epoch 680/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9891 - f1_score: 0.8140 - loss: 0.0332 - precision: 0.9921 - recall: 0.9903 \n",
            "Epoch 681/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8018 - loss: 0.0406 - precision: 0.9883 - recall: 0.9889 \n",
            "Epoch 682/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9841 - f1_score: 0.8051 - loss: 0.0380 - precision: 0.9901 - recall: 0.9840 \n",
            "Epoch 683/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9787 - f1_score: 0.8119 - loss: 0.0552 - precision: 0.9865 - recall: 0.9790 \n",
            "Epoch 684/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9826 - f1_score: 0.8153 - loss: 0.0437 - precision: 0.9861 - recall: 0.9861 \n",
            "Epoch 685/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9851 - f1_score: 0.8076 - loss: 0.0343 - precision: 0.9868 - recall: 0.9893 \n",
            "Epoch 686/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9817 - f1_score: 0.8064 - loss: 0.0534 - precision: 0.9908 - recall: 0.9793 \n",
            "Epoch 687/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9873 - f1_score: 0.8116 - loss: 0.0422 - precision: 0.9916 - recall: 0.9879 \n",
            "Epoch 688/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9800 - f1_score: 0.8070 - loss: 0.0463 - precision: 0.9884 - recall: 0.9788 \n",
            "Epoch 689/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8100 - loss: 0.0444 - precision: 0.9875 - recall: 0.9860 \n",
            "Epoch 690/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9792 - f1_score: 0.8020 - loss: 0.0576 - precision: 0.9837 - recall: 0.9823 \n",
            "Epoch 691/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9899 - f1_score: 0.8109 - loss: 0.0286 - precision: 0.9929 - recall: 0.9909 \n",
            "Epoch 692/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8083 - loss: 0.0426 - precision: 0.9883 - recall: 0.9900 \n",
            "Epoch 693/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9926 - f1_score: 0.8018 - loss: 0.0220 - precision: 0.9957 - recall: 0.9921\n",
            "Epoch 694/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9798 - f1_score: 0.8031 - loss: 0.0710 - precision: 0.9800 - recall: 0.9875\n",
            "Epoch 695/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9870 - f1_score: 0.8043 - loss: 0.0423 - precision: 0.9930 - recall: 0.9860\n",
            "Epoch 696/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9827 - f1_score: 0.8105 - loss: 0.0466 - precision: 0.9880 - recall: 0.9845\n",
            "Epoch 697/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9913 - f1_score: 0.8104 - loss: 0.0253 - precision: 0.9917 - recall: 0.9942\n",
            "Epoch 698/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9834 - f1_score: 0.7998 - loss: 0.0480 - precision: 0.9888 - recall: 0.9840\n",
            "Epoch 699/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9831 - f1_score: 0.8032 - loss: 0.0431 - precision: 0.9876 - recall: 0.9850\n",
            "Epoch 700/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9878 - f1_score: 0.8102 - loss: 0.0358 - precision: 0.9911 - recall: 0.9891\n",
            "Epoch 701/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9915 - f1_score: 0.8123 - loss: 0.0312 - precision: 0.9929 - recall: 0.9935  \n",
            "Epoch 702/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9878 - f1_score: 0.8023 - loss: 0.0373 - precision: 0.9905 - recall: 0.9896 \n",
            "Epoch 703/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8002 - loss: 0.0316 - precision: 0.9918 - recall: 0.9915 \n",
            "Epoch 704/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8013 - loss: 0.0378 - precision: 0.9925 - recall: 0.9832 \n",
            "Epoch 705/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9903 - f1_score: 0.7996 - loss: 0.0276 - precision: 0.9929 - recall: 0.9914 \n",
            "Epoch 706/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.8148 - loss: 0.0562 - precision: 0.9821 - recall: 0.9822 \n",
            "Epoch 707/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8143 - loss: 0.0210 - precision: 0.9967 - recall: 0.9921 \n",
            "Epoch 708/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9818 - f1_score: 0.8034 - loss: 0.0382 - precision: 0.9809 - recall: 0.9895 \n",
            "Epoch 709/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8065 - loss: 0.0337 - precision: 0.9933 - recall: 0.9889 \n",
            "Epoch 710/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9881 - f1_score: 0.8014 - loss: 0.0313 - precision: 0.9914 - recall: 0.9892\n",
            "Epoch 711/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8055 - loss: 0.0271 - precision: 0.9927 - recall: 0.9925 \n",
            "Epoch 712/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9835 - f1_score: 0.8061 - loss: 0.0358 - precision: 0.9898 - recall: 0.9832 \n",
            "Epoch 713/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8032 - loss: 0.0256 - precision: 0.9938 - recall: 0.9942 \n",
            "Epoch 714/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.7994 - loss: 0.0359 - precision: 0.9931 - recall: 0.9849 \n",
            "Epoch 715/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.8194 - loss: 0.0551 - precision: 0.9834 - recall: 0.9823 \n",
            "Epoch 716/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8139 - loss: 0.0428 - precision: 0.9932 - recall: 0.9862 \n",
            "Epoch 717/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9916 - f1_score: 0.8020 - loss: 0.0275 - precision: 0.9923 - recall: 0.9940 \n",
            "Epoch 718/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9887 - f1_score: 0.8120 - loss: 0.0289 - precision: 0.9950 - recall: 0.9867 \n",
            "Epoch 719/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8076 - loss: 0.0382 - precision: 0.9901 - recall: 0.9869 \n",
            "Epoch 720/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9953 - f1_score: 0.8072 - loss: 0.0194 - precision: 0.9955 - recall: 0.9969 \n",
            "Epoch 721/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9831 - f1_score: 0.8185 - loss: 0.0424 - precision: 0.9860 - recall: 0.9874 \n",
            "Epoch 722/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9856 - f1_score: 0.8091 - loss: 0.0324 - precision: 0.9882 - recall: 0.9886 \n",
            "Epoch 723/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9783 - f1_score: 0.8058 - loss: 0.0605 - precision: 0.9824 - recall: 0.9822 \n",
            "Epoch 724/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9895 - f1_score: 0.8040 - loss: 0.0235 - precision: 0.9910 - recall: 0.9918 \n",
            "Epoch 725/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8053 - loss: 0.0366 - precision: 0.9933 - recall: 0.9847 \n",
            "Epoch 726/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9752 - f1_score: 0.8073 - loss: 0.0505 - precision: 0.9803 - recall: 0.9795 \n",
            "Epoch 727/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8114 - loss: 0.0554 - precision: 0.9860 - recall: 0.9893 \n",
            "Epoch 728/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9868 - f1_score: 0.8104 - loss: 0.0331 - precision: 0.9890 - recall: 0.9897 \n",
            "Epoch 729/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8046 - loss: 0.0289 - precision: 0.9940 - recall: 0.9917 \n",
            "Epoch 730/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9823 - f1_score: 0.8134 - loss: 0.0612 - precision: 0.9907 - recall: 0.9806 \n",
            "Epoch 731/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8116 - loss: 0.0234 - precision: 0.9927 - recall: 0.9934 \n",
            "Epoch 732/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9791 - f1_score: 0.7942 - loss: 0.0504 - precision: 0.9830 - recall: 0.9821 \n",
            "Epoch 733/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9854 - f1_score: 0.8175 - loss: 0.0341 - precision: 0.9878 - recall: 0.9884 \n",
            "Epoch 734/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8106 - loss: 0.0264 - precision: 0.9903 - recall: 0.9917 \n",
            "Epoch 735/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8111 - loss: 0.0405 - precision: 0.9865 - recall: 0.9887 \n",
            "Epoch 736/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9795 - f1_score: 0.8096 - loss: 0.0533 - precision: 0.9845 - recall: 0.9822 \n",
            "Epoch 737/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8162 - loss: 0.0325 - precision: 0.9868 - recall: 0.9908 \n",
            "Epoch 738/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9887 - f1_score: 0.8228 - loss: 0.0274 - precision: 0.9932 - recall: 0.9888 \n",
            "Epoch 739/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9792 - f1_score: 0.8118 - loss: 0.0707 - precision: 0.9844 - recall: 0.9822 \n",
            "Epoch 740/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8109 - loss: 0.0325 - precision: 0.9902 - recall: 0.9906 \n",
            "Epoch 741/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9880 - f1_score: 0.8160 - loss: 0.0308 - precision: 0.9892 - recall: 0.9915 \n",
            "Epoch 742/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9938 - f1_score: 0.8088 - loss: 0.0243 - precision: 0.9951 - recall: 0.9948 \n",
            "Epoch 743/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9854 - f1_score: 0.8085 - loss: 0.0380 - precision: 0.9893 - recall: 0.9872 \n",
            "Epoch 744/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9879 - f1_score: 0.8206 - loss: 0.0367 - precision: 0.9885 - recall: 0.9921\n",
            "Epoch 745/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9819 - f1_score: 0.8114 - loss: 0.0525 - precision: 0.9817 - recall: 0.9893 \n",
            "Epoch 746/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8209 - loss: 0.0345 - precision: 0.9902 - recall: 0.9886 \n",
            "Epoch 747/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8209 - loss: 0.0302 - precision: 0.9929 - recall: 0.9917 \n",
            "Epoch 748/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9760 - f1_score: 0.8171 - loss: 0.0532 - precision: 0.9795 - recall: 0.9809 \n",
            "Epoch 749/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9818 - f1_score: 0.8079 - loss: 0.0375 - precision: 0.9864 - recall: 0.9836 \n",
            "Epoch 750/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8201 - loss: 0.0252 - precision: 0.9930 - recall: 0.9931 \n",
            "Epoch 751/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8135 - loss: 0.0329 - precision: 0.9893 - recall: 0.9907 \n",
            "Epoch 752/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8106 - loss: 0.0314 - precision: 0.9910 - recall: 0.9897 \n",
            "Epoch 753/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9800 - f1_score: 0.8140 - loss: 0.0461 - precision: 0.9836 - recall: 0.9841 \n",
            "Epoch 754/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9860 - f1_score: 0.8047 - loss: 0.0343 - precision: 0.9896 - recall: 0.9874 \n",
            "Epoch 755/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9764 - f1_score: 0.8154 - loss: 0.0542 - precision: 0.9815 - recall: 0.9802 \n",
            "Epoch 756/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8065 - loss: 0.0230 - precision: 0.9932 - recall: 0.9928 \n",
            "Epoch 757/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8213 - loss: 0.0294 - precision: 0.9914 - recall: 0.9917 \n",
            "Epoch 758/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8026 - loss: 0.0452 - precision: 0.9898 - recall: 0.9909 \n",
            "Epoch 759/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9875 - f1_score: 0.7994 - loss: 0.0319 - precision: 0.9899 - recall: 0.9894 \n",
            "Epoch 760/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8138 - loss: 0.0338 - precision: 0.9911 - recall: 0.9879 \n",
            "Epoch 761/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9859 - f1_score: 0.8163 - loss: 0.0356 - precision: 0.9881 - recall: 0.9891 \n",
            "Epoch 762/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9820 - f1_score: 0.8054 - loss: 0.0482 - precision: 0.9850 - recall: 0.9853 \n",
            "Epoch 763/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9878 - f1_score: 0.8071 - loss: 0.0372 - precision: 0.9896 - recall: 0.9906 \n",
            "Epoch 764/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8017 - loss: 0.0394 - precision: 0.9904 - recall: 0.9884 \n",
            "Epoch 765/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8208 - loss: 0.0296 - precision: 0.9913 - recall: 0.9911 \n",
            "Epoch 766/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9726 - f1_score: 0.8074 - loss: 0.0728 - precision: 0.9782 - recall: 0.9767 \n",
            "Epoch 767/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8116 - loss: 0.0241 - precision: 0.9929 - recall: 0.9890 \n",
            "Epoch 768/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9895 - f1_score: 0.8127 - loss: 0.0400 - precision: 0.9914 - recall: 0.9915 \n",
            "Epoch 769/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9895 - f1_score: 0.8172 - loss: 0.0345 - precision: 0.9921 - recall: 0.9912 \n",
            "Epoch 770/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9882 - f1_score: 0.8125 - loss: 0.0372 - precision: 0.9920 - recall: 0.9889 \n",
            "Epoch 771/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9918 - f1_score: 0.8210 - loss: 0.0258 - precision: 0.9914 - recall: 0.9955 \n",
            "Epoch 772/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9809 - f1_score: 0.8158 - loss: 0.0506 - precision: 0.9846 - recall: 0.9843 \n",
            "Epoch 773/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8126 - loss: 0.0211 - precision: 0.9926 - recall: 0.9957 \n",
            "Epoch 774/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9821 - f1_score: 0.8146 - loss: 0.0559 - precision: 0.9842 - recall: 0.9868 \n",
            "Epoch 775/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9840 - f1_score: 0.8118 - loss: 0.0384 - precision: 0.9900 - recall: 0.9841 \n",
            "Epoch 776/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8206 - loss: 0.0306 - precision: 0.9921 - recall: 0.9873 \n",
            "Epoch 777/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.8157 - loss: 0.0397 - precision: 0.9871 - recall: 0.9870 \n",
            "Epoch 778/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8193 - loss: 0.0307 - precision: 0.9888 - recall: 0.9917 \n",
            "Epoch 779/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9840 - f1_score: 0.8110 - loss: 0.0360 - precision: 0.9883 - recall: 0.9855 \n",
            "Epoch 780/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9854 - f1_score: 0.8103 - loss: 0.0343 - precision: 0.9906 - recall: 0.9856 \n",
            "Epoch 781/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9862 - f1_score: 0.8141 - loss: 0.0370 - precision: 0.9871 - recall: 0.9905 \n",
            "Epoch 782/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9872 - f1_score: 0.8111 - loss: 0.0311 - precision: 0.9902 - recall: 0.9892\n",
            "Epoch 783/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9923 - f1_score: 0.8192 - loss: 0.0264 - precision: 0.9926 - recall: 0.9949\n",
            "Epoch 784/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9841 - f1_score: 0.8138 - loss: 0.0413 - precision: 0.9873 - recall: 0.9868\n",
            "Epoch 785/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9919 - f1_score: 0.8138 - loss: 0.0247 - precision: 0.9917 - recall: 0.9952 \n",
            "Epoch 786/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9903 - f1_score: 0.8095 - loss: 0.0317 - precision: 0.9934 - recall: 0.9906\n",
            "Epoch 787/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9835 - f1_score: 0.8064 - loss: 0.0475 - precision: 0.9886 - recall: 0.9845\n",
            "Epoch 788/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9926 - f1_score: 0.8146 - loss: 0.0240 - precision: 0.9936 - recall: 0.9945\n",
            "Epoch 789/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9928 - f1_score: 0.8047 - loss: 0.0254 - precision: 0.9954 - recall: 0.9928\n",
            "Epoch 790/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9821 - f1_score: 0.8223 - loss: 0.0715 - precision: 0.9881 - recall: 0.9833\n",
            "Epoch 791/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9954 - f1_score: 0.8130 - loss: 0.0194 - precision: 0.9973 - recall: 0.9952\n",
            "Epoch 792/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9846 - f1_score: 0.8216 - loss: 0.0454 - precision: 0.9889 - recall: 0.9866  \n",
            "Epoch 793/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8167 - loss: 0.0342 - precision: 0.9902 - recall: 0.9913 \n",
            "Epoch 794/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9911 - f1_score: 0.8177 - loss: 0.0327 - precision: 0.9929 - recall: 0.9927 \n",
            "Epoch 795/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9854 - f1_score: 0.8141 - loss: 0.0412 - precision: 0.9924 - recall: 0.9839 \n",
            "Epoch 796/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9884 - f1_score: 0.8093 - loss: 0.0282 - precision: 0.9909 - recall: 0.9901 \n",
            "Epoch 797/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8174 - loss: 0.0299 - precision: 0.9897 - recall: 0.9937 \n",
            "Epoch 798/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8106 - loss: 0.0520 - precision: 0.9890 - recall: 0.9861 \n",
            "Epoch 799/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8093 - loss: 0.0249 - precision: 0.9922 - recall: 0.9939 \n",
            "Epoch 800/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9885 - f1_score: 0.8128 - loss: 0.0295 - precision: 0.9922 - recall: 0.9894 \n",
            "Epoch 801/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9773 - f1_score: 0.8211 - loss: 0.0636 - precision: 0.9870 - recall: 0.9764 \n",
            "Epoch 802/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9924 - f1_score: 0.8160 - loss: 0.0237 - precision: 0.9927 - recall: 0.9951 \n",
            "Epoch 803/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9709 - f1_score: 0.8142 - loss: 0.0688 - precision: 0.9774 - recall: 0.9752 \n",
            "Epoch 804/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8250 - loss: 0.0244 - precision: 0.9933 - recall: 0.9925 \n",
            "Epoch 805/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8062 - loss: 0.0467 - precision: 0.9889 - recall: 0.9903 \n",
            "Epoch 806/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9889 - f1_score: 0.8128 - loss: 0.0260 - precision: 0.9919 - recall: 0.9902 \n",
            "Epoch 807/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9925 - f1_score: 0.8207 - loss: 0.0230 - precision: 0.9945 - recall: 0.9934\n",
            "Epoch 808/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8215 - loss: 0.0275 - precision: 0.9952 - recall: 0.9906 \n",
            "Epoch 809/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.8090 - loss: 0.0847 - precision: 0.9764 - recall: 0.9746 \n",
            "Epoch 810/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8106 - loss: 0.0244 - precision: 0.9937 - recall: 0.9907 \n",
            "Epoch 811/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9844 - f1_score: 0.8107 - loss: 0.0362 - precision: 0.9869 - recall: 0.9876 \n",
            "Epoch 812/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8143 - loss: 0.0265 - precision: 0.9911 - recall: 0.9942 \n",
            "Epoch 813/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8134 - loss: 0.0338 - precision: 0.9857 - recall: 0.9926 \n",
            "Epoch 814/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.8050 - loss: 0.0358 - precision: 0.9896 - recall: 0.9827 \n",
            "Epoch 815/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9938 - f1_score: 0.8255 - loss: 0.0184 - precision: 0.9951 - recall: 0.9949 \n",
            "Epoch 816/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8144 - loss: 0.0291 - precision: 0.9926 - recall: 0.9901 \n",
            "Epoch 817/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9786 - f1_score: 0.8237 - loss: 0.0503 - precision: 0.9826 - recall: 0.9829 \n",
            "Epoch 818/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8237 - loss: 0.0348 - precision: 0.9899 - recall: 0.9909 \n",
            "Epoch 819/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8242 - loss: 0.0250 - precision: 0.9926 - recall: 0.9891 \n",
            "Epoch 820/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9835 - f1_score: 0.8140 - loss: 0.0404 - precision: 0.9845 - recall: 0.9885 \n",
            "Epoch 821/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9891 - f1_score: 0.8133 - loss: 0.0302 - precision: 0.9930 - recall: 0.9891 \n",
            "Epoch 822/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9899 - f1_score: 0.8190 - loss: 0.0305 - precision: 0.9944 - recall: 0.9893 \n",
            "Epoch 823/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.8247 - loss: 0.0746 - precision: 0.9867 - recall: 0.9866 \n",
            "Epoch 824/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9856 - f1_score: 0.8215 - loss: 0.0365 - precision: 0.9908 - recall: 0.9860 \n",
            "Epoch 825/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8210 - loss: 0.0372 - precision: 0.9894 - recall: 0.9877 \n",
            "Epoch 826/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9924 - f1_score: 0.8108 - loss: 0.0222 - precision: 0.9940 - recall: 0.9935 \n",
            "Epoch 827/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9845 - f1_score: 0.8169 - loss: 0.0385 - precision: 0.9868 - recall: 0.9882 \n",
            "Epoch 828/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8163 - loss: 0.0343 - precision: 0.9918 - recall: 0.9926 \n",
            "Epoch 829/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9908 - f1_score: 0.8161 - loss: 0.0261 - precision: 0.9916 - recall: 0.9936\n",
            "Epoch 830/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8100 - loss: 0.0257 - precision: 0.9917 - recall: 0.9942 \n",
            "Epoch 831/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8156 - loss: 0.0221 - precision: 0.9909 - recall: 0.9944 \n",
            "Epoch 832/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9844 - f1_score: 0.8149 - loss: 0.0434 - precision: 0.9876 - recall: 0.9875 \n",
            "Epoch 833/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9861 - f1_score: 0.8112 - loss: 0.0378 - precision: 0.9905 - recall: 0.9868 \n",
            "Epoch 834/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8136 - loss: 0.0387 - precision: 0.9831 - recall: 0.9923 \n",
            "Epoch 835/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9857 - f1_score: 0.8172 - loss: 0.0337 - precision: 0.9885 - recall: 0.9886 \n",
            "Epoch 836/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8105 - loss: 0.0257 - precision: 0.9912 - recall: 0.9914 \n",
            "Epoch 837/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9865 - f1_score: 0.8015 - loss: 0.0461 - precision: 0.9898 - recall: 0.9880 \n",
            "Epoch 838/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9873 - f1_score: 0.8135 - loss: 0.0322 - precision: 0.9924 - recall: 0.9868 \n",
            "Epoch 839/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9814 - f1_score: 0.8135 - loss: 0.0508 - precision: 0.9832 - recall: 0.9867 \n",
            "Epoch 840/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9881 - f1_score: 0.8113 - loss: 0.0303 - precision: 0.9931 - recall: 0.9875 \n",
            "Epoch 841/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9931 - f1_score: 0.8161 - loss: 0.0196 - precision: 0.9934 - recall: 0.9954 \n",
            "Epoch 842/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9803 - f1_score: 0.8192 - loss: 0.0477 - precision: 0.9864 - recall: 0.9814 \n",
            "Epoch 843/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9921 - f1_score: 0.8174 - loss: 0.0247 - precision: 0.9945 - recall: 0.9926 \n",
            "Epoch 844/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9864 - f1_score: 0.8093 - loss: 0.0320 - precision: 0.9858 - recall: 0.9921 \n",
            "Epoch 845/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9875 - f1_score: 0.8037 - loss: 0.0345 - precision: 0.9905 - recall: 0.9889\n",
            "Epoch 846/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8160 - loss: 0.0331 - precision: 0.9909 - recall: 0.9895 \n",
            "Epoch 847/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9915 - f1_score: 0.8261 - loss: 0.0261 - precision: 0.9933 - recall: 0.9930 \n",
            "Epoch 848/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9849 - f1_score: 0.8126 - loss: 0.0380 - precision: 0.9879 - recall: 0.9874 \n",
            "Epoch 849/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8138 - loss: 0.0256 - precision: 0.9918 - recall: 0.9938 \n",
            "Epoch 850/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9911 - f1_score: 0.8125 - loss: 0.0273 - precision: 0.9942 - recall: 0.9914 \n",
            "Epoch 851/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9869 - f1_score: 0.8140 - loss: 0.0348 - precision: 0.9908 - recall: 0.9881 \n",
            "Epoch 852/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9899 - f1_score: 0.8161 - loss: 0.0280 - precision: 0.9907 - recall: 0.9929 \n",
            "Epoch 853/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8155 - loss: 0.0330 - precision: 0.9916 - recall: 0.9871 \n",
            "Epoch 854/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9866 - f1_score: 0.8152 - loss: 0.0313 - precision: 0.9886 - recall: 0.9896 \n",
            "Epoch 855/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9789 - f1_score: 0.8245 - loss: 0.0540 - precision: 0.9850 - recall: 0.9809 \n",
            "Epoch 856/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9925 - f1_score: 0.8151 - loss: 0.0240 - precision: 0.9948 - recall: 0.9930 \n",
            "Epoch 857/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9855 - f1_score: 0.8215 - loss: 0.0441 - precision: 0.9855 - recall: 0.9911 \n",
            "Epoch 858/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9904 - f1_score: 0.8184 - loss: 0.0248 - precision: 0.9908 - recall: 0.9937 \n",
            "Epoch 859/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9893 - f1_score: 0.8131 - loss: 0.0359 - precision: 0.9907 - recall: 0.9918 \n",
            "Epoch 860/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8075 - loss: 0.0300 - precision: 0.9907 - recall: 0.9928 \n",
            "Epoch 861/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8149 - loss: 0.0286 - precision: 0.9907 - recall: 0.9931 \n",
            "Epoch 862/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9901 - f1_score: 0.8148 - loss: 0.0307 - precision: 0.9935 - recall: 0.9904\n",
            "Epoch 863/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9905 - f1_score: 0.8186 - loss: 0.0276 - precision: 0.9927 - recall: 0.9918 \n",
            "Epoch 864/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9848 - f1_score: 0.8226 - loss: 0.0414 - precision: 0.9829 - recall: 0.9929 \n",
            "Epoch 865/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9880 - f1_score: 0.8198 - loss: 0.0301 - precision: 0.9909 - recall: 0.9898 \n",
            "Epoch 866/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8170 - loss: 0.0254 - precision: 0.9911 - recall: 0.9942 \n",
            "Epoch 867/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8186 - loss: 0.0266 - precision: 0.9897 - recall: 0.9937 \n",
            "Epoch 868/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9901 - f1_score: 0.8128 - loss: 0.0262 - precision: 0.9906 - recall: 0.9931 \n",
            "Epoch 869/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9896 - f1_score: 0.8223 - loss: 0.0282 - precision: 0.9887 - recall: 0.9948 \n",
            "Epoch 870/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9891 - f1_score: 0.8151 - loss: 0.0288 - precision: 0.9927 - recall: 0.9895\n",
            "Epoch 871/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8051 - loss: 0.0329 - precision: 0.9908 - recall: 0.9883 \n",
            "Epoch 872/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8207 - loss: 0.0289 - precision: 0.9925 - recall: 0.9939 \n",
            "Epoch 873/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9896 - f1_score: 0.8136 - loss: 0.0253 - precision: 0.9927 - recall: 0.9904 \n",
            "Epoch 874/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9873 - f1_score: 0.8166 - loss: 0.0334 - precision: 0.9895 - recall: 0.9898\n",
            "Epoch 875/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9894 - f1_score: 0.8202 - loss: 0.0213 - precision: 0.9918 - recall: 0.9910\n",
            "Epoch 876/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9921 - f1_score: 0.8240 - loss: 0.0249 - precision: 0.9916 - recall: 0.9956\n",
            "Epoch 877/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9888 - f1_score: 0.8057 - loss: 0.0301 - precision: 0.9898 - recall: 0.9915\n",
            "Epoch 878/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9908 - f1_score: 0.8256 - loss: 0.0237 - precision: 0.9916 - recall: 0.9934\n",
            "Epoch 879/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9876 - f1_score: 0.8287 - loss: 0.0303 - precision: 0.9894 - recall: 0.9908\n",
            "Epoch 880/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9823 - f1_score: 0.8121 - loss: 0.0511 - precision: 0.9890 - recall: 0.9822\n",
            "Epoch 881/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9817 - f1_score: 0.8212 - loss: 0.0519 - precision: 0.9895 - recall: 0.9811\n",
            "Epoch 882/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9869 - f1_score: 0.8122 - loss: 0.0342 - precision: 0.9895 - recall: 0.9891\n",
            "Epoch 883/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9924 - f1_score: 0.8173 - loss: 0.0242 - precision: 0.9936 - recall: 0.9940  \n",
            "Epoch 884/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8099 - loss: 0.0272 - precision: 0.9908 - recall: 0.9919 \n",
            "Epoch 885/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8291 - loss: 0.0224 - precision: 0.9911 - recall: 0.9948 \n",
            "Epoch 886/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8247 - loss: 0.0252 - precision: 0.9920 - recall: 0.9954 \n",
            "Epoch 887/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9810 - f1_score: 0.8224 - loss: 0.0477 - precision: 0.9854 - recall: 0.9841 \n",
            "Epoch 888/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9950 - f1_score: 0.8247 - loss: 0.0162 - precision: 0.9954 - recall: 0.9966 \n",
            "Epoch 889/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8278 - loss: 0.0206 - precision: 0.9942 - recall: 0.9941 \n",
            "Epoch 890/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8193 - loss: 0.0305 - precision: 0.9913 - recall: 0.9836 \n",
            "Epoch 891/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8179 - loss: 0.0277 - precision: 0.9899 - recall: 0.9917 \n",
            "Epoch 892/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9762 - f1_score: 0.8064 - loss: 0.0540 - precision: 0.9795 - recall: 0.9815 \n",
            "Epoch 893/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9936 - f1_score: 0.8156 - loss: 0.0149 - precision: 0.9946 - recall: 0.9950 \n",
            "Epoch 894/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8151 - loss: 0.0293 - precision: 0.9905 - recall: 0.9923 \n",
            "Epoch 895/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9836 - f1_score: 0.8236 - loss: 0.0393 - precision: 0.9876 - recall: 0.9856 \n",
            "Epoch 896/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9884 - f1_score: 0.8188 - loss: 0.0296 - precision: 0.9923 - recall: 0.9887\n",
            "Epoch 897/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9892 - f1_score: 0.8244 - loss: 0.0364 - precision: 0.9893 - recall: 0.9932 \n",
            "Epoch 898/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9838 - f1_score: 0.8203 - loss: 0.0415 - precision: 0.9892 - recall: 0.9845 \n",
            "Epoch 899/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9925 - f1_score: 0.8221 - loss: 0.0238 - precision: 0.9941 - recall: 0.9938 \n",
            "Epoch 900/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9875 - f1_score: 0.8234 - loss: 0.0296 - precision: 0.9880 - recall: 0.9917 \n",
            "Epoch 901/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9915 - f1_score: 0.8208 - loss: 0.0214 - precision: 0.9920 - recall: 0.9943 \n",
            "Epoch 902/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9888 - f1_score: 0.8229 - loss: 0.0285 - precision: 0.9915 - recall: 0.9904 \n",
            "Epoch 903/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9877 - f1_score: 0.8223 - loss: 0.0433 - precision: 0.9900 - recall: 0.9900 \n",
            "Epoch 904/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9908 - f1_score: 0.8355 - loss: 0.0278 - precision: 0.9924 - recall: 0.9929 \n",
            "Epoch 905/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8218 - loss: 0.0204 - precision: 0.9936 - recall: 0.9944 \n",
            "Epoch 906/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9930 - f1_score: 0.8251 - loss: 0.0167 - precision: 0.9927 - recall: 0.9961 \n",
            "Epoch 907/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9819 - f1_score: 0.8233 - loss: 0.0532 - precision: 0.9859 - recall: 0.9850 \n",
            "Epoch 908/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9900 - f1_score: 0.8223 - loss: 0.0253 - precision: 0.9913 - recall: 0.9926 \n",
            "Epoch 909/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8189 - loss: 0.0421 - precision: 0.9855 - recall: 0.9925 \n",
            "Epoch 910/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9893 - f1_score: 0.8251 - loss: 0.0377 - precision: 0.9917 - recall: 0.9910 \n",
            "Epoch 911/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9906 - f1_score: 0.8209 - loss: 0.0272 - precision: 0.9918 - recall: 0.9932 \n",
            "Epoch 912/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9886 - f1_score: 0.8235 - loss: 0.0281 - precision: 0.9915 - recall: 0.9900 \n",
            "Epoch 913/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9870 - f1_score: 0.8222 - loss: 0.0330 - precision: 0.9901 - recall: 0.9888 \n",
            "Epoch 914/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8251 - loss: 0.0196 - precision: 0.9935 - recall: 0.9942 \n",
            "Epoch 915/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9879 - f1_score: 0.8344 - loss: 0.0308 - precision: 0.9907 - recall: 0.9900 \n",
            "Epoch 916/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9898 - f1_score: 0.8315 - loss: 0.0253 - precision: 0.9903 - recall: 0.9934 \n",
            "Epoch 917/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9841 - f1_score: 0.8245 - loss: 0.0384 - precision: 0.9865 - recall: 0.9873 \n",
            "Epoch 918/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9844 - f1_score: 0.8220 - loss: 0.0380 - precision: 0.9833 - recall: 0.9912 \n",
            "Epoch 919/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9918 - f1_score: 0.8375 - loss: 0.0228 - precision: 0.9946 - recall: 0.9921 \n",
            "Epoch 920/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8331 - loss: 0.0347 - precision: 0.9874 - recall: 0.9900 \n",
            "Epoch 921/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9878 - f1_score: 0.8268 - loss: 0.0311 - precision: 0.9900 - recall: 0.9906 \n",
            "Epoch 922/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9918 - f1_score: 0.8222 - loss: 0.0330 - precision: 0.9914 - recall: 0.9955 \n",
            "Epoch 923/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8333 - loss: 0.0232 - precision: 0.9937 - recall: 0.9938 \n",
            "Epoch 924/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9920 - f1_score: 0.8244 - loss: 0.0204 - precision: 0.9954 - recall: 0.9917 \n",
            "Epoch 925/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9878 - f1_score: 0.8208 - loss: 0.0285 - precision: 0.9874 - recall: 0.9928 \n",
            "Epoch 926/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9871 - f1_score: 0.8222 - loss: 0.0301 - precision: 0.9864 - recall: 0.9928 \n",
            "Epoch 927/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9920 - f1_score: 0.8255 - loss: 0.0216 - precision: 0.9949 - recall: 0.9921 \n",
            "Epoch 928/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8305 - loss: 0.0296 - precision: 0.9922 - recall: 0.9916 \n",
            "Epoch 929/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9847 - f1_score: 0.8370 - loss: 0.0404 - precision: 0.9872 - recall: 0.9884 \n",
            "Epoch 930/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9917 - f1_score: 0.8263 - loss: 0.0194 - precision: 0.9917 - recall: 0.9949 \n",
            "Epoch 931/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8273 - loss: 0.0224 - precision: 0.9944 - recall: 0.9938 \n",
            "Epoch 932/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8315 - loss: 0.0271 - precision: 0.9901 - recall: 0.9928 \n",
            "Epoch 933/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9897 - f1_score: 0.8249 - loss: 0.0278 - precision: 0.9922 - recall: 0.9912 \n",
            "Epoch 934/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9741 - f1_score: 0.8215 - loss: 0.0642 - precision: 0.9807 - recall: 0.9770 \n",
            "Epoch 935/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8350 - loss: 0.0240 - precision: 0.9959 - recall: 0.9902 \n",
            "Epoch 936/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9884 - f1_score: 0.8268 - loss: 0.0338 - precision: 0.9902 - recall: 0.9908 \n",
            "Epoch 937/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9852 - f1_score: 0.8259 - loss: 0.0484 - precision: 0.9886 - recall: 0.9872 \n",
            "Epoch 938/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9937 - f1_score: 0.8202 - loss: 0.0260 - precision: 0.9945 - recall: 0.9951 \n",
            "Epoch 939/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9952 - f1_score: 0.8237 - loss: 0.0157 - precision: 0.9948 - recall: 0.9973 \n",
            "Epoch 940/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9923 - f1_score: 0.8270 - loss: 0.0199 - precision: 0.9947 - recall: 0.9929 \n",
            "Epoch 941/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9927 - f1_score: 0.8199 - loss: 0.0233 - precision: 0.9930 - recall: 0.9952 \n",
            "Epoch 942/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8404 - loss: 0.0242 - precision: 0.9936 - recall: 0.9932 \n",
            "Epoch 943/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9778 - f1_score: 0.8307 - loss: 0.0760 - precision: 0.9809 - recall: 0.9831 \n",
            "Epoch 944/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9910 - f1_score: 0.8155 - loss: 0.0247 - precision: 0.9945 - recall: 0.9907 \n",
            "Epoch 945/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9928 - f1_score: 0.8249 - loss: 0.0199 - precision: 0.9942 - recall: 0.9943 \n",
            "Epoch 946/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9937 - f1_score: 0.8232 - loss: 0.0202 - precision: 0.9939 - recall: 0.9960 \n",
            "Epoch 947/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9808 - f1_score: 0.8168 - loss: 0.0700 - precision: 0.9954 - recall: 0.9735 \n",
            "Epoch 948/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8220 - loss: 0.0233 - precision: 0.9927 - recall: 0.9938 \n",
            "Epoch 949/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9858 - f1_score: 0.8275 - loss: 0.0388 - precision: 0.9857 - recall: 0.9914 \n",
            "Epoch 950/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9941 - f1_score: 0.8338 - loss: 0.0216 - precision: 0.9956 - recall: 0.9950 \n",
            "Epoch 951/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9913 - f1_score: 0.8165 - loss: 0.0227 - precision: 0.9928 - recall: 0.9930 \n",
            "Epoch 952/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9720 - f1_score: 0.8245 - loss: 0.0850 - precision: 0.9658 - recall: 0.9900 \n",
            "Epoch 953/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9912 - f1_score: 0.8197 - loss: 0.0234 - precision: 0.9958 - recall: 0.9899 \n",
            "Epoch 954/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9921 - f1_score: 0.8246 - loss: 0.0206 - precision: 0.9935 - recall: 0.9937 \n",
            "Epoch 955/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9827 - f1_score: 0.8133 - loss: 0.0550 - precision: 0.9885 - recall: 0.9829 \n",
            "Epoch 956/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9946 - f1_score: 0.8238 - loss: 0.0153 - precision: 0.9967 - recall: 0.9945 \n",
            "Epoch 957/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9920 - f1_score: 0.8287 - loss: 0.0215 - precision: 0.9953 - recall: 0.9918 \n",
            "Epoch 958/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9935 - f1_score: 0.8269 - loss: 0.0205 - precision: 0.9960 - recall: 0.9936 \n",
            "Epoch 959/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9872 - f1_score: 0.8274 - loss: 0.0319 - precision: 0.9889 - recall: 0.9908 \n",
            "Epoch 960/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8333 - loss: 0.0314 - precision: 0.9883 - recall: 0.9916 \n",
            "Epoch 961/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9936 - f1_score: 0.8203 - loss: 0.0214 - precision: 0.9963 - recall: 0.9931 \n",
            "Epoch 962/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9874 - f1_score: 0.8276 - loss: 0.0322 - precision: 0.9928 - recall: 0.9864 \n",
            "Epoch 963/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9925 - f1_score: 0.8256 - loss: 0.0199 - precision: 0.9955 - recall: 0.9923\n",
            "Epoch 964/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9893 - f1_score: 0.8270 - loss: 0.0291 - precision: 0.9900 - recall: 0.9924\n",
            "Epoch 965/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9954 - f1_score: 0.8238 - loss: 0.0157 - precision: 0.9966 - recall: 0.9958\n",
            "Epoch 966/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9886 - f1_score: 0.8216 - loss: 0.0233 - precision: 0.9920 - recall: 0.9895\n",
            "Epoch 967/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9863 - f1_score: 0.8275 - loss: 0.0325 - precision: 0.9883 - recall: 0.9897\n",
            "Epoch 968/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9890 - f1_score: 0.8204 - loss: 0.0398 - precision: 0.9922 - recall: 0.9900\n",
            "Epoch 969/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9911 - f1_score: 0.8309 - loss: 0.0306 - precision: 0.9897 - recall: 0.9959\n",
            "Epoch 970/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9910 - f1_score: 0.8251 - loss: 0.0220 - precision: 0.9938 - recall: 0.9916\n",
            "Epoch 971/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9937 - f1_score: 0.8283 - loss: 0.0172 - precision: 0.9976 - recall: 0.9921 \n",
            "Epoch 972/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9863 - f1_score: 0.8240 - loss: 0.0302 - precision: 0.9932 - recall: 0.9846 \n",
            "Epoch 973/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9890 - f1_score: 0.8274 - loss: 0.0274 - precision: 0.9928 - recall: 0.9894 \n",
            "Epoch 974/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9917 - f1_score: 0.8228 - loss: 0.0256 - precision: 0.9959 - recall: 0.9906 \n",
            "Epoch 975/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9938 - f1_score: 0.8153 - loss: 0.0213 - precision: 0.9954 - recall: 0.9944 \n",
            "Epoch 976/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9935 - f1_score: 0.8290 - loss: 0.0257 - precision: 0.9953 - recall: 0.9941 \n",
            "Epoch 977/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9862 - f1_score: 0.8271 - loss: 0.0388 - precision: 0.9918 - recall: 0.9860 \n",
            "Epoch 978/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8305 - loss: 0.0252 - precision: 0.9928 - recall: 0.9901 \n",
            "Epoch 979/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9905 - f1_score: 0.8259 - loss: 0.0291 - precision: 0.9931 - recall: 0.9914\n",
            "Epoch 980/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9946 - f1_score: 0.8224 - loss: 0.0165 - precision: 0.9953 - recall: 0.9959 \n",
            "Epoch 981/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9894 - f1_score: 0.8222 - loss: 0.0316 - precision: 0.9909 - recall: 0.9918 \n",
            "Epoch 982/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9837 - f1_score: 0.8220 - loss: 0.0485 - precision: 0.9840 - recall: 0.9896 \n",
            "Epoch 983/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9926 - f1_score: 0.8203 - loss: 0.0201 - precision: 0.9961 - recall: 0.9918 \n",
            "Epoch 984/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9920 - f1_score: 0.8238 - loss: 0.0228 - precision: 0.9936 - recall: 0.9934 \n",
            "Epoch 985/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9909 - f1_score: 0.8313 - loss: 0.0258 - precision: 0.9924 - recall: 0.9930 \n",
            "Epoch 986/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9935 - f1_score: 0.8349 - loss: 0.0204 - precision: 0.9949 - recall: 0.9946 \n",
            "Epoch 987/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9920 - f1_score: 0.8208 - loss: 0.0226 - precision: 0.9944 - recall: 0.9926 \n",
            "Epoch 988/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9837 - f1_score: 0.8144 - loss: 0.0614 - precision: 0.9901 - recall: 0.9824 \n",
            "Epoch 989/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9873 - f1_score: 0.8269 - loss: 0.0269 - precision: 0.9908 - recall: 0.9887 \n",
            "Epoch 990/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9901 - f1_score: 0.8307 - loss: 0.0287 - precision: 0.9924 - recall: 0.9917 \n",
            "Epoch 991/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9903 - f1_score: 0.8157 - loss: 0.0305 - precision: 0.9931 - recall: 0.9909 \n",
            "Epoch 992/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9922 - f1_score: 0.8371 - loss: 0.0232 - precision: 0.9949 - recall: 0.9929 \n",
            "Epoch 993/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9940 - f1_score: 0.8253 - loss: 0.0155 - precision: 0.9942 - recall: 0.9961 \n",
            "Epoch 994/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9918 - f1_score: 0.8243 - loss: 0.0174 - precision: 0.9941 - recall: 0.9927 \n",
            "Epoch 995/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9908 - f1_score: 0.8229 - loss: 0.0229 - precision: 0.9923 - recall: 0.9928 \n",
            "Epoch 996/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9930 - f1_score: 0.8228 - loss: 0.0176 - precision: 0.9947 - recall: 0.9939\n",
            "Epoch 997/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9832 - f1_score: 0.8432 - loss: 0.0428 - precision: 0.9863 - recall: 0.9869 \n",
            "Epoch 998/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9936 - f1_score: 0.8392 - loss: 0.0198 - precision: 0.9945 - recall: 0.9952 \n",
            "Epoch 999/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9924 - f1_score: 0.8275 - loss: 0.0222 - precision: 0.9930 - recall: 0.9948 \n",
            "Epoch 1000/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9914 - f1_score: 0.8138 - loss: 0.0267 - precision: 0.9946 - recall: 0.9911 \n",
            "\n",
            "==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964ms/step - binary_accuracy: 0.8443 - f1_score: 0.8013 - loss: 1.5912 - precision: 0.8514 - recall: 0.9055\n",
            "Accuracy en Conjunto de Prueba: 0.8443\n",
            "Precision en Conjunto de Prueba: 0.8514\n",
            "Recall en Conjunto de Prueba: 0.9055\n",
            "F1-Score en Conjunto de Prueba: 0.8013\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Clase 0       0.83      0.75      0.79       303\n",
            "     Clase 1       0.85      0.91      0.88       487\n",
            "\n",
            "    accuracy                           0.84       790\n",
            "   macro avg       0.84      0.83      0.83       790\n",
            "weighted avg       0.84      0.84      0.84       790\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}