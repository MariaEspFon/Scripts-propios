{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaEspFon/Scripts-propios/blob/main/TensorFlow/CNN_model_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNAOn5Ia7pG"
      },
      "source": [
        "# OPTIMIZACIÓN DE HIPERPARÁMETROS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhxVlFL7j4N6"
      },
      "source": [
        "## 1. Inicialización de Keras y TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcFrOCQOYU1R",
        "outputId": "acf057e9-2ae0-4a0f-9ba6-8c72c70b3bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version:  2.18.0\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "#print(\"Keras version: \", tf.keras.__version__)\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtndO_D__Z2T"
      },
      "source": [
        "## 2. Carga de datos EDA desde Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niPo3Nfh-bVz",
        "outputId": "1b03722e-cef1-4f05-83a3-67d29529f91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset: (3949, 21)\n",
            "Recuento de instancias por clase:\n",
            "State\n",
            "1    2435\n",
            "0    1514\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/MariaEspFon/Scripts-propios/main/MATLAB/EDA_D7.2_EMA.csv'\n",
        "column_names = ['Mean','Median', 'Standard Dev', 'Max Value', 'Min Value', 'Standard Dev 1st diff', 'Median 1st diff', 'Standard Dev 2nd diff',\n",
        "                'Total Area', 'Kurtosis', 'SCR', 'Power', '99% Bandwidth', 'Top Bandwidth Frequency',\n",
        "                'Phasic mean', 'Phasic Stdev', 'Phasic AuC', 'Tonic mean', 'Tonic Stdev', 'Tonic AuC',\n",
        "                'State']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names, sep=',', skipinitialspace=True)\n",
        "\n",
        "size = raw_dataset.shape\n",
        "print(f'Formato del dataset: {size}')\n",
        "\n",
        "class_counts = raw_dataset['State'].value_counts()\n",
        "print(\"Recuento de instancias por clase:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WEvgfenf-pEf",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "e677a28f-e000-4bb7-aefe-a863ab215bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Mean    Median  Standard Dev  Max Value  Min Value  \\\n",
              "4466  1.466113  1.566922      1.261131   3.142194  -0.076818   \n",
              "4467  0.540481  0.034924      0.963236   3.007747  -0.231767   \n",
              "4468  2.449819  2.981136      1.047429   3.098601   0.061658   \n",
              "4469  2.944428  2.946765      0.031031   3.030734   2.796635   \n",
              "4470  2.840264  2.868869      0.263836   2.909742   0.000000   \n",
              "\n",
              "      Standard Dev 1st diff  Median 1st diff  Standard Dev 2nd diff  \\\n",
              "4466               0.183625         0.002763               0.093909   \n",
              "4467               0.171018         0.000410               0.068237   \n",
              "4468               0.102151         0.000678               0.043690   \n",
              "4469               0.014701        -0.000828               0.009593   \n",
              "4470               0.257542        -0.000595               0.258572   \n",
              "\n",
              "      Total Area    Kurtosis  ...        Power  99% Bandwidth  \\\n",
              "4466  174.826977    1.231085  ...   447.202123       0.517393   \n",
              "4467   63.761552    3.701841  ...   145.465354       0.969150   \n",
              "4468  292.429905    3.509624  ...   850.749576       0.402680   \n",
              "4469  350.382482   10.605559  ...  1040.473268       0.016502   \n",
              "4470  339.376835  113.812119  ...   976.335639       0.806445   \n",
              "\n",
              "      Top Bandwidth Frequency  Phasic mean  Phasic Stdev  Phasic AuC  \\\n",
              "4466                 0.517538     2.650141      3.726599   78.992107   \n",
              "4467                 0.969496     1.919576      2.938044   54.869583   \n",
              "4468                 0.402778     1.049711      1.670153   31.491325   \n",
              "4469                 0.016585     0.072713      0.296073    2.045646   \n",
              "4470                 0.806529     0.539952      1.058184   16.198553   \n",
              "\n",
              "      Tonic mean  Tonic Stdev   Tonic AuC  State  \n",
              "4466   -3.209107     1.263214  -95.019918      1  \n",
              "4467   -3.763126     1.339107 -111.580315      1  \n",
              "4468   -0.741003     1.967254  -21.775323      1  \n",
              "4469    1.257076     0.145131   37.424606      1  \n",
              "4470    0.802859     0.775748   23.916348      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943dd167-7b22-4994-b1a4-4fdfd511c5c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Standard Dev</th>\n",
              "      <th>Max Value</th>\n",
              "      <th>Min Value</th>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <th>Median 1st diff</th>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <th>Total Area</th>\n",
              "      <th>Kurtosis</th>\n",
              "      <th>...</th>\n",
              "      <th>Power</th>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <th>Phasic mean</th>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <th>Phasic AuC</th>\n",
              "      <th>Tonic mean</th>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <th>Tonic AuC</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>1.466113</td>\n",
              "      <td>1.566922</td>\n",
              "      <td>1.261131</td>\n",
              "      <td>3.142194</td>\n",
              "      <td>-0.076818</td>\n",
              "      <td>0.183625</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.093909</td>\n",
              "      <td>174.826977</td>\n",
              "      <td>1.231085</td>\n",
              "      <td>...</td>\n",
              "      <td>447.202123</td>\n",
              "      <td>0.517393</td>\n",
              "      <td>0.517538</td>\n",
              "      <td>2.650141</td>\n",
              "      <td>3.726599</td>\n",
              "      <td>78.992107</td>\n",
              "      <td>-3.209107</td>\n",
              "      <td>1.263214</td>\n",
              "      <td>-95.019918</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>0.540481</td>\n",
              "      <td>0.034924</td>\n",
              "      <td>0.963236</td>\n",
              "      <td>3.007747</td>\n",
              "      <td>-0.231767</td>\n",
              "      <td>0.171018</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.068237</td>\n",
              "      <td>63.761552</td>\n",
              "      <td>3.701841</td>\n",
              "      <td>...</td>\n",
              "      <td>145.465354</td>\n",
              "      <td>0.969150</td>\n",
              "      <td>0.969496</td>\n",
              "      <td>1.919576</td>\n",
              "      <td>2.938044</td>\n",
              "      <td>54.869583</td>\n",
              "      <td>-3.763126</td>\n",
              "      <td>1.339107</td>\n",
              "      <td>-111.580315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4468</th>\n",
              "      <td>2.449819</td>\n",
              "      <td>2.981136</td>\n",
              "      <td>1.047429</td>\n",
              "      <td>3.098601</td>\n",
              "      <td>0.061658</td>\n",
              "      <td>0.102151</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.043690</td>\n",
              "      <td>292.429905</td>\n",
              "      <td>3.509624</td>\n",
              "      <td>...</td>\n",
              "      <td>850.749576</td>\n",
              "      <td>0.402680</td>\n",
              "      <td>0.402778</td>\n",
              "      <td>1.049711</td>\n",
              "      <td>1.670153</td>\n",
              "      <td>31.491325</td>\n",
              "      <td>-0.741003</td>\n",
              "      <td>1.967254</td>\n",
              "      <td>-21.775323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4469</th>\n",
              "      <td>2.944428</td>\n",
              "      <td>2.946765</td>\n",
              "      <td>0.031031</td>\n",
              "      <td>3.030734</td>\n",
              "      <td>2.796635</td>\n",
              "      <td>0.014701</td>\n",
              "      <td>-0.000828</td>\n",
              "      <td>0.009593</td>\n",
              "      <td>350.382482</td>\n",
              "      <td>10.605559</td>\n",
              "      <td>...</td>\n",
              "      <td>1040.473268</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>0.016585</td>\n",
              "      <td>0.072713</td>\n",
              "      <td>0.296073</td>\n",
              "      <td>2.045646</td>\n",
              "      <td>1.257076</td>\n",
              "      <td>0.145131</td>\n",
              "      <td>37.424606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4470</th>\n",
              "      <td>2.840264</td>\n",
              "      <td>2.868869</td>\n",
              "      <td>0.263836</td>\n",
              "      <td>2.909742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257542</td>\n",
              "      <td>-0.000595</td>\n",
              "      <td>0.258572</td>\n",
              "      <td>339.376835</td>\n",
              "      <td>113.812119</td>\n",
              "      <td>...</td>\n",
              "      <td>976.335639</td>\n",
              "      <td>0.806445</td>\n",
              "      <td>0.806529</td>\n",
              "      <td>0.539952</td>\n",
              "      <td>1.058184</td>\n",
              "      <td>16.198553</td>\n",
              "      <td>0.802859</td>\n",
              "      <td>0.775748</td>\n",
              "      <td>23.916348</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943dd167-7b22-4994-b1a4-4fdfd511c5c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-943dd167-7b22-4994-b1a4-4fdfd511c5c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0acb679c-dbe1-4c1f-b807-16786b7ea1f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "raw_dataset.tail() # muestra las últimas 5 filas por defecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Cqjf_xnwpw"
      },
      "outputs": [],
      "source": [
        "raw_dataset.head() # muestra las primeras 5 filas por defecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9-FGkx3glzZ"
      },
      "source": [
        "## 3. Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBXjhOwa_eFh"
      },
      "source": [
        "### 3.1. Extracción de los conjuntos de entrenamiento, prueba y validación\n",
        "\n",
        "*   Datos de **entrenamiento**: para el aprendizaje de parámetros.\n",
        "*   Datos de **prueba**: para hacer test de predicciones.\n",
        "*   Datos de **validación**: para afinar hiperparámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wtq9cEZV_V-m"
      },
      "outputs": [],
      "source": [
        "# Extracción de subconjuntos: bloque de código para mantener la proporción de clases\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = raw_dataset.drop('State', axis=1)\n",
        "labels = raw_dataset['State']\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "FekCNTKP_WBI",
        "outputId": "09682f51-1a74-4f70-f181-cd281a3e698d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count         mean          std           min  \\\n",
              "Mean                     3159.0     1.461257     2.688161  2.881417e-04   \n",
              "Median                   3159.0     1.466649     2.710469  0.000000e+00   \n",
              "Standard Dev             3159.0     0.144952     0.381106  4.706701e-04   \n",
              "Max Value                3159.0     1.704078     2.942718  4.779257e-03   \n",
              "Min Value                3159.0     1.193842     2.469216  0.000000e+00   \n",
              "Standard Dev 1st diff    3159.0     0.022006     0.039530  3.494808e-04   \n",
              "Median 1st diff          3159.0    -0.000315     0.003921 -1.093078e-01   \n",
              "Standard Dev 2nd diff    3159.0     0.018383     0.029861  4.191872e-04   \n",
              "Total Area               3159.0   173.890366   319.923866  3.457700e-02   \n",
              "Kurtosis                 3159.0     5.549862     7.382169  1.057126e+00   \n",
              "SCR                      3159.0     1.063944     2.344673  0.000000e+00   \n",
              "Power                    3159.0  1142.881747  3839.609331  1.060477e-04   \n",
              "99% Bandwidth            3159.0     0.182056     0.350587  1.650002e-02   \n",
              "Top Bandwidth Frequency  3159.0     0.182157     0.350636  1.658335e-02   \n",
              "Phasic mean              3159.0     0.606996     1.303538  4.475971e-08   \n",
              "Phasic Stdev             3159.0     0.966032     1.883792  1.652074e-08   \n",
              "Phasic AuC               3159.0    18.063914    38.840793  1.331816e-06   \n",
              "Tonic mean               3159.0    -0.782682     1.836786 -2.952807e+01   \n",
              "Tonic Stdev              3159.0     0.433241     0.832538  1.055206e-04   \n",
              "Tonic AuC                3159.0   -23.288679    54.738380 -8.829021e+02   \n",
              "\n",
              "                               25%        50%         75%           max  \n",
              "Mean                      0.249013   0.433919    1.120415     16.873588  \n",
              "Median                    0.241514   0.431638    1.125672     17.060042  \n",
              "Standard Dev              0.005087   0.024107    0.121097      6.510492  \n",
              "Max Value                 0.293813   0.496918    1.504204     17.572616  \n",
              "Min Value                 0.140055   0.314706    0.660940     16.098618  \n",
              "Standard Dev 1st diff     0.001248   0.005013    0.023161      0.471897  \n",
              "Median 1st diff          -0.000351  -0.000024    0.000155      0.048991  \n",
              "Standard Dev 2nd diff     0.001694   0.004379    0.020992      0.258629  \n",
              "Total Area               29.601951  51.637832  133.571556   2013.300593  \n",
              "Kurtosis                  2.075404   2.857487    5.505709    113.896441  \n",
              "SCR                       0.000000   0.000000    1.000000     24.000000  \n",
              "Power                     7.913682  23.449923  171.273761  34363.988284  \n",
              "99% Bandwidth             0.016504   0.016529    0.167778      1.982856  \n",
              "Top Bandwidth Frequency   0.016587   0.016612    0.167895      1.983451  \n",
              "Phasic mean               0.018716   0.101285    0.523234     21.397006  \n",
              "Phasic Stdev              0.053579   0.223113    0.967546     35.095213  \n",
              "Phasic AuC                0.551897   2.997145   15.523808    638.941089  \n",
              "Tonic mean               -1.153674  -0.500970    0.136751      3.422684  \n",
              "Tonic Stdev               0.027316   0.098597    0.515756     16.795811  \n",
              "Tonic AuC               -34.324767 -14.913256    4.080784    101.863348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54766887-95a9-448f-ad6e-660ab0190d36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.461257</td>\n",
              "      <td>2.688161</td>\n",
              "      <td>2.881417e-04</td>\n",
              "      <td>0.249013</td>\n",
              "      <td>0.433919</td>\n",
              "      <td>1.120415</td>\n",
              "      <td>16.873588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.466649</td>\n",
              "      <td>2.710469</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.241514</td>\n",
              "      <td>0.431638</td>\n",
              "      <td>1.125672</td>\n",
              "      <td>17.060042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.144952</td>\n",
              "      <td>0.381106</td>\n",
              "      <td>4.706701e-04</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.024107</td>\n",
              "      <td>0.121097</td>\n",
              "      <td>6.510492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.704078</td>\n",
              "      <td>2.942718</td>\n",
              "      <td>4.779257e-03</td>\n",
              "      <td>0.293813</td>\n",
              "      <td>0.496918</td>\n",
              "      <td>1.504204</td>\n",
              "      <td>17.572616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.193842</td>\n",
              "      <td>2.469216</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.314706</td>\n",
              "      <td>0.660940</td>\n",
              "      <td>16.098618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.022006</td>\n",
              "      <td>0.039530</td>\n",
              "      <td>3.494808e-04</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0.023161</td>\n",
              "      <td>0.471897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>-1.093078e-01</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.048991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>0.029861</td>\n",
              "      <td>4.191872e-04</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.258629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>173.890366</td>\n",
              "      <td>319.923866</td>\n",
              "      <td>3.457700e-02</td>\n",
              "      <td>29.601951</td>\n",
              "      <td>51.637832</td>\n",
              "      <td>133.571556</td>\n",
              "      <td>2013.300593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.549862</td>\n",
              "      <td>7.382169</td>\n",
              "      <td>1.057126e+00</td>\n",
              "      <td>2.075404</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>5.505709</td>\n",
              "      <td>113.896441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.063944</td>\n",
              "      <td>2.344673</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1142.881747</td>\n",
              "      <td>3839.609331</td>\n",
              "      <td>1.060477e-04</td>\n",
              "      <td>7.913682</td>\n",
              "      <td>23.449923</td>\n",
              "      <td>171.273761</td>\n",
              "      <td>34363.988284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182056</td>\n",
              "      <td>0.350587</td>\n",
              "      <td>1.650002e-02</td>\n",
              "      <td>0.016504</td>\n",
              "      <td>0.016529</td>\n",
              "      <td>0.167778</td>\n",
              "      <td>1.982856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.182157</td>\n",
              "      <td>0.350636</td>\n",
              "      <td>1.658335e-02</td>\n",
              "      <td>0.016587</td>\n",
              "      <td>0.016612</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>1.983451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.606996</td>\n",
              "      <td>1.303538</td>\n",
              "      <td>4.475971e-08</td>\n",
              "      <td>0.018716</td>\n",
              "      <td>0.101285</td>\n",
              "      <td>0.523234</td>\n",
              "      <td>21.397006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.966032</td>\n",
              "      <td>1.883792</td>\n",
              "      <td>1.652074e-08</td>\n",
              "      <td>0.053579</td>\n",
              "      <td>0.223113</td>\n",
              "      <td>0.967546</td>\n",
              "      <td>35.095213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>18.063914</td>\n",
              "      <td>38.840793</td>\n",
              "      <td>1.331816e-06</td>\n",
              "      <td>0.551897</td>\n",
              "      <td>2.997145</td>\n",
              "      <td>15.523808</td>\n",
              "      <td>638.941089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-0.782682</td>\n",
              "      <td>1.836786</td>\n",
              "      <td>-2.952807e+01</td>\n",
              "      <td>-1.153674</td>\n",
              "      <td>-0.500970</td>\n",
              "      <td>0.136751</td>\n",
              "      <td>3.422684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.832538</td>\n",
              "      <td>1.055206e-04</td>\n",
              "      <td>0.027316</td>\n",
              "      <td>0.098597</td>\n",
              "      <td>0.515756</td>\n",
              "      <td>16.795811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-23.288679</td>\n",
              "      <td>54.738380</td>\n",
              "      <td>-8.829021e+02</td>\n",
              "      <td>-34.324767</td>\n",
              "      <td>-14.913256</td>\n",
              "      <td>4.080784</td>\n",
              "      <td>101.863348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54766887-95a9-448f-ad6e-660ab0190d36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54766887-95a9-448f-ad6e-660ab0190d36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54766887-95a9-448f-ad6e-660ab0190d36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd393285-f86e-4ff1-bb82-c765697b3ec7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd393285-f86e-4ff1-bb82-c765697b3ec7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd393285-f86e-4ff1-bb82-c765697b3ec7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_730b46e6-01a3-4557-ae20-91004d509104\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_730b46e6-01a3-4557-ae20-91004d509104 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_stats",
              "summary": "{\n  \"name\": \"train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256.43774243066844,\n        \"min\": -23.288679302492756,\n        \"max\": 1142.8817465910665,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.4612569864023432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856.3494010607636,\n        \"min\": 0.003920865966528552,\n        \"max\": 3839.6093312957755,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.688160769255659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.1982611498348,\n        \"min\": -882.902109713819,\n        \"max\": 1.05712563449178,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0002881416666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.567138491113965,\n        \"min\": -34.3247668007665,\n        \"max\": 29.601950522781898,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.24901303990454848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.034024453837553,\n        \"min\": -14.9132560124876,\n        \"max\": 51.6378323985219,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.43391925352509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.88127532395101,\n        \"min\": 0.000155043576272,\n        \"max\": 171.27376076324,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.120414963183705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7661.905667264518,\n        \"min\": 0.0489910736836237,\n        \"max\": 34363.988283576,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          16.873587916458\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_size = train_dataset.shape\n",
        "test_size = test_dataset.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syU3bAgjhaZb"
      },
      "source": [
        "### 3.2. Normalización y estandarización de todos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "V6-D516VCSUe",
        "outputId": "f430732b-7407-4cac-d87c-6ce0e3128f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato del dataset de training: (3159, 20)\n",
            "Formato del dataset de test: (790, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count          mean  std        min       25%  \\\n",
              "Mean                     3159.0  8.997059e-18  1.0  -0.543483 -0.450957   \n",
              "Median                   3159.0 -1.462022e-17  1.0  -0.541105 -0.452001   \n",
              "Standard Dev             3159.0  6.410405e-17  1.0  -0.379110 -0.366997   \n",
              "Max Value                3159.0 -3.261434e-17  1.0  -0.577459 -0.479239   \n",
              "Min Value                3159.0  1.349559e-17  1.0  -0.483490 -0.426770   \n",
              "Standard Dev 1st diff    3159.0  8.997059e-17  1.0  -0.547850 -0.525124   \n",
              "Median 1st diff          3159.0  8.997059e-18  1.0 -27.798013 -0.008976   \n",
              "Standard Dev 2nd diff    3159.0  1.012169e-16  1.0  -0.601592 -0.558901   \n",
              "Total Area               3159.0 -1.135879e-16  1.0  -0.543429 -0.451009   \n",
              "Kurtosis                 3159.0 -5.848088e-17  1.0  -0.608593 -0.470655   \n",
              "SCR                      3159.0 -3.036507e-17  1.0  -0.453771 -0.453771   \n",
              "Power                    3159.0 -2.249265e-17  1.0  -0.297656 -0.295595   \n",
              "99% Bandwidth            3159.0 -2.474191e-17  1.0  -0.472226 -0.472214   \n",
              "Top Bandwidth Frequency  3159.0 -6.185478e-18  1.0  -0.472211 -0.472199   \n",
              "Phasic mean              3159.0 -2.305496e-17  1.0  -0.465652 -0.451294   \n",
              "Phasic Stdev             3159.0  5.623162e-19  1.0  -0.512813 -0.484370   \n",
              "Phasic AuC               3159.0 -1.433906e-17  1.0  -0.465076 -0.450867   \n",
              "Tonic mean               3159.0 -5.117077e-17  1.0 -15.649830 -0.201979   \n",
              "Tonic Stdev              3159.0  2.924044e-17  1.0  -0.520259 -0.487576   \n",
              "Tonic AuC                3159.0 -6.579099e-17  1.0 -15.704035 -0.201615   \n",
              "\n",
              "                              50%       75%        max  \n",
              "Mean                    -0.382171 -0.126794   5.733411  \n",
              "Median                  -0.381857 -0.125800   5.753023  \n",
              "Standard Dev            -0.317089 -0.062595  16.702809  \n",
              "Max Value               -0.410220 -0.067921   5.392477  \n",
              "Min Value               -0.356038 -0.215818   6.036239  \n",
              "Standard Dev 1st diff   -0.429885  0.029211  11.380875  \n",
              "Median 1st diff          0.074262  0.120010  12.575429  \n",
              "Standard Dev 2nd diff   -0.468976  0.087356   8.045450  \n",
              "Total Area              -0.382130 -0.126026   5.749525  \n",
              "Kurtosis                -0.364713 -0.005981  14.676795  \n",
              "SCR                     -0.453771 -0.027272   9.782197  \n",
              "Power                   -0.291548 -0.253049   8.652210  \n",
              "99% Bandwidth           -0.472143 -0.040728   5.136521  \n",
              "Top Bandwidth Frequency -0.472128 -0.040677   5.137217  \n",
              "Phasic mean             -0.387952 -0.064257  15.948907  \n",
              "Phasic Stdev            -0.394374  0.000804  18.117274  \n",
              "Phasic AuC              -0.387911 -0.065398  15.985183  \n",
              "Tonic mean               0.153372  0.500566   2.289524  \n",
              "Tonic Stdev             -0.401957  0.099112  19.653834  \n",
              "Tonic AuC                0.153008  0.500005   2.286367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-838cdbd4-1e95-44d2-a294-2a0236fd0634\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543483</td>\n",
              "      <td>-0.450957</td>\n",
              "      <td>-0.382171</td>\n",
              "      <td>-0.126794</td>\n",
              "      <td>5.733411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.462022e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.541105</td>\n",
              "      <td>-0.452001</td>\n",
              "      <td>-0.381857</td>\n",
              "      <td>-0.125800</td>\n",
              "      <td>5.753023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>6.410405e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.379110</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-0.317089</td>\n",
              "      <td>-0.062595</td>\n",
              "      <td>16.702809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.261434e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.577459</td>\n",
              "      <td>-0.479239</td>\n",
              "      <td>-0.410220</td>\n",
              "      <td>-0.067921</td>\n",
              "      <td>5.392477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min Value</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.349559e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.483490</td>\n",
              "      <td>-0.426770</td>\n",
              "      <td>-0.356038</td>\n",
              "      <td>-0.215818</td>\n",
              "      <td>6.036239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.547850</td>\n",
              "      <td>-0.525124</td>\n",
              "      <td>-0.429885</td>\n",
              "      <td>0.029211</td>\n",
              "      <td>11.380875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median 1st diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>8.997059e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-27.798013</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.074262</td>\n",
              "      <td>0.120010</td>\n",
              "      <td>12.575429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Dev 2nd diff</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>1.012169e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.601592</td>\n",
              "      <td>-0.558901</td>\n",
              "      <td>-0.468976</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>8.045450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Area</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.135879e-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.543429</td>\n",
              "      <td>-0.451009</td>\n",
              "      <td>-0.382130</td>\n",
              "      <td>-0.126026</td>\n",
              "      <td>5.749525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.848088e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.608593</td>\n",
              "      <td>-0.470655</td>\n",
              "      <td>-0.364713</td>\n",
              "      <td>-0.005981</td>\n",
              "      <td>14.676795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCR</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-3.036507e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.453771</td>\n",
              "      <td>-0.027272</td>\n",
              "      <td>9.782197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Power</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.249265e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.297656</td>\n",
              "      <td>-0.295595</td>\n",
              "      <td>-0.291548</td>\n",
              "      <td>-0.253049</td>\n",
              "      <td>8.652210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99% Bandwidth</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.474191e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472226</td>\n",
              "      <td>-0.472214</td>\n",
              "      <td>-0.472143</td>\n",
              "      <td>-0.040728</td>\n",
              "      <td>5.136521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top Bandwidth Frequency</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.185478e-18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.472211</td>\n",
              "      <td>-0.472199</td>\n",
              "      <td>-0.472128</td>\n",
              "      <td>-0.040677</td>\n",
              "      <td>5.137217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-2.305496e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465652</td>\n",
              "      <td>-0.451294</td>\n",
              "      <td>-0.387952</td>\n",
              "      <td>-0.064257</td>\n",
              "      <td>15.948907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>5.623162e-19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.512813</td>\n",
              "      <td>-0.484370</td>\n",
              "      <td>-0.394374</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>18.117274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phasic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-1.433906e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.465076</td>\n",
              "      <td>-0.450867</td>\n",
              "      <td>-0.387911</td>\n",
              "      <td>-0.065398</td>\n",
              "      <td>15.985183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic mean</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-5.117077e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.649830</td>\n",
              "      <td>-0.201979</td>\n",
              "      <td>0.153372</td>\n",
              "      <td>0.500566</td>\n",
              "      <td>2.289524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic Stdev</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>2.924044e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.520259</td>\n",
              "      <td>-0.487576</td>\n",
              "      <td>-0.401957</td>\n",
              "      <td>0.099112</td>\n",
              "      <td>19.653834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tonic AuC</th>\n",
              "      <td>3159.0</td>\n",
              "      <td>-6.579099e-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-15.704035</td>\n",
              "      <td>-0.201615</td>\n",
              "      <td>0.153008</td>\n",
              "      <td>0.500005</td>\n",
              "      <td>2.286367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-838cdbd4-1e95-44d2-a294-2a0236fd0634')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-838cdbd4-1e95-44d2-a294-2a0236fd0634 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-838cdbd4-1e95-44d2-a294-2a0236fd0634');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea659d04-aea8-46ba-9d43-4426b2d68eb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea659d04-aea8-46ba-9d43-4426b2d68eb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea659d04-aea8-46ba-9d43-4426b2d68eb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_36d66e30-e516-4600-a7ed-e12014f32296\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('normed_train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_36d66e30-e516-4600-a7ed-e12014f32296 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('normed_train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "normed_train_stats",
              "summary": "{\n  \"name\": \"normed_train_stats\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3159.0,\n        \"max\": 3159.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3159.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.130827903032307e-17,\n        \"min\": -1.13587870072444e-16,\n        \"max\": 1.012169139259402e-16,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          8.997059015639129e-18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1848847376991577e-14,\n        \"min\": 0.9999999999999469,\n        \"max\": 1.000000000000002,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.9999999999999469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.397919147016072,\n        \"min\": -27.798013059723413,\n        \"max\": -0.2976557097171227,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.5434826895194267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13303447554408515,\n        \"min\": -0.5589012867384386,\n        \"max\": -0.008976423627184933,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.4509566393357717\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1982775721363611,\n        \"min\": -0.47214325593943735,\n        \"max\": 0.15337222439091985,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.3821712393941821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19358796580988194,\n        \"min\": -0.2530486572965829,\n        \"max\": 0.500566267762931,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.12679376438970055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.4656321224551565,\n        \"min\": 2.2863670387300563,\n        \"max\": 19.653834404298966,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          5.733411150971922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "train_size = normed_train_data.shape\n",
        "test_size = normed_test_data.shape\n",
        "print(f'Formato del dataset de training: {train_size}')\n",
        "print(f'Formato del dataset de test: {test_size}')\n",
        "\n",
        "normed_train_stats = normed_train_data.describe()\n",
        "normed_train_stats = normed_train_stats.transpose()\n",
        "normed_train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmNpCfOqCwqv"
      },
      "source": [
        "## 4.1. Optimización masiva de parámetros\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_conv_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(hp.Int('hidden_blocks', min_value=1, max_value=4)):\n",
        "        filters = hp.Int(f'n_filters{i}', min_value=4, max_value=32, step=4)\n",
        "        kernel_size = hp.Choice(f'size{i}', values=[2, 3, 4, 5])\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))  # Valor fijo para la etapa 1\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_conv_model(HyperParameters())\n",
        "\n",
        "tuner_1 = kt.BayesianOptimization(\n",
        "    build_conv_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage1',\n",
        "    project_name='cnn1d_conv_structure'\n",
        ")\n",
        "\n",
        "#28min 30s sin GPU"
      ],
      "metadata": {
        "id": "U_quo4A8uaj8",
        "outputId": "132e90ed-e37a-4eb8-fc64-143a289d0106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_1.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
        "\n",
        "best_hp1 = tuner_1.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp1.values"
      ],
      "metadata": {
        "id": "xgJLDUbVGQrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(best_hp1.get('hidden_blocks')):\n",
        "        filters = best_hp1.get(f'n_filters{i}')\n",
        "        kernel_size = best_hp1.get(f'size{i}')\n",
        "        if i == 0:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu', input_shape=(train_size[1],1)))\n",
        "        else:\n",
        "            model.add(layers.Conv1D(filters, kernel_size, padding='same',\n",
        "                                    activation='relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Aquí ajustamos solo los parámetros nuevos\n",
        "    dense_units = hp.Int('dense_units', min_value=16, max_value=128, step=8)\n",
        "    lr = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    model.add(layers.Dense(dense_units, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "    return model\n",
        "\n",
        "model = build_final_model(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner_2 = kt.BayesianOptimization(\n",
        "    build_final_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory='tuning_stage2',\n",
        "    project_name='cnn1d_dense_lr_batch'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "6DnGkCSIvH_h",
        "outputId": "0763117c-93aa-4313-ec4e-78ae6573516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │         \u001b[38;5;34m1,372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │           \u001b[38;5;34m112\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m5,136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_48          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,101\u001b[0m (35.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,101</span> (35.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,981\u001b[0m (35.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,981</span> (35.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage2/cnn1d_dense_lr_batch/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_2.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
        "                    batch_size=kt.HyperParameters().Choice('batch_size', [128, 358, 537]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okut5Zt2GmPF",
        "outputId": "b6224996-120f-40e7-8d9a-2c09ada59879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 01m 13s]\n",
            "val_binary_accuracy: 0.7332402169704437\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7618715167045593\n",
            "Total elapsed time: 01h 42m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp2 = tuner_2.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp2.values"
      ],
      "metadata": {
        "id": "w1IQLia14ibr",
        "outputId": "ee370ad5-4952-4a00-b0e0-2451b05df689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_units': 40, 'learning_rate': 0.0004578995948758916}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNb7pcumf33T"
      },
      "source": [
        "## 4.2. Optimización de hiperparámetros del mejor modelo conseguido"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_model_C1(hp):\n",
        "  model = Sequential()\n",
        "  filters1 = hp.Int('nfilters1', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters1, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters2 = hp.Int('nfilters2', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters2, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  filters3 = hp.Int('nfilters3', min_value=4, max_value=64, step=4)\n",
        "  model.add(layers.Conv1D(filters3, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Flatten())\n",
        "  dense_units = hp.Int('dense_units', min_value=16, max_value=64, step=4)\n",
        "  model.add(layers.Dense(dense_units, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "   # compilación del modelo\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['binary_accuracy','precision','recall',keras.metrics.F1Score()])\n",
        "  return model\n",
        "\n",
        "model = build_model_C1(HyperParameters())\n",
        "model.summary()\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model_C1,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=100,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuning_stage',\n",
        "    project_name='TFG'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "KHuAnr0MfWC7",
        "outputId": "059a5330-06b0-449b-c789-7868f4b36636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m52\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │            \u001b[38;5;34m16\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,477\u001b[0m (5.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,477</span> (5.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,453\u001b[0m (5.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,453</span> (5.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from tuning_stage/TFG/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(normed_train_data, train_labels,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1T1WwGjonc",
        "outputId": "e77238f5-1c17-4c36-82ce-f681bd90a235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 27s]\n",
            "val_binary_accuracy: 0.7667597532272339\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7891061305999756\n",
            "Total elapsed time: 01h 01m 48s\n",
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nfilters1': 64, 'nfilters2': 52, 'nfilters3': 56, 'dense_units': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Optimización bayesiana con validación cruzada\n",
        "\n",
        "Mercedes no utilizó validación cruzada; realmente no parece que haga falta porque el dataset no es tan pequeño (supera las 1000 muestras)\n",
        "ESTÁ INCOMPLETO"
      ],
      "metadata": {
        "id": "rjQqaNgvECTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Asegúrate de tener normed_train_data, train_labels definidos antes de esto\n",
        "\n",
        "# Añadir dimensión para Conv1D\n",
        "#X = np.expand_dims(normed_train_data.values, axis=2)\n",
        "#y = train_labels.values\n",
        "\n",
        "# Función de construcción del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1],1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score()])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BD55-165EBGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación cruzada estratificada\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds_acc = []\n",
        "folds_precission = []\n",
        "folds_recall = []\n",
        "folds_f1 = []\n",
        "\n",
        "best_hyperparams = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(normed_train_data, train_labels)):\n",
        "    print(f'\\n🔁 Fold {fold+1}')\n",
        "\n",
        "    tuner = kt.BayesianOptimization(\n",
        "        build_model,\n",
        "        objective='val_binary_accuracy',\n",
        "        max_trials=10, #100\n",
        "        directory='bayes_cv',\n",
        "        project_name=f'fold_{fold}',\n",
        "        overwrite=True\n",
        "    )\n",
        "\n",
        "    X_train, X_val = normed_train_data.iloc[train_index], normed_train_data.iloc[val_index]\n",
        "    y_train, y_val = train_labels.iloc[train_index], train_labels.iloc[val_index]\n",
        "\n",
        "    tuner.search(X_train, y_train,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                 epochs=200, # 50 o 500 (uno más bajo y otro más alto, estudair el tiempo de ejecución a grandes rasgos)\n",
        "                 batch_size=ceil(len(train_index) * 0.1),\n",
        "                 verbose=1)\n",
        "\n",
        "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "    print(\"✅ Mejor optimizador:\", best_hp.get('optimizer'))\n",
        "    print(\"✅ Mejor tasa de aprendizaje:\", best_hp.get('learning_rate'))\n",
        "    best_hyperparams.append(best_hp)\n",
        "\n",
        "# Resultados promedio de los folds\n",
        "print(\"\\n📈 Accuracy promedio en validación cruzada:\", np.mean(folds_acc))\n"
      ],
      "metadata": {
        "id": "Lpoe_h8jIJ65",
        "outputId": "b9660e98-4719-4f2b-8756-f2350da1643b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 00s]\n",
            "val_binary_accuracy: 0.8415213823318481\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.8494453430175781\n",
            "Total elapsed time: 00h 09m 23s\n",
            "✅ Mejor optimizador: nadam\n",
            "✅ Mejor tasa de aprendizaje: 0.003939762513244005\n",
            "\n",
            "📈 Accuracy promedio en validación cruzada: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para construir el modelo con hiperparámetros\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(train_size[1], 1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Hiperparámetros a optimizar\n",
        "    hp_optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')\n",
        "\n",
        "    if hp_optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=hp_learning_rate)\n",
        "    elif hp_optimizer == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=hp_learning_rate)\n",
        "    else:\n",
        "        optimizer = Nadam(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', keras.metrics.F1Score()])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Inicializa la búsqueda bayesiana\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy',\n",
        "    max_trials=15,  # Número de combinaciones a probar\n",
        "    directory='bayesian_opt',\n",
        "    project_name='cnn_lr_opt'\n",
        ")\n",
        "\n",
        "# Divide entrenamiento en train/validation\n",
        "tuner.search(normed_train_data, train_labels.values,\n",
        "             epochs=100,\n",
        "             validation_split=0.2,\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             verbose=0)\n",
        "\n",
        "# Muestra los mejores resultados\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejor optimizador: {best_hps.get('optimizer')}\")\n",
        "print(f\"Mejor learning rate: {best_hps.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "id": "FeVUuw1YlV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Gemini sugiere:"
      ],
      "metadata": {
        "id": "-pjdu1IsCHBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación simple"
      ],
      "metadata": {
        "id": "57WFLZh_C0k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers, activations\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from keras_tuner import HyperParameters\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "\n",
        "# Función de construcción del modelo (tu arquitectura original)\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Asegúrate de que input_shape es correcto para tus datos después de expand_dims\n",
        "    model.add(layers.Conv1D(27, 2, strides=1, padding='same', activation='relu', input_shape=(normed_train_data.shape[1], 1)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(22, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv1D(18, 3, padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(22, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Hiperparámetros a optimizar\n",
        "    hp_opt = hp.Choice('optimizer', ['adam', 'rmsprop', 'nadam'])\n",
        "    hp_lr = hp.Float('learning_rate', 1e-5, 1e-2, sampling='log')\n",
        "\n",
        "    if hp_opt == 'adam':\n",
        "        opt = Adam(learning_rate=hp_lr)\n",
        "    elif hp_opt == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=hp_lr)\n",
        "    else:\n",
        "        opt = Nadam(learning_rate=hp_lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'precision', 'recall', tf.keras.metrics.F1Score(name='f1_score')])\n",
        "    return model\n",
        "\n",
        "print(\"\\n==================== 📈 Optimización de Hiperparámetros (Validación Simple) ====================\")\n",
        "\n",
        "# 2. Configurar e iniciar Keras Tuner para la optimización de hiperparámetros\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_binary_accuracy', # El objetivo del tuner es la precisión de validación\n",
        "    max_trials=20, # Número de combinaciones de HP a probar\n",
        "    directory='keras_tuner_results',\n",
        "    project_name='simple_split_optimization',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Callback para Early Stopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15, # Número de épocas sin mejora\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"Iniciando la búsqueda de hiperparámetros...\")\n",
        "tuner.search(normed_train_data, train_labels,\n",
        "             validation_split=0.2,\n",
        "             epochs=500, # Max. épocas, early stopping lo detendrá\n",
        "             batch_size=ceil(train_size[0]*0.1),\n",
        "             callbacks=[early_stopping_callback],\n",
        "             verbose=1) # Poner en 1 para ver el progreso detallado\n",
        "\n",
        "# 3. Obtener los mejores hiperparámetros encontrados\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"✅ Mejores Hiperparámetros Encontrados:\")\n",
        "print(f\"  Optimizador: {best_hp.get('optimizer')}\")\n",
        "print(f\"  Tasa de Aprendizaje: {best_hp.get('learning_rate'):.1e}\")\n",
        "\n",
        "# 4. Construir y entrenar el modelo final con los mejores HP en todo el conjunto de entrenamiento+validación\n",
        "print(\"\\nEntrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento+validación...\")\n",
        "final_model = tuner.hypermodel.build(best_hp)\n",
        "final_model.fit(normed_train_data, train_labels,\n",
        "                epochs=500,\n",
        "                batch_size=ceil(train_size[0]*0.1),\n",
        "                callbacks=[early_stopping_callback],\n",
        "                verbose=1) # Poner en 1 para ver el progreso del entrenamiento final\n",
        "\n",
        "# 5. Evaluar el modelo final en el conjunto de prueba independiente\n",
        "print(\"\\n==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\")\n",
        "y_pred_probs = final_model.predict(normed_test_data).ravel()\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Calcular métricas finales\n",
        "acc = accuracy_score(test_labels, y_pred)\n",
        "prec = precision_score(test_labels, y_pred)\n",
        "rec = recall_score(test_labels, y_pred)\n",
        "f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "print(f\"Accuracy en Conjunto de Prueba: {acc:.4f}\")\n",
        "print(f\"Precision en Conjunto de Prueba: {prec:.4f}\")\n",
        "print(f\"Recall en Conjunto de Prueba: {rec:.4f}\")\n",
        "print(f\"F1-Score en Conjunto de Prueba: {f1:.4f}\")\n",
        "print(\"\\nReporte de Clasificación:\\n\", classification_report(test_labels, y_pred))\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "cm = tf.math.confusion_matrix(labels=test_labels, predictions=y_pred).numpy()\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "71xl8jrVCGGk",
        "outputId": "6492a8b8-bf49-4da9-ad12-e0d218fb6048"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 41s]\n",
            "val_binary_accuracy: 0.7721518874168396\n",
            "\n",
            "Best val_binary_accuracy So Far: 0.7848101258277893\n",
            "Total elapsed time: 00h 10m 56s\n",
            "✅ Mejores Hiperparámetros Encontrados:\n",
            "  Optimizador: nadam\n",
            "  Tasa de Aprendizaje: 7.2e-04\n",
            "\n",
            "Entrenando el modelo final con los mejores hiperparámetros en el conjunto de entrenamiento+validación...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - binary_accuracy: 0.5656 - f1_score: 0.7641 - loss: 0.6838 - precision: 0.6409 - recall: 0.6878\n",
            "Epoch 2/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: binary_accuracy,f1_score,loss,precision,recall\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6477 - f1_score: 0.7600 - loss: 0.6293 - precision: 0.6506 - recall: 0.9190  \n",
            "Epoch 3/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6594 - f1_score: 0.7524 - loss: 0.6180 - precision: 0.6575 - recall: 0.9092 \n",
            "Epoch 4/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6852 - f1_score: 0.7652 - loss: 0.5900 - precision: 0.6792 - recall: 0.9318 \n",
            "Epoch 5/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6952 - f1_score: 0.7602 - loss: 0.5804 - precision: 0.6922 - recall: 0.9059 \n",
            "Epoch 6/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.6975 - f1_score: 0.7563 - loss: 0.5785 - precision: 0.6968 - recall: 0.8905 \n",
            "Epoch 7/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.6985 - f1_score: 0.7629 - loss: 0.5709 - precision: 0.6985 - recall: 0.8998 \n",
            "Epoch 8/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7144 - f1_score: 0.7645 - loss: 0.5525 - precision: 0.7153 - recall: 0.8942 \n",
            "Epoch 9/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7309 - f1_score: 0.7674 - loss: 0.5474 - precision: 0.7250 - recall: 0.9150 \n",
            "Epoch 10/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7342 - f1_score: 0.7646 - loss: 0.5375 - precision: 0.7448 - recall: 0.8685 \n",
            "Epoch 11/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7286 - f1_score: 0.7532 - loss: 0.5368 - precision: 0.7333 - recall: 0.8663 \n",
            "Epoch 12/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7423 - f1_score: 0.7672 - loss: 0.5215 - precision: 0.7416 - recall: 0.8992 \n",
            "Epoch 13/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7492 - f1_score: 0.7654 - loss: 0.5168 - precision: 0.7492 - recall: 0.8950 \n",
            "Epoch 14/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7579 - f1_score: 0.7607 - loss: 0.5035 - precision: 0.7658 - recall: 0.8727 \n",
            "Epoch 15/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7542 - f1_score: 0.7645 - loss: 0.5097 - precision: 0.7525 - recall: 0.8984 \n",
            "Epoch 16/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7672 - f1_score: 0.7696 - loss: 0.4980 - precision: 0.7730 - recall: 0.8892 \n",
            "Epoch 17/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7617 - f1_score: 0.7567 - loss: 0.5007 - precision: 0.7635 - recall: 0.8816 \n",
            "Epoch 18/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7641 - f1_score: 0.7557 - loss: 0.4907 - precision: 0.7686 - recall: 0.8755 \n",
            "Epoch 19/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7680 - f1_score: 0.7741 - loss: 0.4828 - precision: 0.7632 - recall: 0.9171 \n",
            "Epoch 20/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7719 - f1_score: 0.7615 - loss: 0.4834 - precision: 0.7861 - recall: 0.8642 \n",
            "Epoch 21/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7675 - f1_score: 0.7654 - loss: 0.4810 - precision: 0.7793 - recall: 0.8718 \n",
            "Epoch 22/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7699 - f1_score: 0.7745 - loss: 0.4738 - precision: 0.7803 - recall: 0.8855 \n",
            "Epoch 23/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7755 - f1_score: 0.7637 - loss: 0.4664 - precision: 0.7866 - recall: 0.8734 \n",
            "Epoch 24/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7748 - f1_score: 0.7526 - loss: 0.4667 - precision: 0.7787 - recall: 0.8752 \n",
            "Epoch 25/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7852 - f1_score: 0.7626 - loss: 0.4512 - precision: 0.7824 - recall: 0.9029 \n",
            "Epoch 26/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7934 - f1_score: 0.7674 - loss: 0.4406 - precision: 0.7975 - recall: 0.8955 \n",
            "Epoch 27/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7937 - f1_score: 0.7670 - loss: 0.4429 - precision: 0.8043 - recall: 0.8834 \n",
            "Epoch 28/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7815 - f1_score: 0.7583 - loss: 0.4513 - precision: 0.7923 - recall: 0.8701 \n",
            "Epoch 29/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8113 - f1_score: 0.7598 - loss: 0.4211 - precision: 0.8127 - recall: 0.8993 \n",
            "Epoch 30/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7982 - f1_score: 0.7573 - loss: 0.4297 - precision: 0.8029 - recall: 0.8865 \n",
            "Epoch 31/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.7961 - f1_score: 0.7629 - loss: 0.4310 - precision: 0.7985 - recall: 0.8954 \n",
            "Epoch 32/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8149 - f1_score: 0.7703 - loss: 0.4144 - precision: 0.8161 - recall: 0.9094 \n",
            "Epoch 33/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8026 - f1_score: 0.7619 - loss: 0.4154 - precision: 0.8214 - recall: 0.8681 \n",
            "Epoch 34/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8133 - f1_score: 0.7579 - loss: 0.4095 - precision: 0.8151 - recall: 0.8979 \n",
            "Epoch 35/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8049 - f1_score: 0.7482 - loss: 0.4171 - precision: 0.8119 - recall: 0.8769 \n",
            "Epoch 36/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8152 - f1_score: 0.7601 - loss: 0.4104 - precision: 0.8131 - recall: 0.9073 \n",
            "Epoch 37/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8207 - f1_score: 0.7560 - loss: 0.4004 - precision: 0.8266 - recall: 0.8925 \n",
            "Epoch 38/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8126 - f1_score: 0.7607 - loss: 0.3953 - precision: 0.8227 - recall: 0.8857 \n",
            "Epoch 39/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8143 - f1_score: 0.7625 - loss: 0.4032 - precision: 0.8140 - recall: 0.9056\n",
            "Epoch 40/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8106 - f1_score: 0.7658 - loss: 0.3990 - precision: 0.8127 - recall: 0.9032\n",
            "Epoch 41/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8321 - f1_score: 0.7620 - loss: 0.3832 - precision: 0.8346 - recall: 0.9071 \n",
            "Epoch 42/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8196 - f1_score: 0.7636 - loss: 0.3797 - precision: 0.8236 - recall: 0.9008 \n",
            "Epoch 43/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8343 - f1_score: 0.7572 - loss: 0.3772 - precision: 0.8406 - recall: 0.8984\n",
            "Epoch 44/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8282 - f1_score: 0.7630 - loss: 0.3833 - precision: 0.8396 - recall: 0.8922 \n",
            "Epoch 45/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8388 - f1_score: 0.7617 - loss: 0.3655 - precision: 0.8463 - recall: 0.9016 \n",
            "Epoch 46/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8266 - f1_score: 0.7579 - loss: 0.3765 - precision: 0.8382 - recall: 0.8870 \n",
            "Epoch 47/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8357 - f1_score: 0.7644 - loss: 0.3666 - precision: 0.8459 - recall: 0.8984 \n",
            "Epoch 48/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8429 - f1_score: 0.7656 - loss: 0.3594 - precision: 0.8445 - recall: 0.9153\n",
            "Epoch 49/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8377 - f1_score: 0.7547 - loss: 0.3600 - precision: 0.8428 - recall: 0.9004\n",
            "Epoch 50/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.8498 - f1_score: 0.7588 - loss: 0.3552 - precision: 0.8535 - recall: 0.9115\n",
            "Epoch 51/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8571 - f1_score: 0.7611 - loss: 0.3369 - precision: 0.8610 - recall: 0.9153  \n",
            "Epoch 52/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8461 - f1_score: 0.7633 - loss: 0.3467 - precision: 0.8547 - recall: 0.9044 \n",
            "Epoch 53/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8476 - f1_score: 0.7595 - loss: 0.3503 - precision: 0.8719 - recall: 0.8810 \n",
            "Epoch 54/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8515 - f1_score: 0.7629 - loss: 0.3396 - precision: 0.8620 - recall: 0.9037 \n",
            "Epoch 55/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8603 - f1_score: 0.7581 - loss: 0.3260 - precision: 0.8705 - recall: 0.9059 \n",
            "Epoch 56/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8589 - f1_score: 0.7608 - loss: 0.3282 - precision: 0.8639 - recall: 0.9141 \n",
            "Epoch 57/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8568 - f1_score: 0.7594 - loss: 0.3319 - precision: 0.8638 - recall: 0.9097 \n",
            "Epoch 58/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8658 - f1_score: 0.7697 - loss: 0.3248 - precision: 0.8716 - recall: 0.9211 \n",
            "Epoch 59/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8537 - f1_score: 0.7610 - loss: 0.3233 - precision: 0.8795 - recall: 0.8826 \n",
            "Epoch 60/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8749 - f1_score: 0.7626 - loss: 0.3146 - precision: 0.8810 - recall: 0.9218 \n",
            "Epoch 61/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8595 - f1_score: 0.7600 - loss: 0.3238 - precision: 0.8732 - recall: 0.9018 \n",
            "Epoch 62/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8706 - f1_score: 0.7576 - loss: 0.3095 - precision: 0.8752 - recall: 0.9191 \n",
            "Epoch 63/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8654 - f1_score: 0.7733 - loss: 0.3084 - precision: 0.8741 - recall: 0.9187 \n",
            "Epoch 64/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8668 - f1_score: 0.7623 - loss: 0.3133 - precision: 0.8745 - recall: 0.9151 \n",
            "Epoch 65/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8725 - f1_score: 0.7702 - loss: 0.3083 - precision: 0.8927 - recall: 0.9052 \n",
            "Epoch 66/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8697 - f1_score: 0.7523 - loss: 0.3017 - precision: 0.8784 - recall: 0.9097 \n",
            "Epoch 67/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8741 - f1_score: 0.7591 - loss: 0.3023 - precision: 0.8888 - recall: 0.9079 \n",
            "Epoch 68/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8740 - f1_score: 0.7674 - loss: 0.2944 - precision: 0.8902 - recall: 0.9103 \n",
            "Epoch 69/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8828 - f1_score: 0.7546 - loss: 0.2904 - precision: 0.8981 - recall: 0.9100 \n",
            "Epoch 70/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8827 - f1_score: 0.7565 - loss: 0.2943 - precision: 0.8881 - recall: 0.9235 \n",
            "Epoch 71/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8763 - f1_score: 0.7603 - loss: 0.2954 - precision: 0.8927 - recall: 0.9077 \n",
            "Epoch 72/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8711 - f1_score: 0.7617 - loss: 0.2915 - precision: 0.8800 - recall: 0.9153 \n",
            "Epoch 73/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8990 - f1_score: 0.7582 - loss: 0.2737 - precision: 0.9051 - recall: 0.9323 \n",
            "Epoch 74/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8888 - f1_score: 0.7654 - loss: 0.2758 - precision: 0.8938 - recall: 0.9314 \n",
            "Epoch 75/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8934 - f1_score: 0.7689 - loss: 0.2757 - precision: 0.9028 - recall: 0.9291 \n",
            "Epoch 76/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8913 - f1_score: 0.7619 - loss: 0.2689 - precision: 0.9065 - recall: 0.9184 \n",
            "Epoch 77/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8915 - f1_score: 0.7666 - loss: 0.2695 - precision: 0.9122 - recall: 0.9133 \n",
            "Epoch 78/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8861 - f1_score: 0.7582 - loss: 0.2802 - precision: 0.8928 - recall: 0.9245 \n",
            "Epoch 79/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8926 - f1_score: 0.7586 - loss: 0.2712 - precision: 0.8953 - recall: 0.9334 \n",
            "Epoch 80/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8980 - f1_score: 0.7726 - loss: 0.2623 - precision: 0.9114 - recall: 0.9281 \n",
            "Epoch 81/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8960 - f1_score: 0.7680 - loss: 0.2639 - precision: 0.9097 - recall: 0.9253 \n",
            "Epoch 82/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8817 - f1_score: 0.7667 - loss: 0.2792 - precision: 0.8878 - recall: 0.9269 \n",
            "Epoch 83/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8887 - f1_score: 0.7736 - loss: 0.2698 - precision: 0.9106 - recall: 0.9135 \n",
            "Epoch 84/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8923 - f1_score: 0.7542 - loss: 0.2586 - precision: 0.9039 - recall: 0.9202 \n",
            "Epoch 85/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8865 - f1_score: 0.7581 - loss: 0.2589 - precision: 0.8875 - recall: 0.9323 \n",
            "Epoch 86/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8949 - f1_score: 0.7618 - loss: 0.2571 - precision: 0.9118 - recall: 0.9183 \n",
            "Epoch 87/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8942 - f1_score: 0.7569 - loss: 0.2646 - precision: 0.8974 - recall: 0.9331\n",
            "Epoch 88/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8967 - f1_score: 0.7617 - loss: 0.2492 - precision: 0.9059 - recall: 0.9289 \n",
            "Epoch 89/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8972 - f1_score: 0.7601 - loss: 0.2567 - precision: 0.9217 - recall: 0.9097 \n",
            "Epoch 90/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9031 - f1_score: 0.7620 - loss: 0.2492 - precision: 0.9212 - recall: 0.9214 \n",
            "Epoch 91/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8931 - f1_score: 0.7680 - loss: 0.2618 - precision: 0.9051 - recall: 0.9257 \n",
            "Epoch 92/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8974 - f1_score: 0.7665 - loss: 0.2426 - precision: 0.9119 - recall: 0.9244 \n",
            "Epoch 93/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8975 - f1_score: 0.7610 - loss: 0.2461 - precision: 0.9120 - recall: 0.9222 \n",
            "Epoch 94/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9000 - f1_score: 0.7597 - loss: 0.2475 - precision: 0.9130 - recall: 0.9248 \n",
            "Epoch 95/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9051 - f1_score: 0.7617 - loss: 0.2316 - precision: 0.9186 - recall: 0.9280 \n",
            "Epoch 96/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9166 - f1_score: 0.7713 - loss: 0.2271 - precision: 0.9221 - recall: 0.9469 \n",
            "Epoch 97/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8998 - f1_score: 0.7598 - loss: 0.2398 - precision: 0.9112 - recall: 0.9268 \n",
            "Epoch 98/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9041 - f1_score: 0.7625 - loss: 0.2446 - precision: 0.9168 - recall: 0.9287 \n",
            "Epoch 99/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9005 - f1_score: 0.7548 - loss: 0.2436 - precision: 0.9236 - recall: 0.9114 \n",
            "Epoch 100/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.8985 - f1_score: 0.7630 - loss: 0.2427 - precision: 0.9041 - recall: 0.9347 \n",
            "Epoch 101/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9067 - f1_score: 0.7598 - loss: 0.2303 - precision: 0.9334 - recall: 0.9130 \n",
            "Epoch 102/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9161 - f1_score: 0.7672 - loss: 0.2166 - precision: 0.9176 - recall: 0.9505 \n",
            "Epoch 103/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9159 - f1_score: 0.7638 - loss: 0.2286 - precision: 0.9394 - recall: 0.9239 \n",
            "Epoch 104/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9123 - f1_score: 0.7613 - loss: 0.2302 - precision: 0.9334 - recall: 0.9233 \n",
            "Epoch 105/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9088 - f1_score: 0.7588 - loss: 0.2327 - precision: 0.9087 - recall: 0.9462 \n",
            "Epoch 106/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9078 - f1_score: 0.7635 - loss: 0.2281 - precision: 0.9187 - recall: 0.9333 \n",
            "Epoch 107/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9288 - f1_score: 0.7634 - loss: 0.2155 - precision: 0.9377 - recall: 0.9475 \n",
            "Epoch 108/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9142 - f1_score: 0.7609 - loss: 0.2190 - precision: 0.9280 - recall: 0.9324 \n",
            "Epoch 109/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9084 - f1_score: 0.7672 - loss: 0.2266 - precision: 0.9152 - recall: 0.9401 \n",
            "Epoch 110/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9076 - f1_score: 0.7625 - loss: 0.2303 - precision: 0.9169 - recall: 0.9349 \n",
            "Epoch 111/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9091 - f1_score: 0.7576 - loss: 0.2287 - precision: 0.9261 - recall: 0.9249 \n",
            "Epoch 112/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9131 - f1_score: 0.7650 - loss: 0.2122 - precision: 0.9185 - recall: 0.9435 \n",
            "Epoch 113/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9092 - f1_score: 0.7662 - loss: 0.2239 - precision: 0.9191 - recall: 0.9363 \n",
            "Epoch 114/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9064 - f1_score: 0.7576 - loss: 0.2265 - precision: 0.9236 - recall: 0.9228 \n",
            "Epoch 115/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9230 - f1_score: 0.7555 - loss: 0.2101 - precision: 0.9342 - recall: 0.9394 \n",
            "Epoch 116/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9064 - f1_score: 0.7594 - loss: 0.2234 - precision: 0.9161 - recall: 0.9325 \n",
            "Epoch 117/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9147 - f1_score: 0.7588 - loss: 0.2133 - precision: 0.9207 - recall: 0.9419 \n",
            "Epoch 118/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9188 - f1_score: 0.7595 - loss: 0.2167 - precision: 0.9270 - recall: 0.9417 \n",
            "Epoch 119/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9209 - f1_score: 0.7571 - loss: 0.2023 - precision: 0.9308 - recall: 0.9402 \n",
            "Epoch 120/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9199 - f1_score: 0.7614 - loss: 0.2053 - precision: 0.9267 - recall: 0.9445 \n",
            "Epoch 121/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9183 - f1_score: 0.7687 - loss: 0.1979 - precision: 0.9319 - recall: 0.9376 \n",
            "Epoch 122/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9171 - f1_score: 0.7572 - loss: 0.2109 - precision: 0.9315 - recall: 0.9326 \n",
            "Epoch 123/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9154 - f1_score: 0.7647 - loss: 0.2081 - precision: 0.9223 - recall: 0.9428 \n",
            "Epoch 124/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9142 - f1_score: 0.7592 - loss: 0.2104 - precision: 0.9297 - recall: 0.9300 \n",
            "Epoch 125/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9169 - f1_score: 0.7658 - loss: 0.2077 - precision: 0.9319 - recall: 0.9345 \n",
            "Epoch 126/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9186 - f1_score: 0.7631 - loss: 0.2057 - precision: 0.9326 - recall: 0.9357 \n",
            "Epoch 127/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9329 - f1_score: 0.7734 - loss: 0.1860 - precision: 0.9442 - recall: 0.9496 \n",
            "Epoch 128/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9325 - f1_score: 0.7566 - loss: 0.1907 - precision: 0.9439 - recall: 0.9452 \n",
            "Epoch 129/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9179 - f1_score: 0.7534 - loss: 0.2037 - precision: 0.9278 - recall: 0.9372 \n",
            "Epoch 130/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9222 - f1_score: 0.7586 - loss: 0.2004 - precision: 0.9272 - recall: 0.9470 \n",
            "Epoch 131/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9279 - f1_score: 0.7688 - loss: 0.1947 - precision: 0.9342 - recall: 0.9513 \n",
            "Epoch 132/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9167 - f1_score: 0.7586 - loss: 0.2084 - precision: 0.9276 - recall: 0.9370 \n",
            "Epoch 133/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9234 - f1_score: 0.7747 - loss: 0.1980 - precision: 0.9322 - recall: 0.9480 \n",
            "Epoch 134/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9147 - f1_score: 0.7669 - loss: 0.2025 - precision: 0.9335 - recall: 0.9289 \n",
            "Epoch 135/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9261 - f1_score: 0.7640 - loss: 0.1913 - precision: 0.9339 - recall: 0.9471 \n",
            "Epoch 136/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9262 - f1_score: 0.7610 - loss: 0.1957 - precision: 0.9311 - recall: 0.9502 \n",
            "Epoch 137/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9307 - f1_score: 0.7675 - loss: 0.1766 - precision: 0.9477 - recall: 0.9407 \n",
            "Epoch 138/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9402 - f1_score: 0.7619 - loss: 0.1712 - precision: 0.9477 - recall: 0.9558\n",
            "Epoch 139/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9287 - f1_score: 0.7591 - loss: 0.1865 - precision: 0.9444 - recall: 0.9385\n",
            "Epoch 140/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9273 - f1_score: 0.7682 - loss: 0.1902 - precision: 0.9379 - recall: 0.9460 \n",
            "Epoch 141/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9214 - f1_score: 0.7718 - loss: 0.1961 - precision: 0.9391 - recall: 0.9355\n",
            "Epoch 142/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9320 - f1_score: 0.7667 - loss: 0.1748 - precision: 0.9453 - recall: 0.9453 \n",
            "Epoch 143/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9231 - f1_score: 0.7679 - loss: 0.1905 - precision: 0.9378 - recall: 0.9389\n",
            "Epoch 144/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9297 - f1_score: 0.7627 - loss: 0.1795 - precision: 0.9396 - recall: 0.9467\n",
            "Epoch 145/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9272 - f1_score: 0.7589 - loss: 0.1845 - precision: 0.9344 - recall: 0.9474\n",
            "Epoch 146/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9201 - f1_score: 0.7668 - loss: 0.1870 - precision: 0.9367 - recall: 0.9345 \n",
            "Epoch 147/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9259 - f1_score: 0.7640 - loss: 0.1858 - precision: 0.9415 - recall: 0.9384\n",
            "Epoch 148/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9262 - f1_score: 0.7671 - loss: 0.1855 - precision: 0.9342 - recall: 0.9480\n",
            "Epoch 149/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9276 - f1_score: 0.7643 - loss: 0.1849 - precision: 0.9437 - recall: 0.9390\n",
            "Epoch 150/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9198 - f1_score: 0.7645 - loss: 0.1828 - precision: 0.9270 - recall: 0.9448\n",
            "Epoch 151/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9270 - f1_score: 0.7558 - loss: 0.1820 - precision: 0.9406 - recall: 0.9389  \n",
            "Epoch 152/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9267 - f1_score: 0.7567 - loss: 0.1840 - precision: 0.9361 - recall: 0.9434 \n",
            "Epoch 153/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9141 - f1_score: 0.7608 - loss: 0.1935 - precision: 0.9298 - recall: 0.9299 \n",
            "Epoch 154/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9314 - f1_score: 0.7697 - loss: 0.1793 - precision: 0.9476 - recall: 0.9424 \n",
            "Epoch 155/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9418 - f1_score: 0.7682 - loss: 0.1665 - precision: 0.9490 - recall: 0.9580 \n",
            "Epoch 156/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9285 - f1_score: 0.7517 - loss: 0.1830 - precision: 0.9419 - recall: 0.9391 \n",
            "Epoch 157/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9255 - f1_score: 0.7636 - loss: 0.1833 - precision: 0.9274 - recall: 0.9540 \n",
            "Epoch 158/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9235 - f1_score: 0.7716 - loss: 0.1876 - precision: 0.9338 - recall: 0.9446 \n",
            "Epoch 159/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9239 - f1_score: 0.7594 - loss: 0.1861 - precision: 0.9378 - recall: 0.9375 \n",
            "Epoch 160/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9248 - f1_score: 0.7665 - loss: 0.1813 - precision: 0.9418 - recall: 0.9366 \n",
            "Epoch 161/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9303 - f1_score: 0.7632 - loss: 0.1708 - precision: 0.9446 - recall: 0.9417 \n",
            "Epoch 162/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9433 - f1_score: 0.7632 - loss: 0.1578 - precision: 0.9550 - recall: 0.9526 \n",
            "Epoch 163/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9313 - f1_score: 0.7631 - loss: 0.1724 - precision: 0.9402 - recall: 0.9486 \n",
            "Epoch 164/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9441 - f1_score: 0.7581 - loss: 0.1583 - precision: 0.9583 - recall: 0.9496 \n",
            "Epoch 165/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9320 - f1_score: 0.7616 - loss: 0.1724 - precision: 0.9366 - recall: 0.9537 \n",
            "Epoch 166/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9303 - f1_score: 0.7668 - loss: 0.1722 - precision: 0.9381 - recall: 0.9501 \n",
            "Epoch 167/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9292 - f1_score: 0.7589 - loss: 0.1776 - precision: 0.9384 - recall: 0.9458 \n",
            "Epoch 168/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9351 - f1_score: 0.7667 - loss: 0.1650 - precision: 0.9435 - recall: 0.9523 \n",
            "Epoch 169/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9332 - f1_score: 0.7682 - loss: 0.1720 - precision: 0.9388 - recall: 0.9547 \n",
            "Epoch 170/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9385 - f1_score: 0.7633 - loss: 0.1572 - precision: 0.9499 - recall: 0.9501 \n",
            "Epoch 171/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9375 - f1_score: 0.7636 - loss: 0.1652 - precision: 0.9493 - recall: 0.9492 \n",
            "Epoch 172/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9384 - f1_score: 0.7727 - loss: 0.1575 - precision: 0.9517 - recall: 0.9498 \n",
            "Epoch 173/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9416 - f1_score: 0.7642 - loss: 0.1553 - precision: 0.9510 - recall: 0.9544 \n",
            "Epoch 174/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9282 - f1_score: 0.7619 - loss: 0.1664 - precision: 0.9395 - recall: 0.9436 \n",
            "Epoch 175/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9266 - f1_score: 0.7653 - loss: 0.1736 - precision: 0.9380 - recall: 0.9432 \n",
            "Epoch 176/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9356 - f1_score: 0.7650 - loss: 0.1609 - precision: 0.9537 - recall: 0.9413 \n",
            "Epoch 177/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9305 - f1_score: 0.7709 - loss: 0.1716 - precision: 0.9349 - recall: 0.9557 \n",
            "Epoch 178/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9449 - f1_score: 0.7554 - loss: 0.1477 - precision: 0.9529 - recall: 0.9560 \n",
            "Epoch 179/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9358 - f1_score: 0.7708 - loss: 0.1656 - precision: 0.9494 - recall: 0.9476 \n",
            "Epoch 180/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9349 - f1_score: 0.7654 - loss: 0.1638 - precision: 0.9501 - recall: 0.9440 \n",
            "Epoch 181/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9300 - f1_score: 0.7663 - loss: 0.1677 - precision: 0.9507 - recall: 0.9354 \n",
            "Epoch 182/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9342 - f1_score: 0.7670 - loss: 0.1631 - precision: 0.9472 - recall: 0.9466 \n",
            "Epoch 183/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9474 - f1_score: 0.7672 - loss: 0.1474 - precision: 0.9586 - recall: 0.9564 \n",
            "Epoch 184/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9462 - f1_score: 0.7767 - loss: 0.1496 - precision: 0.9543 - recall: 0.9604 \n",
            "Epoch 185/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9391 - f1_score: 0.7694 - loss: 0.1494 - precision: 0.9475 - recall: 0.9546 \n",
            "Epoch 186/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9277 - f1_score: 0.7622 - loss: 0.1736 - precision: 0.9419 - recall: 0.9400 \n",
            "Epoch 187/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9390 - f1_score: 0.7670 - loss: 0.1619 - precision: 0.9522 - recall: 0.9492 \n",
            "Epoch 188/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9398 - f1_score: 0.7667 - loss: 0.1572 - precision: 0.9492 - recall: 0.9536 \n",
            "Epoch 189/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9309 - f1_score: 0.7756 - loss: 0.1738 - precision: 0.9365 - recall: 0.9552 \n",
            "Epoch 190/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9427 - f1_score: 0.7595 - loss: 0.1564 - precision: 0.9525 - recall: 0.9533 \n",
            "Epoch 191/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9394 - f1_score: 0.7600 - loss: 0.1536 - precision: 0.9543 - recall: 0.9458 \n",
            "Epoch 192/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9382 - f1_score: 0.7709 - loss: 0.1498 - precision: 0.9426 - recall: 0.9594 \n",
            "Epoch 193/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9394 - f1_score: 0.7686 - loss: 0.1524 - precision: 0.9489 - recall: 0.9534 \n",
            "Epoch 194/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9392 - f1_score: 0.7706 - loss: 0.1534 - precision: 0.9543 - recall: 0.9483 \n",
            "Epoch 195/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9399 - f1_score: 0.7587 - loss: 0.1527 - precision: 0.9429 - recall: 0.9593 \n",
            "Epoch 196/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9283 - f1_score: 0.7674 - loss: 0.1629 - precision: 0.9497 - recall: 0.9333 \n",
            "Epoch 197/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9418 - f1_score: 0.7624 - loss: 0.1460 - precision: 0.9519 - recall: 0.9531 \n",
            "Epoch 198/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9457 - f1_score: 0.7729 - loss: 0.1440 - precision: 0.9504 - recall: 0.9635 \n",
            "Epoch 199/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9273 - f1_score: 0.7682 - loss: 0.1674 - precision: 0.9293 - recall: 0.9555 \n",
            "Epoch 200/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9495 - f1_score: 0.7684 - loss: 0.1401 - precision: 0.9604 - recall: 0.9579 \n",
            "Epoch 201/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9463 - f1_score: 0.7697 - loss: 0.1434 - precision: 0.9580 - recall: 0.9556 \n",
            "Epoch 202/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9425 - f1_score: 0.7665 - loss: 0.1451 - precision: 0.9503 - recall: 0.9568 \n",
            "Epoch 203/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9482 - f1_score: 0.7737 - loss: 0.1438 - precision: 0.9531 - recall: 0.9646 \n",
            "Epoch 204/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9418 - f1_score: 0.7650 - loss: 0.1474 - precision: 0.9526 - recall: 0.9529 \n",
            "Epoch 205/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9432 - f1_score: 0.7660 - loss: 0.1462 - precision: 0.9513 - recall: 0.9567 \n",
            "Epoch 206/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9343 - f1_score: 0.7641 - loss: 0.1542 - precision: 0.9445 - recall: 0.9486 \n",
            "Epoch 207/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9410 - f1_score: 0.7657 - loss: 0.1462 - precision: 0.9414 - recall: 0.9644 \n",
            "Epoch 208/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9427 - f1_score: 0.7663 - loss: 0.1377 - precision: 0.9502 - recall: 0.9573 \n",
            "Epoch 209/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9416 - f1_score: 0.7678 - loss: 0.1513 - precision: 0.9470 - recall: 0.9592 \n",
            "Epoch 210/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9477 - f1_score: 0.7689 - loss: 0.1391 - precision: 0.9556 - recall: 0.9601 \n",
            "Epoch 211/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9460 - f1_score: 0.7673 - loss: 0.1427 - precision: 0.9671 - recall: 0.9445 \n",
            "Epoch 212/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9478 - f1_score: 0.7668 - loss: 0.1375 - precision: 0.9572 - recall: 0.9580 \n",
            "Epoch 213/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9410 - f1_score: 0.7641 - loss: 0.1451 - precision: 0.9535 - recall: 0.9498 \n",
            "Epoch 214/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9515 - f1_score: 0.7622 - loss: 0.1350 - precision: 0.9594 - recall: 0.9613 \n",
            "Epoch 215/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9488 - f1_score: 0.7713 - loss: 0.1344 - precision: 0.9577 - recall: 0.9600 \n",
            "Epoch 216/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9454 - f1_score: 0.7714 - loss: 0.1386 - precision: 0.9610 - recall: 0.9511 \n",
            "Epoch 217/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9441 - f1_score: 0.7688 - loss: 0.1363 - precision: 0.9492 - recall: 0.9613 \n",
            "Epoch 218/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9396 - f1_score: 0.7730 - loss: 0.1386 - precision: 0.9476 - recall: 0.9564 \n",
            "Epoch 219/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9417 - f1_score: 0.7646 - loss: 0.1575 - precision: 0.9494 - recall: 0.9562 \n",
            "Epoch 220/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9507 - f1_score: 0.7691 - loss: 0.1370 - precision: 0.9647 - recall: 0.9552 \n",
            "Epoch 221/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9488 - f1_score: 0.7726 - loss: 0.1372 - precision: 0.9483 - recall: 0.9706 \n",
            "Epoch 222/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9367 - f1_score: 0.7566 - loss: 0.1470 - precision: 0.9384 - recall: 0.9583 \n",
            "Epoch 223/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9523 - f1_score: 0.7715 - loss: 0.1272 - precision: 0.9626 - recall: 0.9606 \n",
            "Epoch 224/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9491 - f1_score: 0.7689 - loss: 0.1321 - precision: 0.9655 - recall: 0.9518 \n",
            "Epoch 225/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9439 - f1_score: 0.7742 - loss: 0.1378 - precision: 0.9540 - recall: 0.9560 \n",
            "Epoch 226/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9467 - f1_score: 0.7641 - loss: 0.1324 - precision: 0.9480 - recall: 0.9663 \n",
            "Epoch 227/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9489 - f1_score: 0.7703 - loss: 0.1348 - precision: 0.9622 - recall: 0.9550 \n",
            "Epoch 228/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9399 - f1_score: 0.7615 - loss: 0.1518 - precision: 0.9472 - recall: 0.9543 \n",
            "Epoch 229/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9515 - f1_score: 0.7713 - loss: 0.1372 - precision: 0.9613 - recall: 0.9606 \n",
            "Epoch 230/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9388 - f1_score: 0.7619 - loss: 0.1476 - precision: 0.9549 - recall: 0.9445 \n",
            "Epoch 231/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9421 - f1_score: 0.7669 - loss: 0.1423 - precision: 0.9474 - recall: 0.9593 \n",
            "Epoch 232/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9536 - f1_score: 0.7632 - loss: 0.1292 - precision: 0.9574 - recall: 0.9673 \n",
            "Epoch 233/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9494 - f1_score: 0.7645 - loss: 0.1304 - precision: 0.9547 - recall: 0.9635 \n",
            "Epoch 234/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9372 - f1_score: 0.7838 - loss: 0.1516 - precision: 0.9516 - recall: 0.9504\n",
            "Epoch 235/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9507 - f1_score: 0.7682 - loss: 0.1329 - precision: 0.9612 - recall: 0.9589\n",
            "Epoch 236/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9439 - f1_score: 0.7656 - loss: 0.1324 - precision: 0.9487 - recall: 0.9606\n",
            "Epoch 237/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9469 - f1_score: 0.7667 - loss: 0.1359 - precision: 0.9557 - recall: 0.9577\n",
            "Epoch 238/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9449 - f1_score: 0.7573 - loss: 0.1368 - precision: 0.9484 - recall: 0.9611\n",
            "Epoch 239/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9468 - f1_score: 0.7604 - loss: 0.1298 - precision: 0.9522 - recall: 0.9605\n",
            "Epoch 240/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9506 - f1_score: 0.7679 - loss: 0.1322 - precision: 0.9583 - recall: 0.9618 \n",
            "Epoch 241/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9467 - f1_score: 0.7652 - loss: 0.1360 - precision: 0.9571 - recall: 0.9560 \n",
            "Epoch 242/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9484 - f1_score: 0.7663 - loss: 0.1231 - precision: 0.9545 - recall: 0.9621\n",
            "Epoch 243/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9492 - f1_score: 0.7689 - loss: 0.1284 - precision: 0.9597 - recall: 0.9582\n",
            "Epoch 244/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9513 - f1_score: 0.7747 - loss: 0.1284 - precision: 0.9540 - recall: 0.9688\n",
            "Epoch 245/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9523 - f1_score: 0.7704 - loss: 0.1258 - precision: 0.9652 - recall: 0.9578\n",
            "Epoch 246/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9480 - f1_score: 0.7792 - loss: 0.1271 - precision: 0.9529 - recall: 0.9657  \n",
            "Epoch 247/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9549 - f1_score: 0.7675 - loss: 0.1217 - precision: 0.9650 - recall: 0.9619 \n",
            "Epoch 248/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9485 - f1_score: 0.7764 - loss: 0.1332 - precision: 0.9601 - recall: 0.9582 \n",
            "Epoch 249/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9472 - f1_score: 0.7692 - loss: 0.1317 - precision: 0.9496 - recall: 0.9660 \n",
            "Epoch 250/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9506 - f1_score: 0.7705 - loss: 0.1272 - precision: 0.9573 - recall: 0.9635 \n",
            "Epoch 251/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9472 - f1_score: 0.7658 - loss: 0.1351 - precision: 0.9566 - recall: 0.9577 \n",
            "Epoch 252/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9509 - f1_score: 0.7752 - loss: 0.1279 - precision: 0.9631 - recall: 0.9585 \n",
            "Epoch 253/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9502 - f1_score: 0.7678 - loss: 0.1256 - precision: 0.9581 - recall: 0.9613 \n",
            "Epoch 254/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9494 - f1_score: 0.7718 - loss: 0.1250 - precision: 0.9610 - recall: 0.9575 \n",
            "Epoch 255/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9524 - f1_score: 0.7640 - loss: 0.1240 - precision: 0.9593 - recall: 0.9630 \n",
            "Epoch 256/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9456 - f1_score: 0.7631 - loss: 0.1351 - precision: 0.9444 - recall: 0.9679 \n",
            "Epoch 257/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9566 - f1_score: 0.7715 - loss: 0.1192 - precision: 0.9662 - recall: 0.9640 \n",
            "Epoch 258/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9402 - f1_score: 0.7657 - loss: 0.1460 - precision: 0.9540 - recall: 0.9480 \n",
            "Epoch 259/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9491 - f1_score: 0.7607 - loss: 0.1295 - precision: 0.9636 - recall: 0.9522 \n",
            "Epoch 260/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9538 - f1_score: 0.7671 - loss: 0.1189 - precision: 0.9660 - recall: 0.9589 \n",
            "Epoch 261/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9552 - f1_score: 0.7688 - loss: 0.1204 - precision: 0.9682 - recall: 0.9586 \n",
            "Epoch 262/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9425 - f1_score: 0.7678 - loss: 0.1353 - precision: 0.9535 - recall: 0.9533 \n",
            "Epoch 263/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9569 - f1_score: 0.7767 - loss: 0.1126 - precision: 0.9674 - recall: 0.9639 \n",
            "Epoch 264/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9453 - f1_score: 0.7663 - loss: 0.1297 - precision: 0.9508 - recall: 0.9605 \n",
            "Epoch 265/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9583 - f1_score: 0.7707 - loss: 0.1169 - precision: 0.9661 - recall: 0.9668 \n",
            "Epoch 266/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9547 - f1_score: 0.7653 - loss: 0.1156 - precision: 0.9658 - recall: 0.9601 \n",
            "Epoch 267/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9554 - f1_score: 0.7732 - loss: 0.1173 - precision: 0.9679 - recall: 0.9602 \n",
            "Epoch 268/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9479 - f1_score: 0.7633 - loss: 0.1259 - precision: 0.9536 - recall: 0.9614 \n",
            "Epoch 269/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9531 - f1_score: 0.7670 - loss: 0.1182 - precision: 0.9592 - recall: 0.9649 \n",
            "Epoch 270/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9541 - f1_score: 0.7730 - loss: 0.1190 - precision: 0.9630 - recall: 0.9631 \n",
            "Epoch 271/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9570 - f1_score: 0.7699 - loss: 0.1105 - precision: 0.9671 - recall: 0.9632 \n",
            "Epoch 272/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9497 - f1_score: 0.7671 - loss: 0.1202 - precision: 0.9613 - recall: 0.9568\n",
            "Epoch 273/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9408 - f1_score: 0.7628 - loss: 0.1333 - precision: 0.9533 - recall: 0.9495 \n",
            "Epoch 274/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9567 - f1_score: 0.7761 - loss: 0.1171 - precision: 0.9730 - recall: 0.9576 \n",
            "Epoch 275/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9515 - f1_score: 0.7736 - loss: 0.1182 - precision: 0.9635 - recall: 0.9587 \n",
            "Epoch 276/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9452 - f1_score: 0.7766 - loss: 0.1289 - precision: 0.9523 - recall: 0.9610 \n",
            "Epoch 277/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9543 - f1_score: 0.7671 - loss: 0.1143 - precision: 0.9701 - recall: 0.9552 \n",
            "Epoch 278/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9464 - f1_score: 0.7659 - loss: 0.1316 - precision: 0.9599 - recall: 0.9526 \n",
            "Epoch 279/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9559 - f1_score: 0.7702 - loss: 0.1142 - precision: 0.9635 - recall: 0.9654 \n",
            "Epoch 280/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9523 - f1_score: 0.7678 - loss: 0.1216 - precision: 0.9686 - recall: 0.9535 \n",
            "Epoch 281/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9568 - f1_score: 0.7657 - loss: 0.1164 - precision: 0.9645 - recall: 0.9652 \n",
            "Epoch 282/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9511 - f1_score: 0.7742 - loss: 0.1283 - precision: 0.9592 - recall: 0.9625 \n",
            "Epoch 283/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9550 - f1_score: 0.7750 - loss: 0.1136 - precision: 0.9613 - recall: 0.9669 \n",
            "Epoch 284/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9578 - f1_score: 0.7654 - loss: 0.1164 - precision: 0.9670 - recall: 0.9639 \n",
            "Epoch 285/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9536 - f1_score: 0.7664 - loss: 0.1221 - precision: 0.9651 - recall: 0.9593 \n",
            "Epoch 286/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9539 - f1_score: 0.7693 - loss: 0.1150 - precision: 0.9624 - recall: 0.9629 \n",
            "Epoch 287/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9554 - f1_score: 0.7699 - loss: 0.1143 - precision: 0.9691 - recall: 0.9584 \n",
            "Epoch 288/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9442 - f1_score: 0.7673 - loss: 0.1287 - precision: 0.9508 - recall: 0.9592 \n",
            "Epoch 289/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9600 - f1_score: 0.7752 - loss: 0.1108 - precision: 0.9623 - recall: 0.9742\n",
            "Epoch 290/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9592 - f1_score: 0.7660 - loss: 0.1154 - precision: 0.9656 - recall: 0.9679 \n",
            "Epoch 291/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9632 - f1_score: 0.7715 - loss: 0.1101 - precision: 0.9748 - recall: 0.9656 \n",
            "Epoch 292/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9543 - f1_score: 0.7731 - loss: 0.1132 - precision: 0.9566 - recall: 0.9705 \n",
            "Epoch 293/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9593 - f1_score: 0.7666 - loss: 0.1112 - precision: 0.9645 - recall: 0.9696 \n",
            "Epoch 294/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9549 - f1_score: 0.7685 - loss: 0.1164 - precision: 0.9618 - recall: 0.9654 \n",
            "Epoch 295/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9523 - f1_score: 0.7730 - loss: 0.1198 - precision: 0.9623 - recall: 0.9613 \n",
            "Epoch 296/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9589 - f1_score: 0.7693 - loss: 0.1103 - precision: 0.9661 - recall: 0.9676 \n",
            "Epoch 297/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9530 - f1_score: 0.7785 - loss: 0.1173 - precision: 0.9583 - recall: 0.9674\n",
            "Epoch 298/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9509 - f1_score: 0.7685 - loss: 0.1211 - precision: 0.9547 - recall: 0.9665 \n",
            "Epoch 299/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9628 - f1_score: 0.7641 - loss: 0.1031 - precision: 0.9738 - recall: 0.9653 \n",
            "Epoch 300/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9569 - f1_score: 0.7730 - loss: 0.1134 - precision: 0.9658 - recall: 0.9649 \n",
            "Epoch 301/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9605 - f1_score: 0.7600 - loss: 0.1063 - precision: 0.9708 - recall: 0.9638 \n",
            "Epoch 302/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9580 - f1_score: 0.7778 - loss: 0.1098 - precision: 0.9670 - recall: 0.9664 \n",
            "Epoch 303/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9596 - f1_score: 0.7709 - loss: 0.1034 - precision: 0.9657 - recall: 0.9693 \n",
            "Epoch 304/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9617 - f1_score: 0.7673 - loss: 0.1059 - precision: 0.9664 - recall: 0.9716 \n",
            "Epoch 305/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9634 - f1_score: 0.7730 - loss: 0.1076 - precision: 0.9733 - recall: 0.9678 \n",
            "Epoch 306/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9652 - f1_score: 0.7627 - loss: 0.1042 - precision: 0.9735 - recall: 0.9694 \n",
            "Epoch 307/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9546 - f1_score: 0.7669 - loss: 0.1116 - precision: 0.9617 - recall: 0.9646 \n",
            "Epoch 308/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9481 - f1_score: 0.7741 - loss: 0.1214 - precision: 0.9565 - recall: 0.9607 \n",
            "Epoch 309/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9511 - f1_score: 0.7657 - loss: 0.1173 - precision: 0.9588 - recall: 0.9617 \n",
            "Epoch 310/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9656 - f1_score: 0.7739 - loss: 0.0968 - precision: 0.9719 - recall: 0.9730 \n",
            "Epoch 311/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9607 - f1_score: 0.7676 - loss: 0.1053 - precision: 0.9648 - recall: 0.9716 \n",
            "Epoch 312/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9580 - f1_score: 0.7707 - loss: 0.1102 - precision: 0.9624 - recall: 0.9702 \n",
            "Epoch 313/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9486 - f1_score: 0.7638 - loss: 0.1182 - precision: 0.9599 - recall: 0.9556 \n",
            "Epoch 314/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9605 - f1_score: 0.7727 - loss: 0.1063 - precision: 0.9673 - recall: 0.9691 \n",
            "Epoch 315/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9573 - f1_score: 0.7617 - loss: 0.1080 - precision: 0.9658 - recall: 0.9640\n",
            "Epoch 316/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9590 - f1_score: 0.7693 - loss: 0.1071 - precision: 0.9671 - recall: 0.9666 \n",
            "Epoch 317/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9596 - f1_score: 0.7601 - loss: 0.1094 - precision: 0.9630 - recall: 0.9706 \n",
            "Epoch 318/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9680 - f1_score: 0.7664 - loss: 0.0984 - precision: 0.9742 - recall: 0.9736 \n",
            "Epoch 319/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9592 - f1_score: 0.7773 - loss: 0.1048 - precision: 0.9673 - recall: 0.9676 \n",
            "Epoch 320/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9569 - f1_score: 0.7688 - loss: 0.1126 - precision: 0.9653 - recall: 0.9650 \n",
            "Epoch 321/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9523 - f1_score: 0.7677 - loss: 0.1102 - precision: 0.9644 - recall: 0.9578 \n",
            "Epoch 322/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9682 - f1_score: 0.7704 - loss: 0.0979 - precision: 0.9738 - recall: 0.9749 \n",
            "Epoch 323/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9541 - f1_score: 0.7685 - loss: 0.1155 - precision: 0.9664 - recall: 0.9589 \n",
            "Epoch 324/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9550 - f1_score: 0.7656 - loss: 0.1153 - precision: 0.9614 - recall: 0.9652 \n",
            "Epoch 325/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9651 - f1_score: 0.7601 - loss: 0.0960 - precision: 0.9669 - recall: 0.9757 \n",
            "Epoch 326/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9582 - f1_score: 0.7652 - loss: 0.1095 - precision: 0.9670 - recall: 0.9647 \n",
            "Epoch 327/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9565 - f1_score: 0.7623 - loss: 0.1081 - precision: 0.9542 - recall: 0.9755 \n",
            "Epoch 328/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9545 - f1_score: 0.7614 - loss: 0.1080 - precision: 0.9639 - recall: 0.9611\n",
            "Epoch 329/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9575 - f1_score: 0.7804 - loss: 0.1124 - precision: 0.9636 - recall: 0.9694\n",
            "Epoch 330/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - binary_accuracy: 0.9531 - f1_score: 0.7738 - loss: 0.1140 - precision: 0.9627 - recall: 0.9619\n",
            "Epoch 331/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9629 - f1_score: 0.7646 - loss: 0.0970 - precision: 0.9719 - recall: 0.9672\n",
            "Epoch 332/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9592 - f1_score: 0.7673 - loss: 0.1063 - precision: 0.9647 - recall: 0.9694\n",
            "Epoch 333/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9617 - f1_score: 0.7763 - loss: 0.0959 - precision: 0.9733 - recall: 0.9654\n",
            "Epoch 334/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9607 - f1_score: 0.7702 - loss: 0.0985 - precision: 0.9681 - recall: 0.9683\n",
            "Epoch 335/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9569 - f1_score: 0.7681 - loss: 0.1139 - precision: 0.9620 - recall: 0.9681\n",
            "Epoch 336/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9575 - f1_score: 0.7708 - loss: 0.1012 - precision: 0.9697 - recall: 0.9615\n",
            "Epoch 337/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9614 - f1_score: 0.7604 - loss: 0.0927 - precision: 0.9713 - recall: 0.9648\n",
            "Epoch 338/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9596 - f1_score: 0.7763 - loss: 0.1003 - precision: 0.9596 - recall: 0.9769 \n",
            "Epoch 339/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9648 - f1_score: 0.7638 - loss: 0.1039 - precision: 0.9732 - recall: 0.9692 \n",
            "Epoch 340/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9672 - f1_score: 0.7732 - loss: 0.0946 - precision: 0.9747 - recall: 0.9725 \n",
            "Epoch 341/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9658 - f1_score: 0.7604 - loss: 0.0976 - precision: 0.9712 - recall: 0.9725 \n",
            "Epoch 342/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9623 - f1_score: 0.7735 - loss: 0.0895 - precision: 0.9715 - recall: 0.9680 \n",
            "Epoch 343/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9628 - f1_score: 0.7721 - loss: 0.0962 - precision: 0.9704 - recall: 0.9696 \n",
            "Epoch 344/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9590 - f1_score: 0.7723 - loss: 0.0994 - precision: 0.9700 - recall: 0.9636 \n",
            "Epoch 345/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9657 - f1_score: 0.7703 - loss: 0.0883 - precision: 0.9721 - recall: 0.9725 \n",
            "Epoch 346/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9595 - f1_score: 0.7776 - loss: 0.1061 - precision: 0.9719 - recall: 0.9637 \n",
            "Epoch 347/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9640 - f1_score: 0.7759 - loss: 0.0975 - precision: 0.9675 - recall: 0.9752 \n",
            "Epoch 348/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9659 - f1_score: 0.7686 - loss: 0.0934 - precision: 0.9743 - recall: 0.9701 \n",
            "Epoch 349/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9655 - f1_score: 0.7600 - loss: 0.0959 - precision: 0.9744 - recall: 0.9685 \n",
            "Epoch 350/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9654 - f1_score: 0.7700 - loss: 0.0921 - precision: 0.9722 - recall: 0.9717 \n",
            "Epoch 351/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9653 - f1_score: 0.7753 - loss: 0.0925 - precision: 0.9656 - recall: 0.9796\n",
            "Epoch 352/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9610 - f1_score: 0.7631 - loss: 0.1012 - precision: 0.9669 - recall: 0.9692 \n",
            "Epoch 353/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9613 - f1_score: 0.7742 - loss: 0.0972 - precision: 0.9668 - recall: 0.9714 \n",
            "Epoch 354/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9698 - f1_score: 0.7633 - loss: 0.0899 - precision: 0.9757 - recall: 0.9747 \n",
            "Epoch 355/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9565 - f1_score: 0.7712 - loss: 0.1029 - precision: 0.9630 - recall: 0.9672 \n",
            "Epoch 356/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9622 - f1_score: 0.7715 - loss: 0.1022 - precision: 0.9733 - recall: 0.9658 \n",
            "Epoch 357/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9587 - f1_score: 0.7579 - loss: 0.1011 - precision: 0.9657 - recall: 0.9658 \n",
            "Epoch 358/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9523 - f1_score: 0.7742 - loss: 0.1159 - precision: 0.9639 - recall: 0.9591 \n",
            "Epoch 359/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9618 - f1_score: 0.7731 - loss: 0.0960 - precision: 0.9710 - recall: 0.9675 \n",
            "Epoch 360/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9624 - f1_score: 0.7758 - loss: 0.0967 - precision: 0.9622 - recall: 0.9784 \n",
            "Epoch 361/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9562 - f1_score: 0.7632 - loss: 0.1131 - precision: 0.9627 - recall: 0.9658 \n",
            "Epoch 362/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9673 - f1_score: 0.7581 - loss: 0.0923 - precision: 0.9738 - recall: 0.9721 \n",
            "Epoch 363/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9632 - f1_score: 0.7772 - loss: 0.0997 - precision: 0.9699 - recall: 0.9713 \n",
            "Epoch 364/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9624 - f1_score: 0.7641 - loss: 0.1065 - precision: 0.9761 - recall: 0.9619 \n",
            "Epoch 365/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9685 - f1_score: 0.7749 - loss: 0.0862 - precision: 0.9767 - recall: 0.9726 \n",
            "Epoch 366/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9651 - f1_score: 0.7731 - loss: 0.0991 - precision: 0.9748 - recall: 0.9689 \n",
            "Epoch 367/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9570 - f1_score: 0.7654 - loss: 0.1073 - precision: 0.9630 - recall: 0.9668 \n",
            "Epoch 368/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7726 - loss: 0.0901 - precision: 0.9735 - recall: 0.9670 \n",
            "Epoch 369/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9624 - f1_score: 0.7770 - loss: 0.0935 - precision: 0.9680 - recall: 0.9720 \n",
            "Epoch 370/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9648 - f1_score: 0.7736 - loss: 0.1004 - precision: 0.9799 - recall: 0.9632 \n",
            "Epoch 371/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9645 - f1_score: 0.7617 - loss: 0.0907 - precision: 0.9700 - recall: 0.9716 \n",
            "Epoch 372/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9636 - f1_score: 0.7637 - loss: 0.0929 - precision: 0.9668 - recall: 0.9739 \n",
            "Epoch 373/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9671 - f1_score: 0.7647 - loss: 0.0938 - precision: 0.9755 - recall: 0.9706 \n",
            "Epoch 374/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9570 - f1_score: 0.7726 - loss: 0.1058 - precision: 0.9625 - recall: 0.9688 \n",
            "Epoch 375/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9700 - f1_score: 0.7711 - loss: 0.0863 - precision: 0.9719 - recall: 0.9800 \n",
            "Epoch 376/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9654 - f1_score: 0.7671 - loss: 0.0980 - precision: 0.9763 - recall: 0.9671 \n",
            "Epoch 377/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9679 - f1_score: 0.7603 - loss: 0.0874 - precision: 0.9739 - recall: 0.9731\n",
            "Epoch 378/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9651 - f1_score: 0.7699 - loss: 0.0869 - precision: 0.9713 - recall: 0.9720 \n",
            "Epoch 379/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9659 - f1_score: 0.7692 - loss: 0.0968 - precision: 0.9769 - recall: 0.9677 \n",
            "Epoch 380/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9686 - f1_score: 0.7665 - loss: 0.0905 - precision: 0.9779 - recall: 0.9709 \n",
            "Epoch 381/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9699 - f1_score: 0.7685 - loss: 0.0986 - precision: 0.9784 - recall: 0.9725 \n",
            "Epoch 382/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9658 - f1_score: 0.7754 - loss: 0.0966 - precision: 0.9756 - recall: 0.9699 \n",
            "Epoch 383/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9664 - f1_score: 0.7771 - loss: 0.0897 - precision: 0.9707 - recall: 0.9756 \n",
            "Epoch 384/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9641 - f1_score: 0.7561 - loss: 0.0889 - precision: 0.9691 - recall: 0.9711 \n",
            "Epoch 385/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9708 - f1_score: 0.7742 - loss: 0.0831 - precision: 0.9793 - recall: 0.9739 \n",
            "Epoch 386/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9687 - f1_score: 0.7742 - loss: 0.0830 - precision: 0.9760 - recall: 0.9738 \n",
            "Epoch 387/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9626 - f1_score: 0.7753 - loss: 0.0998 - precision: 0.9730 - recall: 0.9672 \n",
            "Epoch 388/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9665 - f1_score: 0.7748 - loss: 0.0939 - precision: 0.9757 - recall: 0.9703 \n",
            "Epoch 389/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9750 - f1_score: 0.7704 - loss: 0.0778 - precision: 0.9814 - recall: 0.9781 \n",
            "Epoch 390/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9577 - f1_score: 0.7757 - loss: 0.1014 - precision: 0.9644 - recall: 0.9682 \n",
            "Epoch 391/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9681 - f1_score: 0.7767 - loss: 0.0873 - precision: 0.9808 - recall: 0.9681 \n",
            "Epoch 392/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9646 - f1_score: 0.7701 - loss: 0.0934 - precision: 0.9782 - recall: 0.9643 \n",
            "Epoch 393/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7728 - loss: 0.0929 - precision: 0.9662 - recall: 0.9752 \n",
            "Epoch 394/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9642 - f1_score: 0.7669 - loss: 0.0915 - precision: 0.9688 - recall: 0.9729\n",
            "Epoch 395/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9667 - f1_score: 0.7658 - loss: 0.0936 - precision: 0.9747 - recall: 0.9707 \n",
            "Epoch 396/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9647 - f1_score: 0.7598 - loss: 0.0946 - precision: 0.9695 - recall: 0.9721 \n",
            "Epoch 397/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7653 - loss: 0.0958 - precision: 0.9769 - recall: 0.9625 \n",
            "Epoch 398/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9647 - f1_score: 0.7704 - loss: 0.0961 - precision: 0.9672 - recall: 0.9759 \n",
            "Epoch 399/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9773 - f1_score: 0.7732 - loss: 0.0784 - precision: 0.9854 - recall: 0.9779 \n",
            "Epoch 400/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9670 - f1_score: 0.7713 - loss: 0.0899 - precision: 0.9735 - recall: 0.9729 \n",
            "Epoch 401/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9598 - f1_score: 0.7666 - loss: 0.1009 - precision: 0.9584 - recall: 0.9771 \n",
            "Epoch 402/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9632 - f1_score: 0.7696 - loss: 0.0902 - precision: 0.9702 - recall: 0.9701 \n",
            "Epoch 403/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9626 - f1_score: 0.7623 - loss: 0.0906 - precision: 0.9715 - recall: 0.9668 \n",
            "Epoch 404/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9666 - f1_score: 0.7619 - loss: 0.0907 - precision: 0.9666 - recall: 0.9788 \n",
            "Epoch 405/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9599 - f1_score: 0.7700 - loss: 0.0941 - precision: 0.9761 - recall: 0.9587 \n",
            "Epoch 406/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9617 - f1_score: 0.7680 - loss: 0.0953 - precision: 0.9745 - recall: 0.9627 \n",
            "Epoch 407/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9749 - f1_score: 0.7796 - loss: 0.0768 - precision: 0.9772 - recall: 0.9829 \n",
            "Epoch 408/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9699 - f1_score: 0.7680 - loss: 0.0816 - precision: 0.9786 - recall: 0.9722 \n",
            "Epoch 409/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9742 - f1_score: 0.7756 - loss: 0.0787 - precision: 0.9756 - recall: 0.9832 \n",
            "Epoch 410/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9748 - f1_score: 0.7754 - loss: 0.0782 - precision: 0.9818 - recall: 0.9777 \n",
            "Epoch 411/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9709 - f1_score: 0.7713 - loss: 0.0813 - precision: 0.9742 - recall: 0.9790 \n",
            "Epoch 412/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.7690 - loss: 0.0817 - precision: 0.9756 - recall: 0.9744 \n",
            "Epoch 413/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9665 - f1_score: 0.7750 - loss: 0.0887 - precision: 0.9746 - recall: 0.9716 \n",
            "Epoch 414/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9690 - f1_score: 0.7841 - loss: 0.0859 - precision: 0.9761 - recall: 0.9752 \n",
            "Epoch 415/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9716 - f1_score: 0.7657 - loss: 0.0820 - precision: 0.9769 - recall: 0.9765 \n",
            "Epoch 416/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9689 - f1_score: 0.7765 - loss: 0.0831 - precision: 0.9757 - recall: 0.9746 \n",
            "Epoch 417/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9678 - f1_score: 0.7746 - loss: 0.0814 - precision: 0.9693 - recall: 0.9793 \n",
            "Epoch 418/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9698 - f1_score: 0.7695 - loss: 0.0786 - precision: 0.9717 - recall: 0.9795 \n",
            "Epoch 419/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9731 - f1_score: 0.7750 - loss: 0.0847 - precision: 0.9782 - recall: 0.9788 \n",
            "Epoch 420/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9689 - f1_score: 0.7675 - loss: 0.0773 - precision: 0.9783 - recall: 0.9707\n",
            "Epoch 421/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9709 - f1_score: 0.7676 - loss: 0.0881 - precision: 0.9824 - recall: 0.9698\n",
            "Epoch 422/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9675 - f1_score: 0.7633 - loss: 0.0836 - precision: 0.9726 - recall: 0.9739\n",
            "Epoch 423/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9776 - f1_score: 0.7680 - loss: 0.0735 - precision: 0.9838 - recall: 0.9796\n",
            "Epoch 424/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9684 - f1_score: 0.7649 - loss: 0.0817 - precision: 0.9785 - recall: 0.9695\n",
            "Epoch 425/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9684 - f1_score: 0.7714 - loss: 0.0796 - precision: 0.9727 - recall: 0.9760\n",
            "Epoch 426/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9664 - f1_score: 0.7665 - loss: 0.0842 - precision: 0.9746 - recall: 0.9707\n",
            "Epoch 427/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9710 - f1_score: 0.7698 - loss: 0.0779 - precision: 0.9790 - recall: 0.9739\n",
            "Epoch 428/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9715 - f1_score: 0.7762 - loss: 0.0787 - precision: 0.9730 - recall: 0.9814\n",
            "Epoch 429/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9669 - f1_score: 0.7706 - loss: 0.0851 - precision: 0.9742 - recall: 0.9720\n",
            "Epoch 430/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7777 - loss: 0.0772 - precision: 0.9786 - recall: 0.9763 \n",
            "Epoch 431/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9633 - f1_score: 0.7635 - loss: 0.0907 - precision: 0.9696 - recall: 0.9701 \n",
            "Epoch 432/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9619 - f1_score: 0.7799 - loss: 0.0870 - precision: 0.9690 - recall: 0.9703 \n",
            "Epoch 433/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9706 - f1_score: 0.7666 - loss: 0.0779 - precision: 0.9731 - recall: 0.9793 \n",
            "Epoch 434/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9657 - f1_score: 0.7691 - loss: 0.0824 - precision: 0.9794 - recall: 0.9648 \n",
            "Epoch 435/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9687 - f1_score: 0.7705 - loss: 0.0837 - precision: 0.9719 - recall: 0.9775 \n",
            "Epoch 436/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9670 - f1_score: 0.7685 - loss: 0.0850 - precision: 0.9739 - recall: 0.9723 \n",
            "Epoch 437/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9663 - f1_score: 0.7727 - loss: 0.0861 - precision: 0.9692 - recall: 0.9769 \n",
            "Epoch 438/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9684 - f1_score: 0.7611 - loss: 0.0813 - precision: 0.9699 - recall: 0.9783 \n",
            "Epoch 439/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9689 - f1_score: 0.7702 - loss: 0.0833 - precision: 0.9682 - recall: 0.9819 \n",
            "Epoch 440/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9599 - f1_score: 0.7690 - loss: 0.0947 - precision: 0.9630 - recall: 0.9726 \n",
            "Epoch 441/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9689 - f1_score: 0.7753 - loss: 0.0782 - precision: 0.9810 - recall: 0.9687 \n",
            "Epoch 442/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9703 - f1_score: 0.7803 - loss: 0.0753 - precision: 0.9813 - recall: 0.9711 \n",
            "Epoch 443/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9701 - f1_score: 0.7658 - loss: 0.0806 - precision: 0.9816 - recall: 0.9693 \n",
            "Epoch 444/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9763 - f1_score: 0.7722 - loss: 0.0739 - precision: 0.9820 - recall: 0.9796 \n",
            "Epoch 445/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9654 - f1_score: 0.7686 - loss: 0.0802 - precision: 0.9730 - recall: 0.9707 \n",
            "Epoch 446/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9750 - f1_score: 0.7810 - loss: 0.0745 - precision: 0.9810 - recall: 0.9792 \n",
            "Epoch 447/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9747 - f1_score: 0.7710 - loss: 0.0722 - precision: 0.9862 - recall: 0.9727 \n",
            "Epoch 448/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.7646 - loss: 0.0773 - precision: 0.9795 - recall: 0.9770 \n",
            "Epoch 449/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9669 - f1_score: 0.7702 - loss: 0.0835 - precision: 0.9752 - recall: 0.9709 \n",
            "Epoch 450/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9686 - f1_score: 0.7598 - loss: 0.0785 - precision: 0.9780 - recall: 0.9697 \n",
            "Epoch 451/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.7767 - loss: 0.0826 - precision: 0.9727 - recall: 0.9781 \n",
            "Epoch 452/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9643 - f1_score: 0.7640 - loss: 0.0883 - precision: 0.9656 - recall: 0.9759 \n",
            "Epoch 453/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9749 - f1_score: 0.7794 - loss: 0.0690 - precision: 0.9767 - recall: 0.9834 \n",
            "Epoch 454/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9770 - f1_score: 0.7737 - loss: 0.0692 - precision: 0.9857 - recall: 0.9772 \n",
            "Epoch 455/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9779 - f1_score: 0.7785 - loss: 0.0696 - precision: 0.9868 - recall: 0.9778 \n",
            "Epoch 456/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9625 - f1_score: 0.7691 - loss: 0.0893 - precision: 0.9579 - recall: 0.9821 \n",
            "Epoch 457/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9706 - f1_score: 0.7752 - loss: 0.0774 - precision: 0.9792 - recall: 0.9734 \n",
            "Epoch 458/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9657 - f1_score: 0.7669 - loss: 0.0913 - precision: 0.9719 - recall: 0.9721 \n",
            "Epoch 459/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9680 - f1_score: 0.7721 - loss: 0.0841 - precision: 0.9685 - recall: 0.9803 \n",
            "Epoch 460/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9718 - f1_score: 0.7702 - loss: 0.0785 - precision: 0.9802 - recall: 0.9738 \n",
            "Epoch 461/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9724 - f1_score: 0.7721 - loss: 0.0733 - precision: 0.9784 - recall: 0.9770 \n",
            "Epoch 462/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9610 - f1_score: 0.7710 - loss: 0.0941 - precision: 0.9667 - recall: 0.9702 \n",
            "Epoch 463/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9707 - f1_score: 0.7633 - loss: 0.0784 - precision: 0.9747 - recall: 0.9771 \n",
            "Epoch 464/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9684 - f1_score: 0.7716 - loss: 0.0740 - precision: 0.9781 - recall: 0.9705 \n",
            "Epoch 465/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9731 - f1_score: 0.7716 - loss: 0.0741 - precision: 0.9808 - recall: 0.9754 \n",
            "Epoch 466/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9719 - f1_score: 0.7694 - loss: 0.0794 - precision: 0.9786 - recall: 0.9755 \n",
            "Epoch 467/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9679 - f1_score: 0.7745 - loss: 0.0784 - precision: 0.9764 - recall: 0.9719 \n",
            "Epoch 468/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9657 - f1_score: 0.7714 - loss: 0.0841 - precision: 0.9727 - recall: 0.9715 \n",
            "Epoch 469/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9691 - f1_score: 0.7707 - loss: 0.0838 - precision: 0.9737 - recall: 0.9761 \n",
            "Epoch 470/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9735 - f1_score: 0.7731 - loss: 0.0715 - precision: 0.9815 - recall: 0.9757 \n",
            "Epoch 471/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9678 - f1_score: 0.7702 - loss: 0.0797 - precision: 0.9771 - recall: 0.9702 \n",
            "Epoch 472/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9692 - f1_score: 0.7697 - loss: 0.0821 - precision: 0.9776 - recall: 0.9722 \n",
            "Epoch 473/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9784 - f1_score: 0.7663 - loss: 0.0660 - precision: 0.9808 - recall: 0.9839 \n",
            "Epoch 474/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9623 - f1_score: 0.7705 - loss: 0.0879 - precision: 0.9686 - recall: 0.9703 \n",
            "Epoch 475/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9699 - f1_score: 0.7610 - loss: 0.0765 - precision: 0.9735 - recall: 0.9767 \n",
            "Epoch 476/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9765 - f1_score: 0.7717 - loss: 0.0675 - precision: 0.9820 - recall: 0.9801 \n",
            "Epoch 477/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9688 - f1_score: 0.7684 - loss: 0.0826 - precision: 0.9763 - recall: 0.9727 \n",
            "Epoch 478/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9706 - f1_score: 0.7637 - loss: 0.0782 - precision: 0.9767 - recall: 0.9748 \n",
            "Epoch 479/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9680 - f1_score: 0.7671 - loss: 0.0781 - precision: 0.9692 - recall: 0.9788\n",
            "Epoch 480/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9642 - f1_score: 0.7766 - loss: 0.0887 - precision: 0.9701 - recall: 0.9727 \n",
            "Epoch 481/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9726 - f1_score: 0.7642 - loss: 0.0737 - precision: 0.9772 - recall: 0.9775 \n",
            "Epoch 482/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9690 - f1_score: 0.7763 - loss: 0.0840 - precision: 0.9761 - recall: 0.9741 \n",
            "Epoch 483/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9747 - f1_score: 0.7698 - loss: 0.0784 - precision: 0.9783 - recall: 0.9806 \n",
            "Epoch 484/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9772 - f1_score: 0.7738 - loss: 0.0667 - precision: 0.9838 - recall: 0.9795 \n",
            "Epoch 485/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9712 - f1_score: 0.7617 - loss: 0.0765 - precision: 0.9784 - recall: 0.9740 \n",
            "Epoch 486/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9742 - f1_score: 0.7803 - loss: 0.0696 - precision: 0.9787 - recall: 0.9801 \n",
            "Epoch 487/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9689 - f1_score: 0.7733 - loss: 0.0741 - precision: 0.9679 - recall: 0.9824\n",
            "Epoch 488/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9649 - f1_score: 0.7705 - loss: 0.0869 - precision: 0.9745 - recall: 0.9684 \n",
            "Epoch 489/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9695 - f1_score: 0.7714 - loss: 0.0747 - precision: 0.9774 - recall: 0.9728 \n",
            "Epoch 490/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9758 - f1_score: 0.7739 - loss: 0.0666 - precision: 0.9839 - recall: 0.9767 \n",
            "Epoch 491/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9741 - f1_score: 0.7723 - loss: 0.0714 - precision: 0.9822 - recall: 0.9758 \n",
            "Epoch 492/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9721 - f1_score: 0.7717 - loss: 0.0756 - precision: 0.9754 - recall: 0.9795 \n",
            "Epoch 493/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9685 - f1_score: 0.7792 - loss: 0.0813 - precision: 0.9801 - recall: 0.9693 \n",
            "Epoch 494/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9723 - f1_score: 0.7743 - loss: 0.0738 - precision: 0.9769 - recall: 0.9784 \n",
            "Epoch 495/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9672 - f1_score: 0.7742 - loss: 0.0825 - precision: 0.9737 - recall: 0.9734 \n",
            "Epoch 496/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9733 - f1_score: 0.7637 - loss: 0.0765 - precision: 0.9751 - recall: 0.9811 \n",
            "Epoch 497/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9755 - f1_score: 0.7774 - loss: 0.0667 - precision: 0.9826 - recall: 0.9782 \n",
            "Epoch 498/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9777 - f1_score: 0.7712 - loss: 0.0678 - precision: 0.9853 - recall: 0.9784 \n",
            "Epoch 499/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9701 - f1_score: 0.7711 - loss: 0.0747 - precision: 0.9769 - recall: 0.9742 \n",
            "Epoch 500/500\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9768 - f1_score: 0.7763 - loss: 0.0682 - precision: 0.9791 - recall: 0.9838 \n",
            "\n",
            "==================== ✅ Evaluación del Modelo Final en el Conjunto de Prueba ====================\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "Accuracy en Conjunto de Prueba: 0.8190\n",
            "Precision en Conjunto de Prueba: 0.8496\n",
            "Recall en Conjunto de Prueba: 0.8583\n",
            "F1-Score en Conjunto de Prueba: 0.8539\n",
            "\n",
            "Reporte de Clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.76       303\n",
            "           1       0.85      0.86      0.85       487\n",
            "\n",
            "    accuracy                           0.82       790\n",
            "   macro avg       0.81      0.81      0.81       790\n",
            "weighted avg       0.82      0.82      0.82       790\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfftlXWEG-e"
      },
      "source": [
        "## 5. Entrenamiento del modelo\n",
        "\n",
        "Reservamos el 20% de los datos de entrenamiento para la validación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Opcional) Reentrenar modelo final con todos los datos y mejores hiperparámetros\n",
        "for i in range(5):\n",
        "  best_model = tuner.hypermodel.build(best_hp[i])\n",
        "  history = best_model.fit(X_train, y_train,\n",
        "                          validation_data=(X_val, y_val),\n",
        "                          epochs=1000,\n",
        "                          batch_size=ceil(len(train_index)*0.1),\n",
        "                          verbose=0)\n",
        "\n",
        "  test_loss, test_acc, test_precision, test_recall, test_f1 = model.evaluate(X_val, y_val, verbose=0)\n",
        "  print(f'📊 Fold {fold+1}')\n",
        "  print(f'Test accuracy: {100*test_acc:.2f}%')\n",
        "  print(f'Test loss: {test_loss:.3f}')\n",
        "  folds_acc.append(test_acc)\n",
        "  folds_precission.append(test_precision)\n",
        "  folds_recall.append(test_recall)\n",
        "  folds_f1.append(test_f1)\n"
      ],
      "metadata": {
        "id": "WJq-FrDGEvfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "EPOCHS = 1000\n",
        "#BATCH_SIZE = train_size[0]\n",
        "BATCH_SIZE = ceil(train_size[0]*0.1)\n",
        "history = model.fit(normed_train_data, train_labels, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0)"
      ],
      "metadata": {
        "id": "m0aj2up8xVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w3FgAK4CCSnX",
        "outputId": "73e809a4-162b-4ee8-be99-246e20120c88"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"hist\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006347550950908333,\n        \"min\": 0.8095071911811829,\n        \"max\": 0.8248863816261292,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.817196786403656,\n          0.8217406272888184,\n          0.8248863816261292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00013810814603979643,\n        \"min\": 0.7623376250267029,\n        \"max\": 0.7626677751541138,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7625026702880859,\n          0.7623376250267029,\n          0.7626677751541138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007895688488016887,\n        \"min\": 0.3556634485721588,\n        \"max\": 0.37549519538879395,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3609391152858734,\n          0.3556634485721588,\n          0.3585996925830841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007251117900362078,\n        \"min\": 0.8163371682167053,\n        \"max\": 0.8347502946853638,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8257894515991211,\n          0.8311275839805603,\n          0.8347502946853638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019004011327720016,\n        \"min\": 0.8909710645675659,\n        \"max\": 0.8955138921737671,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8921067714691162,\n          0.8915389180183411,\n          0.8909710645675659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0061989731224158405,\n        \"min\": 0.6494413614273071,\n        \"max\": 0.666201114654541,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6494413614273071,\n          0.666201114654541,\n          0.6578212380409241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00029257633830353846,\n        \"min\": 0.74715656042099,\n        \"max\": 0.7478107810020447,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.74715656042099,\n          0.7478107810020447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014469501568279875,\n        \"min\": 1.1016870737075806,\n        \"max\": 1.136595606803894,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.1320658922195435,\n          1.1292800903320312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0026408697542278014,\n        \"min\": 0.6842105388641357,\n        \"max\": 0.6902287006378174,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6895074844360352,\n          0.6842105388641357\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024471442051881953,\n        \"min\": 0.7523364424705505,\n        \"max\": 0.8200934529304504,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7523364424705505,\n          0.8200934529304504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 695,\n        \"max\": 699,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          696,\n          699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-60e77b78-438e-4ad8-968d-20e4913826e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_f1_score</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>0.809507</td>\n",
              "      <td>0.762503</td>\n",
              "      <td>0.375495</td>\n",
              "      <td>0.816337</td>\n",
              "      <td>0.890971</td>\n",
              "      <td>0.656425</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.136596</td>\n",
              "      <td>0.688017</td>\n",
              "      <td>0.778037</td>\n",
              "      <td>695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>0.817197</td>\n",
              "      <td>0.762338</td>\n",
              "      <td>0.360939</td>\n",
              "      <td>0.825789</td>\n",
              "      <td>0.890971</td>\n",
              "      <td>0.649441</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.132066</td>\n",
              "      <td>0.689507</td>\n",
              "      <td>0.752336</td>\n",
              "      <td>696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>0.824886</td>\n",
              "      <td>0.762338</td>\n",
              "      <td>0.358600</td>\n",
              "      <td>0.834750</td>\n",
              "      <td>0.892107</td>\n",
              "      <td>0.657821</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.135590</td>\n",
              "      <td>0.690229</td>\n",
              "      <td>0.775701</td>\n",
              "      <td>697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>0.824187</td>\n",
              "      <td>0.762503</td>\n",
              "      <td>0.358171</td>\n",
              "      <td>0.831751</td>\n",
              "      <td>0.895514</td>\n",
              "      <td>0.653631</td>\n",
              "      <td>0.747811</td>\n",
              "      <td>1.101687</td>\n",
              "      <td>0.685185</td>\n",
              "      <td>0.778037</td>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>0.821741</td>\n",
              "      <td>0.762668</td>\n",
              "      <td>0.355663</td>\n",
              "      <td>0.831128</td>\n",
              "      <td>0.891539</td>\n",
              "      <td>0.666201</td>\n",
              "      <td>0.747157</td>\n",
              "      <td>1.129280</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.820093</td>\n",
              "      <td>699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60e77b78-438e-4ad8-968d-20e4913826e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60e77b78-438e-4ad8-968d-20e4913826e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60e77b78-438e-4ad8-968d-20e4913826e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd7443af-e889-4364-95bb-0df4c538ca25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd7443af-e889-4364-95bb-0df4c538ca25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd7443af-e889-4364-95bb-0df4c538ca25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     accuracy  f1_score      loss  precision    recall  val_accuracy  \\\n",
              "695  0.809507  0.762503  0.375495   0.816337  0.890971      0.656425   \n",
              "696  0.817197  0.762338  0.360939   0.825789  0.890971      0.649441   \n",
              "697  0.824886  0.762338  0.358600   0.834750  0.892107      0.657821   \n",
              "698  0.824187  0.762503  0.358171   0.831751  0.895514      0.653631   \n",
              "699  0.821741  0.762668  0.355663   0.831128  0.891539      0.666201   \n",
              "\n",
              "     val_f1_score  val_loss  val_precision  val_recall  epoch  \n",
              "695      0.747811  1.136596       0.688017    0.778037    695  \n",
              "696      0.747811  1.132066       0.689507    0.752336    696  \n",
              "697      0.747811  1.135590       0.690229    0.775701    697  \n",
              "698      0.747811  1.101687       0.685185    0.778037    698  \n",
              "699      0.747157  1.129280       0.684211    0.820093    699  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "PHxBjzT8Ep82",
        "outputId": "d6a539c6-e7d7-4462-e120-6e33c9e956cd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Binary Crossentropy')\n",
        "  plt.plot(hist['epoch'], hist['binary_accuracy'],'r--',\n",
        "           label='Training Accuracy')\n",
        "  plt.plot(hist['epoch'], hist['val_binary_accuracy'],'b',\n",
        "           label = 'Validation Accuracy')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9M9YKiC-295"
      },
      "source": [
        "## 6. Validación del modelo con los datos de test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS6oqzXxT3AJ",
        "outputId": "e1f55709-b906-46f5-cb3d-db606148ea40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step - accuracy: 0.6644 - f1_score: 0.7639 - loss: 0.9440 - precision: 0.6860 - recall: 0.8382\n",
            "Test accuracy: 66.44%\n",
            "Test loss: 0.944\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, test_f1, test_precision, test_recall = model.evaluate(normed_test_data, test_labels, batch_size=(test_size[0]))\n",
        "print(f'Test accuracy: {100*test_acc:.2f}%')\n",
        "print(f'Test loss: {test_loss:.3f}')\n",
        "# 66,55%"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}